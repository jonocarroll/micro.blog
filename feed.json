{
	"version": "https://jsonfeed.org/version/1",
	"title": "Jonathan Carroll's micro blog",
	"icon": "https://micro.blog/jonocarroll/avatar.jpg",
	"home_page_url": "https://jcarroll.xyz/",
	"feed_url": "https://jcarroll.xyz/feed.json",
	"items": [
		
			{
				"id": "http://jonocarroll.micro.blog/2023/07/03/filtering-vectors.html",
				"title": "Filtering vectors",
				"content_html": "<p>I saw a YouTube short demonstrating how to use <code>filter()</code> in Python along the lines of</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"><code class=\"language-python\" data-lang=\"python\">nums<span style=\"color:#f92672\">=</span>range(<span style=\"color:#ae81ff\">1</span>,<span style=\"color:#ae81ff\">30</span>)\n\n<span style=\"color:#66d9ef\">def</span> <span style=\"color:#a6e22e\">is_prime</span>(num):\n  <span style=\"color:#66d9ef\">for</span> x <span style=\"color:#f92672\">in</span> range(<span style=\"color:#ae81ff\">2</span>,num):\n    <span style=\"color:#66d9ef\">if</span> (num<span style=\"color:#f92672\">%</span>x) <span style=\"color:#f92672\">==</span> <span style=\"color:#ae81ff\">0</span>:\n      <span style=\"color:#66d9ef\">return</span> <span style=\"color:#66d9ef\">False</span>\n    \n  <span style=\"color:#66d9ef\">return</span> <span style=\"color:#66d9ef\">True</span>\n\n  \nprimes<span style=\"color:#f92672\">=</span>list(filter(is_prime, nums))\nprint(primes)\n<span style=\"color:#75715e\"># [1, 2, 3, 5, 7, 11, 13, 17, 19, 23, 29]</span>\n</code></pre></div><p>and as always, I like to think about how I&rsquo;d do this in other languages (e.g. R).</p>\n<p>The (deliberately brute-force) <code>is_prime()</code> function translates easily enough</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"><code class=\"language-r\" data-lang=\"r\">is_prime <span style=\"color:#f92672\">&lt;-</span> <span style=\"color:#a6e22e\">function</span>(x) {\n  <span style=\"color:#a6e22e\">for </span>(i in <span style=\"color:#ae81ff\">2</span><span style=\"color:#f92672\">:</span>(x<span style=\"color:#ae81ff\">-1</span>)) {\n    <span style=\"color:#a6e22e\">if </span>(x <span style=\"color:#f92672\">%%</span> i <span style=\"color:#f92672\">==</span> <span style=\"color:#ae81ff\">0</span>) <span style=\"color:#a6e22e\">return</span>(<span style=\"color:#66d9ef\">FALSE</span>)\n  }\n  <span style=\"color:#66d9ef\">TRUE</span>\n}\n</code></pre></div><p>and the most common way to run this over a vector of inputs is with something like <code>sapply()</code> returning a vector of logicals that can be used for square-bracket subsetting</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"><code class=\"language-r\" data-lang=\"r\">x <span style=\"color:#f92672\">&lt;-</span> <span style=\"color:#ae81ff\">1</span><span style=\"color:#f92672\">:</span><span style=\"color:#ae81ff\">30</span>\nprimes <span style=\"color:#f92672\">&lt;-</span> x<span style=\"color:#a6e22e\">[sapply</span>(x, is_prime)]\nprimes\n<span style=\"color:#75715e\"># [1]  3  5  7 11 13 17 19 23 29</span>\n</code></pre></div><p>We can get rid of the need for <code>sapply()</code> by vectorising the function which is done easily with <code>Vectorize()</code></p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"><code class=\"language-r\" data-lang=\"r\">is_prime_v <span style=\"color:#f92672\">&lt;-</span> <span style=\"color:#a6e22e\">Vectorize</span>(is_prime)\nprimes <span style=\"color:#f92672\">&lt;-</span> x<span style=\"color:#a6e22e\">[is_prime_v</span>(x)]\nprimes\n<span style=\"color:#75715e\"># [1]  3  5  7 11 13 17 19 23 29</span>\n</code></pre></div><p>It&rsquo;s usually at this point that I feel bad about having to write <code>x</code> twice and lament that while {dplyr} is great for <code>data.frame</code>s, we don&rsquo;t have something equivalent for filtering of vectors so easily&hellip; except we do (as I usually end up remembering). <code>Filter()</code> is a base function that works on vectors and is the equivalent of what we saw in Python (per the docs, <a href=\"https://hoogle.haskell.org/?hoogle=filter\">&ldquo;Filter corresponds to filter in Haskell&rdquo;</a>)</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"><code class=\"language-r\" data-lang=\"r\">primes <span style=\"color:#f92672\">&lt;-</span> <span style=\"color:#a6e22e\">Filter</span>(is_prime, x)\nprimes\n<span style=\"color:#75715e\"># [1]  3  5  7 11 13 17 19 23 29</span>\n</code></pre></div><p>I need to remember to use that (as well as the rest of the gold-mine in the &lsquo;funprog&rsquo; toolbox like <code>Map</code> and <code>Reduce</code>) more often.</p>\n",
				"content_text": "I saw a YouTube short demonstrating how to use `filter()` in Python along the lines of\r\n\r\n```python\r\nnums=range(1,30)\r\n\r\ndef is_prime(num):\r\n  for x in range(2,num):\r\n    if (num%x) == 0:\r\n      return False\r\n    \r\n  return True\r\n\r\n  \r\nprimes=list(filter(is_prime, nums))\r\nprint(primes)\r\n# [1, 2, 3, 5, 7, 11, 13, 17, 19, 23, 29]\r\n```\r\n\r\nand as always, I like to think about how I'd do this in other languages (e.g. R). \r\n\r\nThe (deliberately brute-force) `is_prime()` function translates easily enough\r\n\r\n```r\r\nis_prime <- function(x) {\r\n  for (i in 2:(x-1)) {\r\n    if (x %% i == 0) return(FALSE)\r\n  }\r\n  TRUE\r\n}\r\n```\r\n\r\nand the most common way to run this over a vector of inputs is with something like `sapply()` returning a vector of logicals that can be used for square-bracket subsetting\r\n\r\n```r\r\nx <- 1:30\r\nprimes <- x[sapply(x, is_prime)]\r\nprimes\r\n# [1]  3  5  7 11 13 17 19 23 29\r\n```\r\n\r\nWe can get rid of the need for `sapply()` by vectorising the function which is done easily with `Vectorize()`\r\n\r\n```r\r\nis_prime_v <- Vectorize(is_prime)\r\nprimes <- x[is_prime_v(x)]\r\nprimes\r\n# [1]  3  5  7 11 13 17 19 23 29\r\n```\r\n\r\nIt's usually at this point that I feel bad about having to write `x` twice and lament that while {dplyr} is great for `data.frame`s, we don't have something equivalent for filtering of vectors so easily... except we do (as I usually end up remembering). `Filter()` is a base function that works on vectors and is the equivalent of what we saw in Python (per the docs, [\"Filter corresponds to filter in Haskell\"](https://hoogle.haskell.org/?hoogle=filter))\r\n\r\n```r\r\nprimes <- Filter(is_prime, x)\r\nprimes\r\n# [1]  3  5  7 11 13 17 19 23 29\r\n```\r\n\r\nI need to remember to use that (as well as the rest of the gold-mine in the 'funprog' toolbox like `Map` and `Reduce`) more often.\n",
				"date_published": "2023-07-03T13:05:36+09:30",
				"url": "https://jcarroll.xyz/2023/07/03/filtering-vectors.html",
				"tags": ["R"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/06/14/around-the-web.html",
				"title": "Around the web 2023W24",
				"content_html": "<p>I think I&rsquo;m happy with my <a href=\"https://feedrabbit.com/\">RSS-to-email</a> setup now but I feel like I&rsquo;m only passively reading things and can do better. I&rsquo;m going to try summarising (on this micro blog) the interesting posts I see (RSS feeds, newsletters, social feeds, general web finds) as a way to share some links, to be able to find them again later, and to reinforce what I&rsquo;m learning. This is informal, largely unstructured, largely unedited, and possibly only interesting to me, but if you don&rsquo;t like it then don&rsquo;t read it. Feel free to comment (here or elsewhere) and start a conversation on any of the topics (or anything).</p>\n<p>I think I&rsquo;ll aim for a weekly post with all the things I read that week. That way I can add to them as I revisit each day. This post already ended up longer than I expected, but I was able to piece it together over many updates via a web text input box rather than re-building my static website.</p>\n<h2 id=\"this-is-valid-python-syntax\">This is valid Python syntax</h2>\n<p><a href=\"https://www.bitecode.dev/p/this-is-valid-python-syntax\">https://www.bitecode.dev/p/this-is-valid-python-syntax</a></p>\n<p>Source: HN toot (now substack subscribed)</p>\n<p>I <em>really</em> like this post for the fact that it teaches a pile of interesting (python) syntax and invites the reader to see if they can unpack all the pieces. Fun little puzzles like <a href=\"https://codegolf.stackexchange.com/\">code-golf</a> are great for this.</p>\n<p>One thing that really struck me was python&rsquo;s ability to use a variable number of arguments in a function</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"><code class=\"language-python\" data-lang=\"python\"><span style=\"color:#66d9ef\">def</span> <span style=\"color:#a6e22e\">a_lot</span>(<span style=\"color:#f92672\">*</span>of_stuff): <span style=\"color:#75715e\"># accept 0, 1 or more params</span>\n<span style=\"color:#f92672\">...</span>     print(of_stuff)\n<span style=\"color:#f92672\">...</span>\n</code></pre></div><p>which we <em>can</em> do in R with <code>...</code></p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"><code class=\"language-r\" data-lang=\"r\">a_lot <span style=\"color:#f92672\">&lt;-</span> <span style=\"color:#a6e22e\">function</span>(<span style=\"color:#66d9ef\">...</span>) {\n  <span style=\"color:#a6e22e\">print</span>(<span style=\"color:#a6e22e\">list</span>(<span style=\"color:#66d9ef\">...</span>))\n}\n<span style=\"color:#a6e22e\">a_lot</span>(a <span style=\"color:#f92672\">=</span> <span style=\"color:#ae81ff\">1</span>, b <span style=\"color:#f92672\">=</span> <span style=\"color:#ae81ff\">2</span>)\n<span style=\"color:#f92672\">$</span>a\n[1] <span style=\"color:#ae81ff\">1</span>\n\n<span style=\"color:#f92672\">$</span>b\n[1] <span style=\"color:#ae81ff\">2</span>\n</code></pre></div><p>but python can also unpack (&ldquo;splat&rdquo;?) the arguments</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"><code class=\"language-python\" data-lang=\"python\"><span style=\"color:#f92672\">&gt;&gt;&gt;</span> <span style=\"color:#66d9ef\">def</span> <span style=\"color:#a6e22e\">square_area</span>(x1, y1, x2, y2):\n<span style=\"color:#f92672\">...</span>     side_length <span style=\"color:#f92672\">=</span> abs(x2 <span style=\"color:#f92672\">-</span> x1)\n<span style=\"color:#f92672\">...</span>     area <span style=\"color:#f92672\">=</span> side_length <span style=\"color:#f92672\">**</span> <span style=\"color:#ae81ff\">2</span>\n<span style=\"color:#f92672\">...</span>     <span style=\"color:#66d9ef\">return</span> area\n<span style=\"color:#f92672\">...</span> coords <span style=\"color:#f92672\">=</span> [<span style=\"color:#ae81ff\">0</span>, <span style=\"color:#ae81ff\">0</span>, <span style=\"color:#ae81ff\">3</span>, <span style=\"color:#ae81ff\">3</span>]\n<span style=\"color:#f92672\">&gt;&gt;&gt;</span> square_area(coords[<span style=\"color:#ae81ff\">0</span>], coords[<span style=\"color:#ae81ff\">1</span>], coords[<span style=\"color:#ae81ff\">2</span>], coords[<span style=\"color:#ae81ff\">3</span>])\n<span style=\"color:#ae81ff\">9</span>\n<span style=\"color:#f92672\">&gt;&gt;&gt;</span> square_area(<span style=\"color:#f92672\">*</span>coords)\n<span style=\"color:#ae81ff\">9</span>\n</code></pre></div><p>which R can&rsquo;t do (well, <code>do.call(what, args)</code> does that, but not as cleanly).</p>\n<p>I bet some interesting results could be made with R syntax - there&rsquo;s an idea for a post.</p>\n<h2 id=\"get-the-most-out-of-python-dicts\">Get the most out of Python dicts</h2>\n<p><a href=\"https://www.bitecode.dev/p/get-the-most-out-of-python-dict\">https://www.bitecode.dev/p/get-the-most-out-of-python-dict</a></p>\n<p>Source: Substack subscription</p>\n<p><code>dict</code> is a structure in python that I suppose the R equivalent of is a named vector or a <code>list</code>, but there&rsquo;s some hashset-like quality to them (the keys are unique) so that&rsquo;s not exact at all. There&rsquo;s a lot of semantics specific to <code>dict</code> that I haven&rsquo;t appreciated yet, so this was a nice little tour.</p>\n<h2 id=\"how-to-write-conditional-statements-in-r-four-methods\">How to Write Conditional Statements in R: Four Methods</h2>\n<p><a href=\"https://towardsdatascience.com/how-to-write-conditional-statements-in-r-four-methods-f9bedbae0683\">https://towardsdatascience.com/how-to-write-conditional-statements-in-r-four-methods-f9bedbae0683</a></p>\n<p>Source: Mastodon boost</p>\n<p>This is a post for R beginners, but I&rsquo;m wary that the <code>ifelse()</code> vector example could be misleading since it will error if the logic is applied back to the <code>if()</code> scenario (length &gt; 1). The post isn&rsquo;t wrong per-se, but it would be worth pointing out. I&rsquo;ve also hit bugs in the past because the <em>shape</em> of the condition needs to match the shape of the result</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"><code class=\"language-r\" data-lang=\"r\"><span style=\"color:#a6e22e\">ifelse</span>(<span style=\"color:#66d9ef\">TRUE</span>, <span style=\"color:#ae81ff\">1</span><span style=\"color:#f92672\">:</span><span style=\"color:#ae81ff\">4</span>, <span style=\"color:#ae81ff\">2</span>)\n[1] <span style=\"color:#ae81ff\">1</span>\n</code></pre></div><p>The author also says</p>\n<blockquote>\n<p>This makes ifelse a clean way of evaluating lots of simple conditions without needing slow, messy loops.</p>\n</blockquote>\n<p>and it should be noted that for-loops aren&rsquo;t slow; your code is slow <a href=\"https://youtu.be/TdbweYvwnss\">https://youtu.be/TdbweYvwnss</a></p>\n<h2 id=\"emulated-build-and-test-of-bioconductor-packages-for-linux-arm64\">Emulated build and test of Bioconductor packages for Linux ARM64</h2>\n<p><a href=\"https://bioconductor.github.io/biocblog/posts/2023-06-09-debug-linux-arm64-on-docker/\">https://bioconductor.github.io/biocblog/posts/2023-06-09-debug-linux-arm64-on-docker/</a></p>\n<p>Source: Mastodon follow</p>\n<p>along with rocker/rstudio arm64 builds <a href=\"https://hub.docker.com/r/rocker/rstudio/tags\">https://hub.docker.com/r/rocker/rstudio/tags</a></p>\n<p>I&rsquo;ve been waiting for this for a while! I got an M1 mac when I started my current job over a year ago and while I can deploy docker images in a cloud solution, I couldn&rsquo;t test them locally. Time to build all the things!</p>\n<h2 id=\"feeling-rusty-counting-characters\">Feeling rusty: counting characters</h2>\n<p><a href=\"https://josiahparry.com/posts/2023-04-13-counting-chars/\">https://josiahparry.com/posts/2023-04-13-counting-chars/</a></p>\n<p>Source: the Julia post below</p>\n<p>Just when you think R is sort of okay at performance - not terrible, but by no means the fastest - Rust goes and shows you that you&rsquo;re wasting your time even trying to keep up and has already gone to lunch after completing all its tasks. This was a great intro to &lsquo;Rust as an RCpp replacement&rsquo; via {rextendr} (a fuller intro from the same author is <a href=\"https://youtu.be/tRm-Qq2_Ap0\">https://youtu.be/tRm-Qq2_Ap0</a>).</p>\n<h2 id=\"string-matching-in-julia\">String Matching in Julia</h2>\n<p><a href=\"https://www.ericekholm.com/posts/string-match-jl/\">https://www.ericekholm.com/posts/string-match-jl/</a></p>\n<p>Source: RT</p>\n<p>This reminds me what I like so much about Julia syntax. Those function definitions are just <em>so</em> clean!</p>\n<div class=\"highlight\"><pre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4\"><code class=\"language-julia\" data-lang=\"julia\"><span style=\"color:#66d9ef\">function</span> compare_strings(x<span style=\"color:#f92672\">::</span><span style=\"color:#66d9ef\">String</span>, y<span style=\"color:#f92672\">::</span><span style=\"color:#66d9ef\">String</span>)\n    s <span style=\"color:#f92672\">=</span> <span style=\"color:#ae81ff\">0</span>\n    <span style=\"color:#66d9ef\">for</span> i <span style=\"color:#f92672\">∈</span> eachindex(x)\n        x[i] <span style=\"color:#f92672\">!=</span> y[i] <span style=\"color:#f92672\">?</span> <span style=\"color:#66d9ef\">break</span> <span style=\"color:#f92672\">:</span> s <span style=\"color:#f92672\">+=</span> <span style=\"color:#ae81ff\">1</span>\n    <span style=\"color:#66d9ef\">end</span>\n    <span style=\"color:#66d9ef\">return</span> s\n<span style=\"color:#66d9ef\">end</span>\n</code></pre></div><p>And being able to add more definitions just by <em>writing them out</em> is so compact (a full post on that coming soon).</p>\n<p>As for performance, that looks hard to beat. I plan to run the R, Rust, and Julia functions on one machine and see how they compare, but I&rsquo;m not going to let it get in the way of writing this.</p>\n<h2 id=\"whats-so-special-about-arrays\">What’s so special about arrays?</h2>\n<p><a href=\"https://josiahparry.com/posts/2023-06-11-matrix-bug.html\">https://josiahparry.com/posts/2023-06-11-matrix-bug.html</a></p>\n<p>Source: r-contributors slack</p>\n<p>I commented in the slack thread but my take on this is that <code>matrix</code> is pretty much a vector with a <code>dim</code> attribute, so I&rsquo;m not so surprised that <code>unclass()</code> doesn&rsquo;t really &ldquo;un-class&rdquo; it. <code>?class</code> seems to refer to this as an &ldquo;implicit class&rdquo;.</p>\n<h2 id=\"effective-spaced-repetition\">Effective Spaced Repetition</h2>\n<p><a href=\"https://borretti.me/article/effective-spaced-repetition\">https://borretti.me/article/effective-spaced-repetition</a></p>\n<p>Source: originally via <a href=\"https://borretti.me/article/depth-first-procrastination\">https://borretti.me/article/depth-first-procrastination</a> via RSS Feed</p>\n<p>This is a longer read, but I&rsquo;m on board with the principle.</p>\n<h2 id=\"research-sum-types\">(Research) Sum Types</h2>\n<p>Trigger: <a href=\"https://corecursive.com/048-jared-forsyth-the-reason-for-types/#sum-types-in-reasonml\">Corecursive podcast</a></p>\n<p>I&rsquo;m digging through some older episodes for a once-a-week rare commute somewhere and this term caught my ear so I decided to look into it a bit and it turns out to be super interesting! I haven&rsquo;t dug through all of these, but this serves as a sort of bookmark for me to come back to.</p>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Algebraic_data_type\">https://en.wikipedia.org/wiki/Algebraic_data_type</a></li>\n<li><a href=\"https://www.reddit.com/r/ProgrammingLanguages/comments/10jewgp/could_you_explain_why_sum_types_are_so_good/\">https://www.reddit.com/r/ProgrammingLanguages/comments/10jewgp/could_you_explain_why_sum_types_are_so_good/</a></li>\n<li><a href=\"https://shreevatsa.wordpress.com/2015/01/31/boolean-blindness/\">https://shreevatsa.wordpress.com/2015/01/31/boolean-blindness/</a></li>\n<li><a href=\"https://serokell.io/blog/algebraic-data-types-in-haskell\">https://serokell.io/blog/algebraic-data-types-in-haskell</a></li>\n<li><a href=\"https://jrsinclair.com/articles/2019/algebraic-data-types-what-i-wish-someone-had-explained-about-functional-programming/\">https://jrsinclair.com/articles/2019/algebraic-data-types-what-i-wish-someone-had-explained-about-functional-programming/</a></li>\n<li><a href=\"https://docs.rs/sum_type/latest/sum_type/\">https://docs.rs/sum_type/latest/sum_type/</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=LafOj_HrxRQ\">https://www.youtube.com/watch?v=LafOj_HrxRQ</a> aaaand now I&rsquo;m glad I was keeping track of all of these; this is a very timely video on Rust enums that covers some of this topic. Found via <a href=\"https://this-week-in-rust.org/blog/2023/06/14/this-week-in-rust-499/\">This Week in Rust</a>.</li>\n</ul>\n<h2 id=\"is-that-a-compiler-bug\">Is That a Compiler Bug?</h2>\n<p><a href=\"https://blog.regehr.org/archives/26\">https://blog.regehr.org/archives/26</a></p>\n<p>An older post (circa 2010) that I don&rsquo;t recall how I came across. Interesting, though not something I&rsquo;m likely to encounter myself anytime soon.</p>\n<h2 id=\"writing-r-in-vscode-working-with-multiple-r-sessions\">Writing R in VSCode: Working with multiple R sessions</h2>\n<p><a href=\"https://renkun.me/2020/04/14/writing-r-in-vscode-working-with-multiple-r-sessions/\">https://renkun.me/2020/04/14/writing-r-in-vscode-working-with-multiple-r-sessions/</a></p>\n<p>Source: rOpenSci slack</p>\n<p>I&rsquo;ve been starting to use <code>tmux</code> in terminals lately and am really enjoying it, so when a question came up about connecting a VSCode session to it (which could be remotely connected) my interest was piqued. The linked post might be a solution to that, though I&rsquo;m yet to try it myself.</p>\n<h2 id=\"list-one-task-do-it-cross-it-out\">List one task, do it, cross it out</h2>\n<p><a href=\"https://www.oliverburkeman.com/onething\">https://www.oliverburkeman.com/onething</a></p>\n<p>Source: can&rsquo;t recall&hellip; HN? This echos a lot of what the &lsquo;minimalist&rsquo; folks are saying about organising and cleaning; trying to decide which of the dozen semi-important things you need to work on often leads to doing none of them, but by choosing just one you know exactly what you need to do.</p>\n<h2 id=\"finish-your-projects\">Finish your projects</h2>\n<p><a href=\"https://github.com/readme/guides/finish-your-projects\">https://github.com/readme/guides/finish-your-projects</a></p>\n<p>Source: TLDR newsletter</p>\n<p>Similar to the above article in terms of message; pick something and do it.</p>\n<h2 id=\"iterating-on-testing-in-rust\">Iterating on Testing in Rust</h2>\n<p><a href=\"https://epage.github.io/blog/2023/06/iterating-on-test/\">https://epage.github.io/blog/2023/06/iterating-on-test/</a></p>\n<p>Source: HN</p>\n<p>Good overview of how tests work in Rust.</p>\n<h2 id=\"row-relational-operations-with-slice\">Row relational operations with slice()</h2>\n<p><a href=\"https://yjunechoe.github.io/posts/2023-06-11-row-relational-operations/\">https://yjunechoe.github.io/posts/2023-06-11-row-relational-operations/</a></p>\n<p>Source: RWeekly</p>\n<p>Winners: <code>slice()</code> as a <code>filter()</code> being able use row indices with <code>cond + 1</code>; <code>outer()</code> to get non-recycling addition. A very in-depth article that goes through lots of uses of <code>slice()</code>.</p>\n<h2 id=\"on-updating-a-chat-assistant-app-for-the-rstudio-ide\">On updating a chat assistant app for the RStudio IDE</h2>\n<ul>\n<li><a href=\"https://samuelenrique.com/posts/2023-06-02-updating-gptstudio/\">https://samuelenrique.com/posts/2023-06-02-updating-gptstudio/</a></li>\n</ul>\n<p>Source: RWeekly</p>\n<p>The auto-updating streaming output is very cool! I wonder if there&rsquo;s an open streaming resource I could use to try this?</p>\n<p>This also demonstrates adding &lsquo;copy&rsquo; button to code blocks which I don&rsquo;t have on my blog - perhaps I could? They used</p>\n<pre tabindex=\"0\"><code class=\"language- \" data-lang=\" \">$('pre').each(function() {\n  const $codeChunk = $(this);\n  const $copyButton = $('&lt;button&gt;').text('Copy');\n  $codeChunk.prepend($copyButton);\n\n  $copyButton.on('click', function() {\n    const codeText = $codeChunk.text();\n    navigator.clipboard.writeText(codeText);\n  });\n});\n</code></pre><h2 id=\"a-terminal-case-of-linux\">A terminal case of Linux</h2>\n<p><a href=\"https://fasterthanli.me/articles/a-terminal-case-of-linux\">https://fasterthanli.me/articles/a-terminal-case-of-linux</a></p>\n<p>Source: ? (Mastodon?)</p>\n<p>I don&rsquo;t recall where or why I found this 2021 article but as usual, Amos goes reeeeally deep into some Rust code (and libc / Linux in this case). I got hooked on these posts when (re-)doing AoC 2022 and for <a href=\"https://fasterthanli.me/series/advent-of-code-2022/part-1\">day 1</a> Amos went mile-deep (25mins read) on Rust in general when the problem to be solved was &ldquo;straightforward&rdquo;.</p>\n<h2 id=\"friction-baby\">Friction, Baby</h2>\n<p><a href=\"https://tedium.co/2023/06/10/productivity-friction-theory/\">https://tedium.co/2023/06/10/productivity-friction-theory/</a></p>\n<p>Source: HN</p>\n<p>This makes a lot of sense to me and made me consider a lot of the patterns (anti-, dark-, or otherwise) I see in my media consumption. The goal of this micro blog is to have as little friction as possible when publishing some markdown text. Sometimes, some interactions could use a bit more friction.</p>\n",
				"content_text": "I think I'm happy with my [RSS-to-email](https://feedrabbit.com/) setup now but I feel like I'm only passively reading things and can do better. I'm going to try summarising (on this micro blog) the interesting posts I see (RSS feeds, newsletters, social feeds, general web finds) as a way to share some links, to be able to find them again later, and to reinforce what I'm learning. This is informal, largely unstructured, largely unedited, and possibly only interesting to me, but if you don't like it then don't read it. Feel free to comment (here or elsewhere) and start a conversation on any of the topics (or anything).\n\nI think I'll aim for a weekly post with all the things I read that week. That way I can add to them as I revisit each day. This post already ended up longer than I expected, but I was able to piece it together over many updates via a web text input box rather than re-building my static website.\n\n## This is valid Python syntax\n\n[https://www.bitecode.dev/p/this-is-valid-python-syntax](https://www.bitecode.dev/p/this-is-valid-python-syntax)\n\nSource: HN toot (now substack subscribed)\n\nI _really_ like this post for the fact that it teaches a pile of interesting (python) syntax and invites the reader to see if they can unpack all the pieces. Fun little puzzles like [code-golf](https://codegolf.stackexchange.com/) are great for this.\n\nOne thing that really struck me was python's ability to use a variable number of arguments in a function\n\n```python\ndef a_lot(*of_stuff): # accept 0, 1 or more params\n...     print(of_stuff)\n...\n```\n\nwhich we _can_ do in R with `...`\n\n```r\na_lot <- function(...) {\n  print(list(...))\n}\na_lot(a = 1, b = 2)\n$a\n[1] 1\n\n$b\n[1] 2\n```\n\nbut python can also unpack (\"splat\"?) the arguments\n\n```python\n>>> def square_area(x1, y1, x2, y2):\n...     side_length = abs(x2 - x1)\n...     area = side_length ** 2\n...     return area\n... coords = [0, 0, 3, 3]\n>>> square_area(coords[0], coords[1], coords[2], coords[3])\n9\n>>> square_area(*coords)\n9\n```\n\nwhich R can't do (well, `do.call(what, args)` does that, but not as cleanly).\n\nI bet some interesting results could be made with R syntax - there's an idea for a post.\n\n## Get the most out of Python dicts\n\n[https://www.bitecode.dev/p/get-the-most-out-of-python-dict](https://www.bitecode.dev/p/get-the-most-out-of-python-dict)\n\nSource: Substack subscription\n\n`dict` is a structure in python that I suppose the R equivalent of is a named vector or a `list`, but there's some hashset-like quality to them (the keys are unique) so that's not exact at all. There's a lot of semantics specific to `dict` that I haven't appreciated yet, so this was a nice little tour.\n\n## How to Write Conditional Statements in R: Four Methods\n\n[https://towardsdatascience.com/how-to-write-conditional-statements-in-r-four-methods-f9bedbae0683](https://towardsdatascience.com/how-to-write-conditional-statements-in-r-four-methods-f9bedbae0683)\n\nSource: Mastodon boost\n\nThis is a post for R beginners, but I'm wary that the `ifelse()` vector example could be misleading since it will error if the logic is applied back to the `if()` scenario (length > 1). The post isn't wrong per-se, but it would be worth pointing out. I've also hit bugs in the past because the _shape_ of the condition needs to match the shape of the result\n\n```r\nifelse(TRUE, 1:4, 2)\n[1] 1\n```\n\nThe author also says\n\n> This makes ifelse a clean way of evaluating lots of simple conditions without needing slow, messy loops.\n\nand it should be noted that for-loops aren't slow; your code is slow [https://youtu.be/TdbweYvwnss](https://youtu.be/TdbweYvwnss)\n\n## Emulated build and test of Bioconductor packages for Linux ARM64\n\n[https://bioconductor.github.io/biocblog/posts/2023-06-09-debug-linux-arm64-on-docker/](https://bioconductor.github.io/biocblog/posts/2023-06-09-debug-linux-arm64-on-docker/)\n\nSource: Mastodon follow\n\nalong with rocker/rstudio arm64 builds [https://hub.docker.com/r/rocker/rstudio/tags](https://hub.docker.com/r/rocker/rstudio/tags)\n\nI've been waiting for this for a while! I got an M1 mac when I started my current job over a year ago and while I can deploy docker images in a cloud solution, I couldn't test them locally. Time to build all the things!\n\n## Feeling rusty: counting characters\n\n[https://josiahparry.com/posts/2023-04-13-counting-chars/](https://josiahparry.com/posts/2023-04-13-counting-chars/)\n\nSource: the Julia post below\n\nJust when you think R is sort of okay at performance - not terrible, but by no means the fastest - Rust goes and shows you that you're wasting your time even trying to keep up and has already gone to lunch after completing all its tasks. This was a great intro to 'Rust as an RCpp replacement' via {rextendr} (a fuller intro from the same author is [https://youtu.be/tRm-Qq2_Ap0](https://youtu.be/tRm-Qq2_Ap0)).\n\n## String Matching in Julia\n\n[https://www.ericekholm.com/posts/string-match-jl/](https://www.ericekholm.com/posts/string-match-jl/)\n\nSource: RT\n\nThis reminds me what I like so much about Julia syntax. Those function definitions are just _so_ clean!\n\n```julia\nfunction compare_strings(x::String, y::String)\n    s = 0\n    for i ∈ eachindex(x)\n        x[i] != y[i] ? break : s += 1\n    end\n    return s\nend\n```\n\nAnd being able to add more definitions just by _writing them out_ is so compact (a full post on that coming soon).\n\nAs for performance, that looks hard to beat. I plan to run the R, Rust, and Julia functions on one machine and see how they compare, but I'm not going to let it get in the way of writing this.\n\n## What’s so special about arrays?\n\n[https://josiahparry.com/posts/2023-06-11-matrix-bug.html](https://josiahparry.com/posts/2023-06-11-matrix-bug.html) \n\nSource: r-contributors slack\n\nI commented in the slack thread but my take on this is that `matrix` is pretty much a vector with a `dim` attribute, so I'm not so surprised that `unclass()` doesn't really \"un-class\" it. `?class` seems to refer to this as an \"implicit class\".\n\n## Effective Spaced Repetition\n\n[https://borretti.me/article/effective-spaced-repetition](https://borretti.me/article/effective-spaced-repetition)\n\nSource: originally via [https://borretti.me/article/depth-first-procrastination](https://borretti.me/article/depth-first-procrastination) via RSS Feed\n\nThis is a longer read, but I'm on board with the principle.\n\n## (Research) Sum Types\n\nTrigger: [Corecursive podcast](https://corecursive.com/048-jared-forsyth-the-reason-for-types/#sum-types-in-reasonml)\n\nI'm digging through some older episodes for a once-a-week rare commute somewhere and this term caught my ear so I decided to look into it a bit and it turns out to be super interesting! I haven't dug through all of these, but this serves as a sort of bookmark for me to come back to.\n\n- [https://en.wikipedia.org/wiki/Algebraic_data_type](https://en.wikipedia.org/wiki/Algebraic_data_type)\n- [https://www.reddit.com/r/ProgrammingLanguages/comments/10jewgp/could_you_explain_why_sum_types_are_so_good/](https://www.reddit.com/r/ProgrammingLanguages/comments/10jewgp/could_you_explain_why_sum_types_are_so_good/)\n- [https://shreevatsa.wordpress.com/2015/01/31/boolean-blindness/](https://shreevatsa.wordpress.com/2015/01/31/boolean-blindness/)\n- [https://serokell.io/blog/algebraic-data-types-in-haskell](https://serokell.io/blog/algebraic-data-types-in-haskell)\n- [https://jrsinclair.com/articles/2019/algebraic-data-types-what-i-wish-someone-had-explained-about-functional-programming/](https://jrsinclair.com/articles/2019/algebraic-data-types-what-i-wish-someone-had-explained-about-functional-programming/)\n- [https://docs.rs/sum_type/latest/sum_type/](https://docs.rs/sum_type/latest/sum_type/)\n- [https://www.youtube.com/watch?v=LafOj_HrxRQ](https://www.youtube.com/watch?v=LafOj_HrxRQ) aaaand now I'm glad I was keeping track of all of these; this is a very timely video on Rust enums that covers some of this topic. Found via [This Week in Rust](https://this-week-in-rust.org/blog/2023/06/14/this-week-in-rust-499/).\n\n## Is That a Compiler Bug?\n\n[https://blog.regehr.org/archives/26](https://blog.regehr.org/archives/26)\n\nAn older post (circa 2010) that I don't recall how I came across. Interesting, though not something I'm likely to encounter myself anytime soon.\n\n## Writing R in VSCode: Working with multiple R sessions\n\n[https://renkun.me/2020/04/14/writing-r-in-vscode-working-with-multiple-r-sessions/](https://renkun.me/2020/04/14/writing-r-in-vscode-working-with-multiple-r-sessions/)\n\nSource: rOpenSci slack\n\nI've been starting to use `tmux` in terminals lately and am really enjoying it, so when a question came up about connecting a VSCode session to it (which could be remotely connected) my interest was piqued. The linked post might be a solution to that, though I'm yet to try it myself. \n\n## List one task, do it, cross it out\n\n[https://www.oliverburkeman.com/onething](https://www.oliverburkeman.com/onething)\n\nSource: can't recall... HN? This echos a lot of what the 'minimalist' folks are saying about organising and cleaning; trying to decide which of the dozen semi-important things you need to work on often leads to doing none of them, but by choosing just one you know exactly what you need to do.\n\n## Finish your projects\n\n[https://github.com/readme/guides/finish-your-projects](https://github.com/readme/guides/finish-your-projects)\n\nSource: TLDR newsletter\n\nSimilar to the above article in terms of message; pick something and do it.\n\n## Iterating on Testing in Rust\n\n[https://epage.github.io/blog/2023/06/iterating-on-test/](https://epage.github.io/blog/2023/06/iterating-on-test/)\n\nSource: HN\n\nGood overview of how tests work in Rust.\n\n## Row relational operations with slice()\n\n[https://yjunechoe.github.io/posts/2023-06-11-row-relational-operations/](https://yjunechoe.github.io/posts/2023-06-11-row-relational-operations/)\n\nSource: RWeekly\n\nWinners: `slice()` as a `filter()` being able use row indices with `cond + 1`; `outer()` to get non-recycling addition. A very in-depth article that goes through lots of uses of `slice()`.\n\n## On updating a chat assistant app for the RStudio IDE\n\n- [https://samuelenrique.com/posts/2023-06-02-updating-gptstudio/](https://samuelenrique.com/posts/2023-06-02-updating-gptstudio/)\n\nSource: RWeekly\n\nThe auto-updating streaming output is very cool! I wonder if there's an open streaming resource I could use to try this?\n\nThis also demonstrates adding 'copy' button to code blocks which I don't have on my blog - perhaps I could? They used\n\n``` \n$('pre').each(function() {\n  const $codeChunk = $(this);\n  const $copyButton = $('<button>').text('Copy');\n  $codeChunk.prepend($copyButton);\n\n  $copyButton.on('click', function() {\n    const codeText = $codeChunk.text();\n    navigator.clipboard.writeText(codeText);\n  });\n});\n```\n\n## A terminal case of Linux\n\n[https://fasterthanli.me/articles/a-terminal-case-of-linux](https://fasterthanli.me/articles/a-terminal-case-of-linux)\n\nSource: ? (Mastodon?)\n\nI don't recall where or why I found this 2021 article but as usual, Amos goes reeeeally deep into some Rust code (and libc / Linux in this case). I got hooked on these posts when (re-)doing AoC 2022 and for [day 1](https://fasterthanli.me/series/advent-of-code-2022/part-1) Amos went mile-deep (25mins read) on Rust in general when the problem to be solved was \"straightforward\".\n\n## Friction, Baby\n\n[https://tedium.co/2023/06/10/productivity-friction-theory/](https://tedium.co/2023/06/10/productivity-friction-theory/)\n\nSource: HN\n\nThis makes a lot of sense to me and made me consider a lot of the patterns (anti-, dark-, or otherwise) I see in my media consumption. The goal of this micro blog is to have as little friction as possible when publishing some markdown text. Sometimes, some interactions could use a bit more friction.\n",
				"date_published": "2023-06-16T13:20:20+09:30",
				"url": "https://jcarroll.xyz/2023/06/14/around-the-web.html",
				"tags": ["Around the web"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/05/12/fizzbuzz-without-an.html",
				"title": "FizzBuzz without an if",
				"content_html": "<p>Apparently using an <code>if</code> to solve <a href=\"https://en.wikipedia.org/wiki/Fizz_buzz\">FizzBuzz</a> is a sign that you&rsquo;re <a href=\"https://youtu.be/GfNBZ7awHGo?t=545\">not a great programmer</a>&hellip; Well, that&rsquo;s how I would have done it :-(</p>\n<p>I wanted to see what the <code>map</code> alternative looked like, and I found <a href=\"https://builtin.com/software-engineering-perspectives/fizzbuzz-python#:~:text=Programming%20with%20Mosh-,4.%20LAMBDA,-Another%20method%20we\">this python example</a></p>\n<pre tabindex=\"0\"><code>print(*map(lambda i: 'Fizz'*(not i%3)+'Buzz'*(not i%5) or i, range(1,101)),sep='\\n')\r\n</code></pre><p>What&rsquo;s interesting to me is that there&rsquo;s an <code>or</code> in there - if neither of the modulo operations match, then the resulting string is empty, and that can be used in an <code>or</code> (failing the left-hand side). Whoa! That doesn&rsquo;t work in R because characters can&rsquo;t be used in logical operations</p>\n<pre tabindex=\"0\"><code>&quot;&quot; | 2\r\nError in &quot;&quot; | 2 : \r\n  operations are possible only for numeric, logical or complex types\r\n</code></pre><p>The rest I can more or less reproduce in R, using <code>strrep</code> in place of the infix <code>*</code> used for &lsquo;repeat string&rsquo;</p>\n<pre tabindex=\"0\"><code>sapply(1:20, \r\n       \\(x) paste0(\r\n         strrep(&quot;Fizz&quot;, x %% 3 == 0), \r\n         strrep(&quot;Buzz&quot;, x %% 5 == 0), \r\n         strrep(x, x %% 3 != 0 &amp;&amp; x %% 5 != 0)\r\n       )\r\n)\r\n [1] &quot;1&quot;        &quot;2&quot;        &quot;Fizz&quot;     &quot;4&quot;        &quot;Buzz&quot;     &quot;Fizz&quot;    \r\n [7] &quot;7&quot;        &quot;8&quot;        &quot;Fizz&quot;     &quot;Buzz&quot;     &quot;11&quot;       &quot;Fizz&quot;    \r\n[13] &quot;13&quot;       &quot;14&quot;       &quot;FizzBuzz&quot; &quot;16&quot;       &quot;17&quot;       &quot;Fizz&quot;    \r\n[19] &quot;19&quot;       &quot;Buzz&quot;    \r\n</code></pre><p>This also requires the additional comparison for when the number is a divisor of neither number, so kudos to python for working nicer in that case.</p>\n<p>Is there an even better way to solve this without an <code>if</code>?</p>\n",
				"content_text": "Apparently using an `if` to solve [FizzBuzz](https://en.wikipedia.org/wiki/Fizz_buzz) is a sign that you're [not a great programmer](https://youtu.be/GfNBZ7awHGo?t=545)... Well, that's how I would have done it :-(\r\n\r\nI wanted to see what the `map` alternative looked like, and I found [this python example](https://builtin.com/software-engineering-perspectives/fizzbuzz-python#:~:text=Programming%20with%20Mosh-,4.%20LAMBDA,-Another%20method%20we)\r\n\r\n```\r\nprint(*map(lambda i: 'Fizz'*(not i%3)+'Buzz'*(not i%5) or i, range(1,101)),sep='\\n')\r\n```\r\n\r\nWhat's interesting to me is that there's an `or` in there - if neither of the modulo operations match, then the resulting string is empty, and that can be used in an `or` (failing the left-hand side). Whoa! That doesn't work in R because characters can't be used in logical operations\r\n\r\n```\r\n\"\" | 2\r\nError in \"\" | 2 : \r\n  operations are possible only for numeric, logical or complex types\r\n```\r\n\r\nThe rest I can more or less reproduce in R, using `strrep` in place of the infix `*` used for 'repeat string'\r\n\r\n```\r\nsapply(1:20, \r\n       \\(x) paste0(\r\n         strrep(\"Fizz\", x %% 3 == 0), \r\n         strrep(\"Buzz\", x %% 5 == 0), \r\n         strrep(x, x %% 3 != 0 && x %% 5 != 0)\r\n       )\r\n)\r\n [1] \"1\"        \"2\"        \"Fizz\"     \"4\"        \"Buzz\"     \"Fizz\"    \r\n [7] \"7\"        \"8\"        \"Fizz\"     \"Buzz\"     \"11\"       \"Fizz\"    \r\n[13] \"13\"       \"14\"       \"FizzBuzz\" \"16\"       \"17\"       \"Fizz\"    \r\n[19] \"19\"       \"Buzz\"    \r\n```\r\n\r\nThis also requires the additional comparison for when the number is a divisor of neither number, so kudos to python for working nicer in that case.\r\n\r\nIs there an even better way to solve this without an `if`?\n",
				"date_published": "2023-05-12T16:11:17+09:30",
				"url": "https://jcarroll.xyz/2023/05/12/fizzbuzz-without-an.html",
				"tags": ["R"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/04/12/finished-reading-bullshit.html",
				"title": "Finished reading: Bullshit Jobs by David Graeber 📚",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9780241267363\">Bullshit Jobs</a> by David Graeber 📚</p>\n<p>I&rsquo;ll preface this with my sympathy for my colleagues and friends currently struggling to find work after corporate layoffs. This book makes their plight even worse as it details people who <em>do</em> have jobs, but don&rsquo;t believe they should as they don&rsquo;t feel they offer any benefit to society. This is the (much) expanded version of a <a href=\"https://www.atlasofplaces.com/essays/on-the-phenomenon-of-bullshit-jobs/\">short essay</a> backed up with references and sidenotes.</p>\n<p>I&rsquo;ve puzzled for a while at the notion of aiming for &ldquo;100% employment&rdquo; both from the perspective that &ldquo;productivity should be improving with technology, so do we still <em>need</em> those jobs?&rdquo; and the more social &ldquo;is the goal really for everyone to be working more?&rdquo; This book spells out those arguments in great detail and points out that, if all was going well, we could all be working 15 hour weeks with the rest of the time left to do whatever we want.</p>\n<p>I don&rsquo;t think I&rsquo;m spoiling much to say that the conclusion of the book leads towards a universal basic income (not without its own issues and complexities) being a way to even the field - people not needing to take on work they really don&rsquo;t want to do or feel they can&rsquo;t leave because the only alternative is poverty and homelessness. The notion that we could take what we spend torturing the poor (by making them apply for housing, food-stamps, assistance, &hellip;, including paying the people who implement those programs, those who manage those people, and the infrastructure to support all of them) and just give everyone enough money to survive is a radical shift, and I suspect too hard to sell to governments who still take pride in having that many people &ldquo;working&rdquo; on helping others (despite most not actually getting any help).</p>\n<p>I don&rsquo;t feel that my own work is as futile as some of the testimonies, but I do see a huge inefficiency of every company hiring someone (or a team of people) to do the exact same thing for <em>their</em> data. The sheer amount of duplication that happens across companies is surely something that wouldn&rsquo;t exist if money weren&rsquo;t such a driver of why companies do what they do.</p>\n<p>The brief mention of open-source work surprised me - <a href=\"https://micro.blog/books/9780578675862\">Working in Public</a> details how poorly this is supported, but this book highlights that when all of the &ldquo;fun&rdquo; work of building tools is open source, no one builds the &ldquo;core&rdquo; pieces, so a lot of companies end up spending a lot of effort &ldquo;duct taping&rdquo; those free, open-source solutions together.</p>\n<p>This book also dives into the political landscape (mostly in the US but also elsewhere) and articulates why it&rsquo;s all washed together now (and doomed, no matter which side you&rsquo;re on).</p>\n<p>As for what I didn&rsquo;t like about this book - the footnotes take up so much space (sometimes an entire page themselves) that they&rsquo;ve been moved to the end of the book, but they are so frequent (sometimes one per sentence) that I read the entire book flipping back and forth between them. I had to use two bookmarks. This was extremely frustrating, particularly when the footnotes were of little importance. Many had URLs which I haven&rsquo;t checked, but are probably stale. Some were interesting, but this made the book much harder to read.</p>\n<p>Definitely an interesting read, but if you hated society before reading it (I did) then you&rsquo;re not going to be happier afterwards (I&rsquo;m not).</p>\n",
				"content_text": "Finished reading: [Bullshit Jobs](https://micro.blog/books/9780241267363) by David Graeber 📚\r\n\r\nI'll preface this with my sympathy for my colleagues and friends currently struggling to find work after corporate layoffs. This book makes their plight even worse as it details people who _do_ have jobs, but don't believe they should as they don't feel they offer any benefit to society. This is the (much) expanded version of a [short essay](https://www.atlasofplaces.com/essays/on-the-phenomenon-of-bullshit-jobs/) backed up with references and sidenotes.\r\n\r\nI've puzzled for a while at the notion of aiming for \"100% employment\" both from the perspective that \"productivity should be improving with technology, so do we still _need_ those jobs?\" and the more social \"is the goal really for everyone to be working more?\" This book spells out those arguments in great detail and points out that, if all was going well, we could all be working 15 hour weeks with the rest of the time left to do whatever we want.\r\n\r\nI don't think I'm spoiling much to say that the conclusion of the book leads towards a universal basic income (not without its own issues and complexities) being a way to even the field - people not needing to take on work they really don't want to do or feel they can't leave because the only alternative is poverty and homelessness. The notion that we could take what we spend torturing the poor (by making them apply for housing, food-stamps, assistance, ..., including paying the people who implement those programs, those who manage those people, and the infrastructure to support all of them) and just give everyone enough money to survive is a radical shift, and I suspect too hard to sell to governments who still take pride in having that many people \"working\" on helping others (despite most not actually getting any help).\r\n\r\nI don't feel that my own work is as futile as some of the testimonies, but I do see a huge inefficiency of every company hiring someone (or a team of people) to do the exact same thing for *their* data. The sheer amount of duplication that happens across companies is surely something that wouldn't exist if money weren't such a driver of why companies do what they do. \r\n\r\nThe brief mention of open-source work surprised me - [Working in Public](https://micro.blog/books/9780578675862) details how poorly this is supported, but this book highlights that when all of the \"fun\" work of building tools is open source, no one builds the \"core\" pieces, so a lot of companies end up spending a lot of effort \"duct taping\" those free, open-source solutions together.\r\n\r\nThis book also dives into the political landscape (mostly in the US but also elsewhere) and articulates why it's all washed together now (and doomed, no matter which side you're on).\r\n\r\nAs for what I didn't like about this book - the footnotes take up so much space (sometimes an entire page themselves) that they've been moved to the end of the book, but they are so frequent (sometimes one per sentence) that I read the entire book flipping back and forth between them. I had to use two bookmarks. This was extremely frustrating, particularly when the footnotes were of little importance. Many had URLs which I haven't checked, but are probably stale. Some were interesting, but this made the book much harder to read.\r\n\r\nDefinitely an interesting read, but if you hated society before reading it (I did) then you're not going to be happier afterwards (I'm not).\n",
				"date_published": "2023-04-12T10:10:58+09:30",
				"url": "https://jcarroll.xyz/2023/04/12/finished-reading-bullshit.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/04/12/finished-reading-soonish.html",
				"title": "Finished reading: Soonish by Kelly and Zach Weinersmith 📚",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9781846149009\">Soonish</a> by Kelly and Zach Weinersmith 📚</p>\n<p>Another &lsquo;prominently featured on a library shelf&rsquo; find that caught my attention partly because of the authors' name - I&rsquo;ve spent many hours reading <a href=\"https://www.smbc-comics.com/\">Saturday Morning Breakfast Cereal</a> and there was definitely a time during my PhD when reading the day&rsquo;s new comics (along with <a href=\"https://xkcd.com/\">XKCD</a> and others) was just part of my routine.</p>\n<p>This condenses what was surely a lot of research down into digestible summaries - punctuated with humour - about how some new technologies might change the world. It&rsquo;s almost a shame that it&rsquo;s not longer; I suspect a <em>lot</em> of material had to be cut just to get it down to the already sizeable read it is.</p>\n<p>This is approachable for anyone not already familiar with these fields, and the authors use some clever analogies to explain the concepts.</p>\n<p>Worth a read, for sure. It will be interesting to see how much of it plays out as they predict.</p>\n",
				"content_text": "Finished reading: [Soonish](https://micro.blog/books/9781846149009) by Kelly and Zach Weinersmith 📚\r\n\r\nAnother 'prominently featured on a library shelf' find that caught my attention partly because of the authors' name - I've spent many hours reading [Saturday Morning Breakfast Cereal](https://www.smbc-comics.com/) and there was definitely a time during my PhD when reading the day's new comics (along with [XKCD](https://xkcd.com/) and others) was just part of my routine.\r\n\r\nThis condenses what was surely a lot of research down into digestible summaries - punctuated with humour - about how some new technologies might change the world. It's almost a shame that it's not longer; I suspect a *lot* of material had to be cut just to get it down to the already sizeable read it is.\r\n\r\nThis is approachable for anyone not already familiar with these fields, and the authors use some clever analogies to explain the concepts. \r\n\r\nWorth a read, for sure. It will be interesting to see how much of it plays out as they predict.\n",
				"date_published": "2023-04-12T09:40:51+09:30",
				"url": "https://jcarroll.xyz/2023/04/12/finished-reading-soonish.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/04/12/finished-reading-version.html",
				"title": "Finished reading: Version Zero by David Yoon 📚",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9780593190371\">Version Zero</a> by David Yoon 📚</p>\n<p>I thoroughly enjoyed this book. Credit to my local librarians who placed it prominently on a shelf I was casually browsing. The author does a great job of slowly building up the characters and turning up the dial in the last third of the story to the point that I really didn&rsquo;t want to stop reading it.</p>\n<p>The plot is highly relevant to modern social network / business issues and there are some not-so-subtle allusions to the current largest big tech companies.</p>\n<p>I <a href=\"https://jcarroll.com.au/2023/03/31/version-zero-easter-eggs/\">wrote about the easter egg code on my main blog</a> and have heard back from the person who wrote it (update coming soon).</p>\n<p>Definitely recommend. Once you&rsquo;re finished, go back and re-read the first few pages.</p>\n",
				"content_text": "Finished reading: [Version Zero](https://micro.blog/books/9780593190371) by David Yoon 📚\r\n\r\nI thoroughly enjoyed this book. Credit to my local librarians who placed it prominently on a shelf I was casually browsing. The author does a great job of slowly building up the characters and turning up the dial in the last third of the story to the point that I really didn't want to stop reading it. \r\n\r\nThe plot is highly relevant to modern social network / business issues and there are some not-so-subtle allusions to the current largest big tech companies. \r\n\r\nI [wrote about the easter egg code on my main blog](https://jcarroll.com.au/2023/03/31/version-zero-easter-eggs/) and have heard back from the person who wrote it (update coming soon).\r\n\r\nDefinitely recommend. Once you're finished, go back and re-read the first few pages.\n",
				"date_published": "2023-04-12T09:32:53+09:30",
				"url": "https://jcarroll.xyz/2023/04/12/finished-reading-version.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/03/12/finished-reading-eastern.html",
				"title": "Finished reading: Eastern Standard Tribe by Cory Doctorow 📚",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9780007327942\">Eastern Standard Tribe</a> by Cory Doctorow 📚</p>\n<p>I found this one browsing the shelves at the library and recognised the name from my days reading <a href=\"https://boingboing.net/\">boingboing.net</a> (and the <a href=\"https://www.explainxkcd.com/wiki/index.php/Category:Comics_featuring_Cory_Doctorow\">numerous mentions</a> in XKCD, e.g. <a href=\"https://xkcd.com/239/\">this one</a>). I didn&rsquo;t hate this book, but the writing style did remind me a lot of <a href=\"https://micro.blog/books/9780141924045?title=Snow+Crash&amp;author=Neal+Stephenson&amp;cover_id=68854\">Snow Crash</a> (which I didn&rsquo;t like) with all the (unnecessary?) techy/futuristic names for things and places that were only named to highlight how techy/futuristic the world was portrayed to be. The story itself was okay but never <em>really</em> seemed to go anywhere.</p>\n<p>Not a book I&rsquo;d steer away from (I actually gave away my purchased copy of Snow Crash because I don&rsquo;t ever intend to read it again) but not something I&rsquo;ll steer people towards, either.</p>\n",
				"content_text": "Finished reading: [Eastern Standard Tribe](https://micro.blog/books/9780007327942) by Cory Doctorow 📚\r\n\r\nI found this one browsing the shelves at the library and recognised the name from my days reading [boingboing.net](https://boingboing.net/) (and the [numerous mentions](https://www.explainxkcd.com/wiki/index.php/Category:Comics_featuring_Cory_Doctorow) in XKCD, e.g. [this one](https://xkcd.com/239/)). I didn't hate this book, but the writing style did remind me a lot of [Snow Crash](https://micro.blog/books/9780141924045?title=Snow+Crash&author=Neal+Stephenson&cover_id=68854) (which I didn't like) with all the (unnecessary?) techy/futuristic names for things and places that were only named to highlight how techy/futuristic the world was portrayed to be. The story itself was okay but never *really* seemed to go anywhere.\r\n\r\nNot a book I'd steer away from (I actually gave away my purchased copy of Snow Crash because I don't ever intend to read it again) but not something I'll steer people towards, either.\n",
				"date_published": "2023-03-12T13:20:32+09:30",
				"url": "https://jcarroll.xyz/2023/03/12/finished-reading-eastern.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/03/12/finished-reading-chess.html",
				"title": "Finished reading: 500 Chess Questions Answered by Andrew Soltis 📚",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9781849947596\">500 Chess Questions Answered</a> by Andrew Soltis 📚</p>\n<p>Not a novel and not a textbook, but it took long enough to read that it deserves mention. This is full of valuable tips and notes, but aside from reading it cover to cover, it doesn&rsquo;t serve much use as a reference. There were a few points about calculating that I can incorporate into my games, but otherwise, it seems to be focused at beginners despite having some pretty complex examples.</p>\n<p>If you&rsquo;re new to the game, it&rsquo;s worth a read.</p>\n<p>I&rsquo;m jonocarroll on lichess.org and chess.com if anyone wants a game. My Elo is currently around 1100 (rapid).</p>\n",
				"content_text": "Finished reading: [500 Chess Questions Answered](https://micro.blog/books/9781849947596) by Andrew Soltis 📚\r\n\r\nNot a novel and not a textbook, but it took long enough to read that it deserves mention. This is full of valuable tips and notes, but aside from reading it cover to cover, it doesn't serve much use as a reference. There were a few points about calculating that I can incorporate into my games, but otherwise, it seems to be focused at beginners despite having some pretty complex examples.\r\n\r\nIf you're new to the game, it's worth a read.\r\n\r\nI'm jonocarroll on lichess.org and chess.com if anyone wants a game. My Elo is currently around 1100 (rapid).\n",
				"date_published": "2023-03-12T13:09:11+09:30",
				"url": "https://jcarroll.xyz/2023/03/12/finished-reading-chess.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/03/05/220456.html",
				"title": "Finished reading: The Apocalypse Seven by Gene Doucette 📚",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9780358418948\">The Apocalypse Seven</a> by Gene Doucette 📚</p>\n<p>As soon as I finished <a href=\"https://jcarroll.xyz/2023/03/05/finished-reading-the.html\">The Spaceship Next Door</a> I had a look for the author&rsquo;s other books. I got mixed up between a couple and I thought this one was the sequel. It&rsquo;s not, but I borrowed a copy anyway.</p>\n<p>This is a different story, but told with the same narrative style that again feels distinct from most other sci-fi I&rsquo;ve read. Still very enjoyable; I finished this one in just a few evenings.</p>\n<p>My only gripe with this book was that the author clearly had a familiarity with the area (they note that they spent quite a bit of time there in real life) but I&rsquo;ve never been to <a href=\"https://www.google.com/maps/search/Harvard+University,+Cambridge,+MA,+USA/@42.3733004,-71.1183839,14.64z\">Cambridge</a> and so the frequent specific references to real streets and landmarks were all lost on me. Despite that, I could certainly follow along and enjoyed the story.</p>\n<p>Another fun read. I&rsquo;m looking forward to getting a copy of the actual sequel to that first book.</p>\n",
				"content_text": "Finished reading: [The Apocalypse Seven](https://micro.blog/books/9780358418948) by Gene Doucette 📚\r\n\r\nAs soon as I finished [The Spaceship Next Door](https://jcarroll.xyz/2023/03/05/finished-reading-the.html) I had a look for the author's other books. I got mixed up between a couple and I thought this one was the sequel. It's not, but I borrowed a copy anyway.\r\n\r\nThis is a different story, but told with the same narrative style that again feels distinct from most other sci-fi I've read. Still very enjoyable; I finished this one in just a few evenings. \r\n\r\nMy only gripe with this book was that the author clearly had a familiarity with the area (they note that they spent quite a bit of time there in real life) but I've never been to [Cambridge](https://www.google.com/maps/search/Harvard+University,+Cambridge,+MA,+USA/@42.3733004,-71.1183839,14.64z) and so the frequent specific references to real streets and landmarks were all lost on me. Despite that, I could certainly follow along and enjoyed the story.\r\n\r\nAnother fun read. I'm looking forward to getting a copy of the actual sequel to that first book.\n",
				"date_published": "2023-03-05T21:04:56+09:30",
				"url": "https://jcarroll.xyz/2023/03/05/220456.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/03/05/215624.html",
				"title": "Finished reading: The Phoenix Project by Gene Kim 📚",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9781942788294\">The Phoenix Project</a> by Gene Kim 📚</p>\n<p>I was on the fence about this one; I&rsquo;ve managed a tech team before but I&rsquo;m not currently in charge of anyone so I&rsquo;ve about had my fill of &lsquo;mangement&rsquo; information books. With that said, this is a novel that tells a story which happens to describe some best practices and approaches for running (or being in) a tech team.</p>\n<p>The part I really like is <a href=\"https://itrevolution.com/articles/the-three-ways-principles-underpinning-devops/\">The Three Ways</a> principles and I think there&rsquo;s insight there for anyone working in a project of any kind. The story makes a lot of parallels between manufacturing physical goods and &lsquo;knowledge work&rsquo;, focussing on bottlenecks, and planning, and if you haven&rsquo;t thought about your project in that way then I&rsquo;d say definitely pick up this book. &ldquo;Go fast and break things&rdquo; runs counter to a lot of that, but eventually you&rsquo;re going to need to build something a bit more robust, and some planning will be of great benefit.</p>\n<p>The writing itself felt a little forced, but perhaps I just don&rsquo;t deal with people who talk like that (?).</p>\n<p>If you&rsquo;re near the top of a tech-focussed team, I recommend you have a read. There might not be anything new to you in there, but if there is, it&rsquo;ll be useful.</p>\n",
				"content_text": "Finished reading: [The Phoenix Project](https://micro.blog/books/9781942788294) by Gene Kim 📚\r\n\r\nI was on the fence about this one; I've managed a tech team before but I'm not currently in charge of anyone so I've about had my fill of 'mangement' information books. With that said, this is a novel that tells a story which happens to describe some best practices and approaches for running (or being in) a tech team.\r\n\r\nThe part I really like is [The Three Ways](https://itrevolution.com/articles/the-three-ways-principles-underpinning-devops/) principles and I think there's insight there for anyone working in a project of any kind. The story makes a lot of parallels between manufacturing physical goods and 'knowledge work', focussing on bottlenecks, and planning, and if you haven't thought about your project in that way then I'd say definitely pick up this book. \"Go fast and break things\" runs counter to a lot of that, but eventually you're going to need to build something a bit more robust, and some planning will be of great benefit.\r\n\r\nThe writing itself felt a little forced, but perhaps I just don't deal with people who talk like that (?).\r\n\r\nIf you're near the top of a tech-focussed team, I recommend you have a read. There might not be anything new to you in there, but if there is, it'll be useful.\n",
				"date_published": "2023-03-05T20:56:24+09:30",
				"url": "https://jcarroll.xyz/2023/03/05/215624.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/03/05/finished-reading-jellyfish.html",
				"title": "Finished reading: Jellyfish Age Backwards by Nicklas Brendborg 📚",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9781529387926\">Jellyfish Age Backwards</a> by Nicklas Brendborg 📚</p>\n<p>Another recommendation from social media, if I recall. This had a lot of really interesting information about aging across species, some things we&rsquo;ve discovered that influence it, and some things that don&rsquo;t. The focus extended beyond just humans, so this was a really nice broad exploration with neat comparisons and details about unique species.</p>\n<p>Nothing too complex in there, but well worth a read.</p>\n",
				"content_text": "Finished reading: [Jellyfish Age Backwards](https://micro.blog/books/9781529387926) by Nicklas Brendborg 📚\r\n\r\nAnother recommendation from social media, if I recall. This had a lot of really interesting information about aging across species, some things we've discovered that influence it, and some things that don't. The focus extended beyond just humans, so this was a really nice broad exploration with neat comparisons and details about unique species.\r\n\r\nNothing too complex in there, but well worth a read.\n",
				"date_published": "2023-03-05T20:45:44+09:30",
				"url": "https://jcarroll.xyz/2023/03/05/finished-reading-jellyfish.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/03/05/finished-reading-the.html",
				"title": "Finished reading: The Spaceship Next Door by Gene Doucette 📚",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9781328567543\">The Spaceship Next Door</a> by Gene Doucette 📚</p>\n<p>I like to mix in some fiction between more serious topics, and someone recommended this. I couldn&rsquo;t find a physical copy anywhere so I tried out my library&rsquo;s ebook offering (<a href=\"https://www.overdrive.com/apps/libby\">Libby</a>). I&rsquo;d have preferred to use my new Kindle Scribe, but this worked okay enough on my phone.</p>\n<p>The author has a refreshing narrative style for sci-fi; something I can&rsquo;t quite put my finger on, but it was a very enjoyable read. Some twists and turns and none of it felt too forced or strayed too far from the main storyline. I&rsquo;m not quite sure it&rsquo;s the kind of story I&rsquo;d come back to again and again but I genuinely enjoyed it and have a hold on a physical copy of the sequel already (plus another from the author).</p>\n<p>Thumbs up, worth a read.</p>\n",
				"content_text": "Finished reading: [The Spaceship Next Door](https://micro.blog/books/9781328567543) by Gene Doucette 📚\r\n\r\nI like to mix in some fiction between more serious topics, and someone recommended this. I couldn't find a physical copy anywhere so I tried out my library's ebook offering ([Libby](https://www.overdrive.com/apps/libby)). I'd have preferred to use my new Kindle Scribe, but this worked okay enough on my phone.\r\n\r\nThe author has a refreshing narrative style for sci-fi; something I can't quite put my finger on, but it was a very enjoyable read. Some twists and turns and none of it felt too forced or strayed too far from the main storyline. I'm not quite sure it's the kind of story I'd come back to again and again but I genuinely enjoyed it and have a hold on a physical copy of the sequel already (plus another from the author).\r\n\r\nThumbs up, worth a read.\n",
				"date_published": "2023-03-05T20:41:05+09:30",
				"url": "https://jcarroll.xyz/2023/03/05/finished-reading-the.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/03/05/finished-reading-human.html",
				"title": "Finished reading: 10% Human: How Your Body’s Microbes Hold The Key To Health And Happiness by Alanna Collen 📚",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9780007584048\">10% Human: How Your Body’s Microbes Hold The Key To Health And Happiness</a> by Alanna Collen 📚</p>\n<p>I had this one on my shelf for a while and I&rsquo;m very happy I finally got around to reading it. I knew (roughly) that we have a vast microbiome within our gut, but I hadn&rsquo;t really seen most of the details about just how impactful we now know that to be to our health. In particular, I wasn&rsquo;t aware of the connection to eating fiber; my understanding only extended as far as fiber being something indigestible that helped keep things moving right. As it turns out, there&rsquo;s a whole lot more to it, and a lot involves gut bacteria.</p>\n<p>Sure enough, I&rsquo;ve vastly increased my fiber intake (gradually) after reading this. I&rsquo;m also very curious about what we might be able to learn about the intersection of autoimmune (and other) diseases and the microbiome.</p>\n<p>I&rsquo;ve since been recommended a slightly newer <a href=\"https://micro.blog/books/9780062368621\">book</a> on this topic which I now have a copy of.</p>\n<p>Highly recommended - if you read this and don&rsquo;t increase your fiber intake / support your microbiome, I&rsquo;ll be surprised.</p>\n",
				"content_text": "Finished reading: [10% Human: How Your Body’s Microbes Hold The Key To Health And Happiness](https://micro.blog/books/9780007584048) by Alanna Collen 📚\n\nI had this one on my shelf for a while and I'm very happy I finally got around to reading it. I knew (roughly) that we have a vast microbiome within our gut, but I hadn't really seen most of the details about just how impactful we now know that to be to our health. In particular, I wasn't aware of the connection to eating fiber; my understanding only extended as far as fiber being something indigestible that helped keep things moving right. As it turns out, there's a whole lot more to it, and a lot involves gut bacteria.\n\nSure enough, I've vastly increased my fiber intake (gradually) after reading this. I'm also very curious about what we might be able to learn about the intersection of autoimmune (and other) diseases and the microbiome.\n\nI've since been recommended a slightly newer [book](https://micro.blog/books/9780062368621) on this topic which I now have a copy of.\n\nHighly recommended - if you read this and don't increase your fiber intake / support your microbiome, I'll be surprised.\n",
				"date_published": "2023-03-05T20:34:13+09:30",
				"url": "https://jcarroll.xyz/2023/03/05/finished-reading-human.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/03/05/finished-reading-once.html",
				"title": "Finished reading: Once Upon an Algorithm by Martin Erwig 📚",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9780262545297\">Once Upon an Algorithm</a> by Martin Erwig 📚</p>\n<p>I liked the premise of this book - algorithms taught with examples from classic children&rsquo;s tales. I didn&rsquo;t finish it, however - it was just too wordy (I got about halfway through). In fairness, I started with a very similar approach to <a href=\"https://beyondspreadsheetswithr.com/\">my own book</a> which for a while had a working title of &ldquo;The R Handyman&rdquo; with allusions to power tools, tool belts, hand tools, etc&hellip; but the metaphors felt too forced after a while and we changed tack to focus on the programming without them.</p>\n<p>What I did read was well presented and went into some decent detail about software design, algorithms, and complexity. At some point, though, I think some sort of implementations were necessary to bring it all together, and this book lacked that.</p>\n<p>Worth a try, but if you&rsquo;re really into algorithms I&rsquo;d say get a book with implementations (e.g. <a href=\"https://jcarroll.xyz/2023/01/29/finished-reading-the.html\">this one</a>).</p>\n",
				"content_text": "Finished reading: [Once Upon an Algorithm](https://micro.blog/books/9780262545297) by Martin Erwig 📚\r\n\r\nI liked the premise of this book - algorithms taught with examples from classic children's tales. I didn't finish it, however - it was just too wordy (I got about halfway through). In fairness, I started with a very similar approach to [my own book](https://beyondspreadsheetswithr.com/) which for a while had a working title of \"The R Handyman\" with allusions to power tools, tool belts, hand tools, etc... but the metaphors felt too forced after a while and we changed tack to focus on the programming without them.\r\n\r\nWhat I did read was well presented and went into some decent detail about software design, algorithms, and complexity. At some point, though, I think some sort of implementations were necessary to bring it all together, and this book lacked that.\r\n\r\nWorth a try, but if you're really into algorithms I'd say get a book with implementations (e.g. [this one](https://jcarroll.xyz/2023/01/29/finished-reading-the.html)).\n",
				"date_published": "2023-03-05T20:22:04+09:30",
				"url": "https://jcarroll.xyz/2023/03/05/finished-reading-once.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/03/01/finished-reading-the.html",
				"title": "Finished reading: The Book of Why by Judea Pearl 📚",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9780241242643\">The Book of Why</a> by Judea Pearl 📚</p>\n<p>This was the topic of a book club at work but I&rsquo;m really glad I read it. My scepticism going in was probably typical of someone not all that familiar with causal analysis, believing that we can just throw all the variables at a regression model and get an answer - anything uncorrelated will have a small coefficient and we can dispose of it. This book - while it takes a slightly arrogant/high-and-mighty approach to getting there - carefully explains that this approach works <em>only</em> if there is no dependency between the variables. This is, of course, structured into the regression model assumptions that the covariates are &ldquo;<em>independent</em> and identically distributed&rdquo; (i.i.d.) but who checks assumptions? It goes into depth about the different ways that covariates can be connected; how to route around some of them; and how to figure out which ones to include.</p>\n<p>Some of the examples seemed a bit too strawman for my liking, but I do think the general foundation is pretty solid. It&rsquo;s a bit odd to have what should really be a textbook in causal analysis as a prose-heavy combination of history and wordy examples, but then again I can&rsquo;t say I&rsquo;d have picked up the textbook and read it cover-to-cover like this.</p>\n<p>Overall, I think this should be on any data scientist&rsquo;s reading list at some point. I have a bunch of follow-on reading to get through now, but I&rsquo;m much less likely to make the simple errors in my own statistical analyses (even if I do need to find an analyst who <em>can</em> work it out).</p>\n",
				"content_text": "Finished reading: [The Book of Why](https://micro.blog/books/9780241242643) by Judea Pearl 📚\r\n\r\nThis was the topic of a book club at work but I'm really glad I read it. My scepticism going in was probably typical of someone not all that familiar with causal analysis, believing that we can just throw all the variables at a regression model and get an answer - anything uncorrelated will have a small coefficient and we can dispose of it. This book - while it takes a slightly arrogant/high-and-mighty approach to getting there - carefully explains that this approach works _only_ if there is no dependency between the variables. This is, of course, structured into the regression model assumptions that the covariates are \"*independent* and identically distributed\" (i.i.d.) but who checks assumptions? It goes into depth about the different ways that covariates can be connected; how to route around some of them; and how to figure out which ones to include.\r\n\r\nSome of the examples seemed a bit too strawman for my liking, but I do think the general foundation is pretty solid. It's a bit odd to have what should really be a textbook in causal analysis as a prose-heavy combination of history and wordy examples, but then again I can't say I'd have picked up the textbook and read it cover-to-cover like this.\r\n\r\nOverall, I think this should be on any data scientist's reading list at some point. I have a bunch of follow-on reading to get through now, but I'm much less likely to make the simple errors in my own statistical analyses (even if I do need to find an analyst who _can_ work it out).\n",
				"date_published": "2023-03-01T17:57:26+09:30",
				"url": "https://jcarroll.xyz/2023/03/01/finished-reading-the.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/01/29/finished-reading-the.html",
				"title": "Finished reading: The Self-Taught Computer Scientist by Cory Althoff 📚",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9781119724339\">The Self-Taught Computer Scientist</a> by Cory Althoff 📚</p>\n<p>This is the book I wish I&rsquo;d read before doing <a href=\"https://adventofcode.com/2022\">Advent of Code</a> - a full blog post on that will eventually be on my <a href=\"https://jcarroll.com.au\">main blog</a>; I finished both parts of all 25 exercises in (strictly) base R, and am more than halfway through re-doing all of them in Rust. I was surprised at how much computer science was needed to solve these, but I did enjoy what I learned along the way, so actually reading up on some of it seemed like a good idea.</p>\n<p>This book is the follow-on from <a href=\"https://micro.blog/books/9781472147097\">&lsquo;The Self Taught Programmer&rsquo;</a> (now on my to-read list) and does a really good job of walking through the concepts, partly framed at setting the reader up for being able to solve the typical software engineering interview questions. The code is python, which is approachable enough. There&rsquo;s some minor funkiness of seeing</p>\n<pre tabindex=\"0\"><code class=\"language-{python}\" data-lang=\"{python}\">if condition:\r\n  return True\r\nelse:\r\n  return False\r\n</code></pre><p>rather than just returning <code>condition</code> but otherwise the code is carefully explained. I believe this has the best explanations I&rsquo;ve seen of &lsquo;big O notation&rsquo; for time complexity and how the different variations arise. Similarly, this is the first time I&rsquo;ve understood what a linked list and binary tree are (and how/why someone may want to invert them - I&rsquo;ve only seen the stereotypical interview question).</p>\n<p>As always, the more you learn about programming in one language the more you learn about all the other languages you know, so now I&rsquo;m interested in understanding some of these concepts from an R perspective. I certainly made use of <code>VecDeque</code> and <code>HashMap</code> in my Rust AoC solutions, but in R I was stuck with poorly-performing <code>vector</code> and <code>list</code> objects, which I occasionally improved with an <code>environment</code>. I was very happy to see that R 4.2.2 gains <code>utils::hashtab()</code> (<a href=\"https://stat.ethz.ch/R-manual/R-devel/library/utils/html/hashtab.html\">link</a>)!.</p>\n<p>Overall I was happy with this book. A great introduction to the concepts, and some useful approaches to interview questions (if you&rsquo;re likely to be asked them).</p>\n",
				"content_text": "Finished reading: [The Self-Taught Computer Scientist](https://micro.blog/books/9781119724339) by Cory Althoff 📚\r\n\r\nThis is the book I wish I'd read before doing [Advent of Code](https://adventofcode.com/2022) - a full blog post on that will eventually be on my [main blog](https://jcarroll.com.au); I finished both parts of all 25 exercises in (strictly) base R, and am more than halfway through re-doing all of them in Rust. I was surprised at how much computer science was needed to solve these, but I did enjoy what I learned along the way, so actually reading up on some of it seemed like a good idea.\r\n\r\nThis book is the follow-on from ['The Self Taught Programmer'](https://micro.blog/books/9781472147097) (now on my to-read list) and does a really good job of walking through the concepts, partly framed at setting the reader up for being able to solve the typical software engineering interview questions. The code is python, which is approachable enough. There's some minor funkiness of seeing\r\n\r\n```{python}\r\nif condition:\r\n  return True\r\nelse:\r\n  return False\r\n```\r\n\r\nrather than just returning `condition` but otherwise the code is carefully explained. I believe this has the best explanations I've seen of 'big O notation' for time complexity and how the different variations arise. Similarly, this is the first time I've understood what a linked list and binary tree are (and how/why someone may want to invert them - I've only seen the stereotypical interview question).\r\n\r\nAs always, the more you learn about programming in one language the more you learn about all the other languages you know, so now I'm interested in understanding some of these concepts from an R perspective. I certainly made use of `VecDeque` and `HashMap` in my Rust AoC solutions, but in R I was stuck with poorly-performing `vector` and `list` objects, which I occasionally improved with an `environment`. I was very happy to see that R 4.2.2 gains `utils::hashtab()` ([link](https://stat.ethz.ch/R-manual/R-devel/library/utils/html/hashtab.html))!. \r\n\r\nOverall I was happy with this book. A great introduction to the concepts, and some useful approaches to interview questions (if you're likely to be asked them).\n",
				"date_published": "2023-01-29T14:38:08+09:30",
				"url": "https://jcarroll.xyz/2023/01/29/finished-reading-the.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/01/26/finished-reading-living.html",
				"title": "Finished reading: Living in Data by Jer Thorp 📚",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9781250849151\">Living in Data</a> by Jer Thorp 📚</p>\n<p>(<a href=\"https://jcarroll.xyz/2023/01/20/currently-reading-living.html\">previously</a>)</p>\n<p>As a data person, this book spoke to me deeply. As someone who has worked with collected data many times, it offered a fresh insight into understanding nuances of data, where it has come from, how it is <em>never</em> collected without human involvement, and how biases are embedded into every bit and byte.</p>\n<p>Reading this at the same time as <a href=\"https://jcarroll.xyz/2023/01/26/finished-reading-the.html\">The Checklist Manifesto</a> was timely as there is a lot of overlap between the ideas in terms of gathering data.</p>\n<p>There were many great examples of &ldquo;practical visualisations&rdquo; and real-world projects involving an intersection of art and (data) science. One of the most interesting was a project involving planting genetically identical trees across a wide area, the idea being that &ldquo;how they grow&rdquo; reflects the local conditions, and as such they are a proxy for data about each area. It&rsquo;s a <a href=\"https://www.deeproot.com/blog/blog-entries/onetrees-the-forgotten-tree-art-project/\">somewhat lost project</a> it seems, but interesting nonetheless.</p>\n<p>My very minor nitpick about this one was the very common American-ism of assuming everyone is in the Northern Hemisphere, and as such &ldquo;winter&rdquo; and &ldquo;spring&rdquo; refer to unique times of the year. It reminded me of the bias inherent in the construction of the &lsquo;north is up&rsquo; mental model of the world</p>\n<!-- raw HTML omitted -->\n<p>(you do have to choose some direction, and any is as good as any other, but it&rsquo;s a choice).</p>\n<p>I loved reading this book, and I will be strongly recommending it to everyone who works with data. I am very happy that I picked up this one - sometimes browsing the shelves randomly works.</p>\n",
				"content_text": "Finished reading: [Living in Data](https://micro.blog/books/9781250849151) by Jer Thorp 📚\n\n([previously](https://jcarroll.xyz/2023/01/20/currently-reading-living.html))\n\nAs a data person, this book spoke to me deeply. As someone who has worked with collected data many times, it offered a fresh insight into understanding nuances of data, where it has come from, how it is *never* collected without human involvement, and how biases are embedded into every bit and byte.\n\nReading this at the same time as [The Checklist Manifesto](https://jcarroll.xyz/2023/01/26/finished-reading-the.html) was timely as there is a lot of overlap between the ideas in terms of gathering data.\n\nThere were many great examples of \"practical visualisations\" and real-world projects involving an intersection of art and (data) science. One of the most interesting was a project involving planting genetically identical trees across a wide area, the idea being that \"how they grow\" reflects the local conditions, and as such they are a proxy for data about each area. It's a [somewhat lost project](https://www.deeproot.com/blog/blog-entries/onetrees-the-forgotten-tree-art-project/) it seems, but interesting nonetheless.\n\nMy very minor nitpick about this one was the very common American-ism of assuming everyone is in the Northern Hemisphere, and as such \"winter\" and \"spring\" refer to unique times of the year. It reminded me of the bias inherent in the construction of the 'north is up' mental model of the world\n\n<img src=\"https://cdn.uploads.micro.blog/64109/2023/5254ada67e.jpg\" width=\"600\" height=\"366\" alt=\"\">\n\n(you do have to choose some direction, and any is as good as any other, but it's a choice).\n\nI loved reading this book, and I will be strongly recommending it to everyone who works with data. I am very happy that I picked up this one - sometimes browsing the shelves randomly works.\n",
				"date_published": "2023-01-26T14:28:23+09:30",
				"url": "https://jcarroll.xyz/2023/01/26/finished-reading-living.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/01/26/finished-reading-the.html",
				"title": "Finished reading: The Checklist Manifesto by Atul Gawande 📚",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9781846683145\">The Checklist Manifesto</a> by Atul Gawande 📚</p>\n<p>I honestly didn&rsquo;t know what I was getting when I placed a library hold on this book - a recommendation from somewhere, but I assumed it was about something like how to write good checklists or manage priorities. This is not that book. This is a wild ride through the ways that some checklists have been used by the author and others throughout history. Not just any checklists, mind you - it&rsquo;s a tour of how a very important checklist was designed, refined, and implemented. The side-stories are often confronting, impactful, and very entertainingly spun together. I clicked &lsquo;confirm purchase&rsquo; on my own copy of this book before I had finished reading it. I suspect I&rsquo;ll come back to this one again.</p>\n<p>Highly recommended to anyone and everyone, but especially anyone who wants to ensure that things actually get done.</p>\n",
				"content_text": "Finished reading: [The Checklist Manifesto](https://micro.blog/books/9781846683145) by Atul Gawande 📚\r\n\r\nI honestly didn't know what I was getting when I placed a library hold on this book - a recommendation from somewhere, but I assumed it was about something like how to write good checklists or manage priorities. This is not that book. This is a wild ride through the ways that some checklists have been used by the author and others throughout history. Not just any checklists, mind you - it's a tour of how a very important checklist was designed, refined, and implemented. The side-stories are often confronting, impactful, and very entertainingly spun together. I clicked 'confirm purchase' on my own copy of this book before I had finished reading it. I suspect I'll come back to this one again.\r\n\r\nHighly recommended to anyone and everyone, but especially anyone who wants to ensure that things actually get done.\n",
				"date_published": "2023-01-26T14:06:38+09:30",
				"url": "https://jcarroll.xyz/2023/01/26/finished-reading-the.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/01/26/finished-reading-our.html",
				"title": "Finished reading: Our Data, Ourselves by Jacqueline D. Lipton 📚",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9780520390508\">Our Data, Ourselves</a> by Jacqueline D. Lipton 📚</p>\n<p>I abandoned this book after a few chapters. I wasn&rsquo;t sure how much I really wanted to read a book about technology and data where the author claims on page 10 that</p>\n<blockquote>\n<p>&ldquo;RFID can be monitored at a distance. You do not need a digital reader in the proximity of the device to locate and &lsquo;read&rsquo; its information. RFID microchips are implanted in livestock and pets to help find them if they are lost. They are implanted into digital devices, notably automobiles, to find them if they become stolen or lost, or simply to track them for work or other purposes.&rdquo;</p>\n</blockquote>\n<p>This is&hellip; somewhere between blatantly wrong and misunderstood. RFID <em>is</em> used for these things (microchips in animals, automobile assembly lines, books at a library) but it&rsquo;s used over very short distances, and is entirely passive (the tag is not powered). Someone has apparently managed to <a href=\"https://www.theregister.com/2006/01/30/dutch_biometric_passport_crack/\">read a passport</a> from about 10 metres using special equipment, but that&rsquo;s far from standard usage. I don&rsquo;t think you can just &ldquo;find&rdquo; an RFID tag in the wild with any reader. You <em>can</em> use one to identify a <em>found</em> animal, or which automobile is passing a sensor in a factory, or which book is being checked out, but there&rsquo;s definitely some strong notion of &ldquo;proximity&rdquo; involved, as far as I&rsquo;m aware (please correct me if I&rsquo;m wrong). I believe RFID is used in automated highway toll collection, but it involves significant power, likely not passively.</p>\n<p>That left a bad enough taste in my (mind)mouth that I wasn&rsquo;t particularly open to reading in great depth about (very specifically) American law</p>\n<blockquote>\n<p>This book focuses on the American position on individual privacy</p>\n</blockquote>\n<p>especially with the note that</p>\n<blockquote>\n<p>our powerful First Amendment protections of free speech-that is, speech free from government interference-have been regarded as limiting laws that restrict what we can say about each other.</p>\n</blockquote>\n<p>I can only read so many &ldquo;Someone vs Someone&rdquo; names of legal precedents and US-specific names of agencies, court jurisdictions, etc. before giving up. This may be of more interest to someone in the US interested in specific legal aspects, but it&rsquo;s not for me.</p>\n",
				"content_text": "Finished reading: [Our Data, Ourselves](https://micro.blog/books/9780520390508) by Jacqueline D. Lipton 📚\r\n\r\nI abandoned this book after a few chapters. I wasn't sure how much I really wanted to read a book about technology and data where the author claims on page 10 that\r\n\r\n> \"RFID can be monitored at a distance. You do not need a digital reader in the proximity of the device to locate and 'read' its information. RFID microchips are implanted in livestock and pets to help find them if they are lost. They are implanted into digital devices, notably automobiles, to find them if they become stolen or lost, or simply to track them for work or other purposes.\"\r\n\r\nThis is... somewhere between blatantly wrong and misunderstood. RFID _is_ used for these things (microchips in animals, automobile assembly lines, books at a library) but it's used over very short distances, and is entirely passive (the tag is not powered). Someone has apparently managed to [read a passport](https://www.theregister.com/2006/01/30/dutch_biometric_passport_crack/) from about 10 metres using special equipment, but that's far from standard usage. I don't think you can just \"find\" an RFID tag in the wild with any reader. You _can_ use one to identify a _found_ animal, or which automobile is passing a sensor in a factory, or which book is being checked out, but there's definitely some strong notion of \"proximity\" involved, as far as I'm aware (please correct me if I'm wrong). I believe RFID is used in automated highway toll collection, but it involves significant power, likely not passively.\r\n\r\nThat left a bad enough taste in my (mind)mouth that I wasn't particularly open to reading in great depth about (very specifically) American law \r\n\r\n> This book focuses on the American position on individual privacy\r\n\r\nespecially with the note that \r\n\r\n> our powerful First Amendment protections of free speech-that is, speech free from government interference-have been regarded as limiting laws that restrict what we can say about each other.\r\n\r\nI can only read so many \"Someone vs Someone\" names of legal precedents and US-specific names of agencies, court jurisdictions, etc. before giving up. This may be of more interest to someone in the US interested in specific legal aspects, but it's not for me.\r\n\r\n",
				"date_published": "2023-01-26T14:00:22+09:30",
				"url": "https://jcarroll.xyz/2023/01/26/finished-reading-our.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/01/20/currently-reading-living.html",
				
				"content_html": "<p>Currently reading: <a href=\"https://micro.blog/books/9781250849151\">Living in Data</a> by Jer Thorp 📚</p>\n<p>I picked this up browsing shelves in a (particularly <a href=\"https://playandgo.com.au/dymocks-book-store-rundle-mall-adelaide-review/\">beautiful</a>) brick and mortar book store thanks to a voucher I received for a journal article review. So far I&rsquo;m loving it. This was my first introduction to Johanna Drucker&rsquo;s framing of <a href=\"http://www.digitalhumanities.org/dhq/vol/5/1/000091/000091.html\">&ldquo;capta&rdquo;</a> rather than &ldquo;data&rdquo;, the former better reflecting the essence of information being &ldquo;taken and constructed&rdquo; rather than given. Lots to get through yet, but so far very entertaining and insightful.</p>\n",
				"content_text": "Currently reading: [Living in Data](https://micro.blog/books/9781250849151) by Jer Thorp 📚\n\nI picked this up browsing shelves in a (particularly [beautiful](https://playandgo.com.au/dymocks-book-store-rundle-mall-adelaide-review/)) brick and mortar book store thanks to a voucher I received for a journal article review. So far I'm loving it. This was my first introduction to Johanna Drucker's framing of [\"capta\"](http://www.digitalhumanities.org/dhq/vol/5/1/000091/000091.html) rather than \"data\", the former better reflecting the essence of information being \"taken and constructed\" rather than given. Lots to get through yet, but so far very entertaining and insightful.\n",
				"date_published": "2023-01-20T21:11:45+09:30",
				"url": "https://jcarroll.xyz/2023/01/20/currently-reading-living.html"
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/01/08/finished-reading-loonshots.html",
				"title": "Finished reading: Loonshots by Safi Bahcall 📚",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9781250185976\">Loonshots</a> by Safi Bahcall 📚</p>\n<p>This was recommended by someone at work and this time I&rsquo;m very glad they did. The author carefully details the history of some of the most significant breakthroughs and, as a physicist, isn&rsquo;t shy with the specifics. It was staggering to me at the start of the book how intertwined the &ldquo;big&rdquo; computer tech (and by extension, media; Lucasfilm, Pixar, &hellip;) companies are and the history they share. By the end of the book these connections are much clearer. I hadn&rsquo;t expected quite the history lesson, but the prevalence of persisting English technology over the much older Chinese inventions becomes well-reasoned. Less fun is the contemplation that maybe we don&rsquo;t currently have an equivalent of Bell Labs fostering such speculative exploration without the need to be profitable in the near future. Even the well-funded but negative revenue companies have the plan to be highly profitable, not a plan to make something better. The <a href=\"https://www.bcorporation.net/en-us/certification\">B corporations</a> are a good exception, but they&rsquo;re still not quite &ldquo;loonshot nurseries&rdquo;.</p>\n<p>One of the key learnings for me, as someone who works in a Silicon-valley-adjacent biotech startup (hence the recommendation), was that the attitude of creating a &ldquo;disruptive&rdquo; technology is backwards. Many technologies can be seen as disruptive in hindsight, but they never start out with that attitude. Incremental improvement with the support to try something different certainly leads there, but it&rsquo;s perhaps too large a leap to try to get there sooner. Having the support to try something different that could be better is the first step towards making something incredible, and it certainly won&rsquo;t work every time, but not trying will absolutely lead to not making it.</p>\n<p>Lastly, I don&rsquo;t think it really sunk in while I was working there for nearly five years since I wasn&rsquo;t so read-up on the history, but seeing Genentech mentioned in many of these recent books always makes me do a double-take.</p>\n<p>I thoroughly enjoyed this book and recommend it to anyone interested in how big ideas come about and survive, and why others don&rsquo;t.</p>\n",
				"content_text": "Finished reading: [Loonshots](https://micro.blog/books/9781250185976) by Safi Bahcall 📚\r\n\r\nThis was recommended by someone at work and this time I'm very glad they did. The author carefully details the history of some of the most significant breakthroughs and, as a physicist, isn't shy with the specifics. It was staggering to me at the start of the book how intertwined the \"big\" computer tech (and by extension, media; Lucasfilm, Pixar, ...) companies are and the history they share. By the end of the book these connections are much clearer. I hadn't expected quite the history lesson, but the prevalence of persisting English technology over the much older Chinese inventions becomes well-reasoned. Less fun is the contemplation that maybe we don't currently have an equivalent of Bell Labs fostering such speculative exploration without the need to be profitable in the near future. Even the well-funded but negative revenue companies have the plan to be highly profitable, not a plan to make something better. The [B corporations](https://www.bcorporation.net/en-us/certification) are a good exception, but they're still not quite \"loonshot nurseries\".\r\n\r\nOne of the key learnings for me, as someone who works in a Silicon-valley-adjacent biotech startup (hence the recommendation), was that the attitude of creating a \"disruptive\" technology is backwards. Many technologies can be seen as disruptive in hindsight, but they never start out with that attitude. Incremental improvement with the support to try something different certainly leads there, but it's perhaps too large a leap to try to get there sooner. Having the support to try something different that could be better is the first step towards making something incredible, and it certainly won't work every time, but not trying will absolutely lead to not making it.\r\n\r\nLastly, I don't think it really sunk in while I was working there for nearly five years since I wasn't so read-up on the history, but seeing Genentech mentioned in many of these recent books always makes me do a double-take.\r\n\r\nI thoroughly enjoyed this book and recommend it to anyone interested in how big ideas come about and survive, and why others don't.\n",
				"date_published": "2023-01-08T13:05:31+09:30",
				"url": "https://jcarroll.xyz/2023/01/08/finished-reading-loonshots.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/01/06/implicit-or-explicit.html",
				"title": "Implicit or Explicit connection object?",
				"content_html": "<p>I&rsquo;m wrapping a (stateless, hit-every-time) REST API and my design was challenged with an alternative opinion - which is great! I get to have a more serious think about design and what might work best. I have an internal function which does the actual talking to the server, e.g. <code>.get_from_API()</code> which needs to know the URL, auth key, and query parameters. I originally designed my package to fetch these from environment variables depending on the API instance (e.g. &lsquo;prod&rsquo; vs &lsquo;dev&rsquo;) and the user (their user-specific key). Individual endpoint wrappers essentially boil down to</p>\n<pre tabindex=\"0\"><code class=\"language-{r}\" data-lang=\"{r}\">get_this &lt;- function(something) {\r\n    .get_from_API(construct_endpoint(something))\r\n}\r\n</code></pre><p>I asked the following question on some of the social sites I use:</p>\n<hr>\n<p>Is there a good reason to use one of these vs the other when wrapping an API?</p>\n<p>A:</p>\n<pre tabindex=\"0\"><code class=\"language-{r}\" data-lang=\"{r}\">get_this(x, ...) # GET\r\nget_that(x, ...) # GET\r\nset_this(x, y, ...) # SET\r\nset_that(x, y, ...) # SET\r\n</code></pre><p>with something like this within each of these</p>\n<pre tabindex=\"0\"><code class=\"language-{r}\" data-lang=\"{r}\">greedy_con &lt;- .connect(Sys.getenv(implicit_api_vars), ...)\r\n</code></pre><p>OR</p>\n<p>B:</p>\n<pre tabindex=\"0\"><code class=\"language-{r}\" data-lang=\"{r}\">lazy_con &lt;- .connect(explicit_api_vars, ...)\r\nthis(lazy_con, x, ...) # GET\r\nthat(lazy_con, x, ...) # GET\r\nthis(lazy_con, x) &lt;- y # SET\r\nthat(lazy_con, x) &lt;- y # SET\r\n</code></pre><p>(Or some third option)?</p>\n<hr>\n<p>The motivation for the second option may have come from python where methods on objects are much more common. Indeed, the canonical python version of this wrapper uses</p>\n<pre tabindex=\"0\"><code class=\"language-{python}\" data-lang=\"{python}\">lazy_con = NameOfAPI(url = {}, key = {})\r\n\r\nlazy_con.this()\r\nlazy_con.that()\r\n</code></pre><p>In R we have dispatch (e.g. S3) so I <em>could</em> assign a class <code>mycon</code> to <code>lazy_con</code> and methods <code>this.mycon()</code> and <code>that.mycon()</code> but this seems very overengineered. Apparently BioConductor also uses this method syntax but there the standard is S4 dispatch (and typically larger data) so a more explicit object might make more sense.</p>\n<p>Methods on classes seems to be a common frustration for me in python and rust where I&rsquo;m constantly trying to use some function (e.g. <code>abs(x-y)</code>) which is actually a method (<code>(x-y).abs()</code>) but I think I understand <em>why</em> they&rsquo;re built that way.</p>\n<p>So far the responses seem to lean entirely towards hiding the complexity of the connection away. That said, adopting the &lsquo;setter&rsquo; assignment syntax would mean I could do away with the explicit &lsquo;get&rsquo; in the getter function names.</p>\n<p>Do you have an opinion on this? Let me know!</p>\n",
				"content_text": "I'm wrapping a (stateless, hit-every-time) REST API and my design was challenged with an alternative opinion - which is great! I get to have a more serious think about design and what might work best. I have an internal function which does the actual talking to the server, e.g. `.get_from_API()` which needs to know the URL, auth key, and query parameters. I originally designed my package to fetch these from environment variables depending on the API instance (e.g. 'prod' vs 'dev') and the user (their user-specific key). Individual endpoint wrappers essentially boil down to\r\n\r\n```{r}\r\nget_this <- function(something) {\r\n    .get_from_API(construct_endpoint(something))\r\n}\r\n```\r\n\r\nI asked the following question on some of the social sites I use:\r\n\r\n---\r\n\r\nIs there a good reason to use one of these vs the other when wrapping an API?\r\n\r\nA: \r\n\r\n```{r}\r\nget_this(x, ...) # GET\r\nget_that(x, ...) # GET\r\nset_this(x, y, ...) # SET\r\nset_that(x, y, ...) # SET\r\n```\r\n\r\nwith something like this within each of these\r\n\r\n```{r}\r\ngreedy_con <- .connect(Sys.getenv(implicit_api_vars), ...)\r\n```\r\n\r\nOR\r\n\r\nB:\r\n\r\n```{r}\r\nlazy_con <- .connect(explicit_api_vars, ...)\r\nthis(lazy_con, x, ...) # GET\r\nthat(lazy_con, x, ...) # GET\r\nthis(lazy_con, x) <- y # SET\r\nthat(lazy_con, x) <- y # SET\r\n```\r\n\r\n(Or some third option)?\r\n\r\n---\r\n\r\nThe motivation for the second option may have come from python where methods on objects are much more common. Indeed, the canonical python version of this wrapper uses\r\n\r\n```{python}\r\nlazy_con = NameOfAPI(url = {}, key = {})\r\n\r\nlazy_con.this()\r\nlazy_con.that()\r\n```\r\n\r\nIn R we have dispatch (e.g. S3) so I *could* assign a class `mycon` to `lazy_con` and methods `this.mycon()` and `that.mycon()` but this seems very overengineered. Apparently BioConductor also uses this method syntax but there the standard is S4 dispatch (and typically larger data) so a more explicit object might make more sense.\r\n\r\nMethods on classes seems to be a common frustration for me in python and rust where I'm constantly trying to use some function (e.g. `abs(x-y)`) which is actually a method (`(x-y).abs()`) but I think I understand *why* they're built that way. \r\n\r\nSo far the responses seem to lean entirely towards hiding the complexity of the connection away. That said, adopting the 'setter' assignment syntax would mean I could do away with the explicit 'get' in the getter function names.\r\n\r\nDo you have an opinion on this? Let me know!\n",
				"date_published": "2023-01-06T14:57:11+09:30",
				"url": "https://jcarroll.xyz/2023/01/06/implicit-or-explicit.html",
				"tags": ["R"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/01/04/finished-reading-neuromancer.html",
				"title": "Finished reading: Neuromancer by William Gibson 📚",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9783608504880\">Neuromancer</a> by William Gibson 📚</p>\n<p>I was recommended this on one of the socials and figured it was about time to get around to it. As the &lsquo;first&rsquo; &ldquo;cyber&rdquo; sci-fi book it was well-written and despite being conservative in its predictions for the future, many of these time has proven to be accurate. The pace is reasonable, but by the end it felt a bit like one short story without many offshoots - I&rsquo;m not complaining; perhaps I&rsquo;ve read too many books whose author tried to fill the pages with unnecessary side stories. Worth the read, but probably not one I&rsquo;ll come back to too often.</p>\n",
				"content_text": "Finished reading: [Neuromancer](https://micro.blog/books/9783608504880) by William Gibson 📚\n\nI was recommended this on one of the socials and figured it was about time to get around to it. As the 'first' \"cyber\" sci-fi book it was well-written and despite being conservative in its predictions for the future, many of these time has proven to be accurate. The pace is reasonable, but by the end it felt a bit like one short story without many offshoots - I'm not complaining; perhaps I've read too many books whose author tried to fill the pages with unnecessary side stories. Worth the read, but probably not one I'll come back to too often.\n",
				"date_published": "2023-01-04T17:44:09+09:30",
				"url": "https://jcarroll.xyz/2023/01/04/finished-reading-neuromancer.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/08/06/finished-reading-start.html",
				"title": "Finished reading: Start with Why: How Great Leaders Inspire Everyone to Take Action by Simon Sinek ",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9781591846444\">Start with Why: How Great Leaders Inspire Everyone to Take Action</a> by Simon Sinek</p>\n<p>I <a href=\"https://jcarroll.xyz/2022/06/29/currently-reading-start.html\">posted about this one</a> after a few chapters because it started to get on my nerves. I think I hate-finished it. The author makes some more questionable connections (a bow needs to pulled <em>away</em> from the target&hellip; what?) and continues to write like the reader is definitely American. The argument that Apple fans and Harley riders like iPhones and Harleys because of <em>why</em> the respective companies do what they do never convinced me in the slightest.</p>\n<p>The message that the <em>why</em> of a company should be prominent, consistent, and persistent seems fine, I just don&rsquo;t think I liked how that point was made (and taken too far).</p>\n<p>Much of the book, particularly the final chapters are great examples of <a href=\"https://en.wikipedia.org/wiki/Survivorship_bias\">survivorship bias</a> but the author seems to either be deliberately overlooking that.</p>\n<p>I didn&rsquo;t particularly enjoy this book.</p>\n<!-- raw HTML omitted -->\n",
				"content_text": "Finished reading: [Start with Why: How Great Leaders Inspire Everyone to Take Action](https://micro.blog/books/9781591846444) by Simon Sinek \n\nI [posted about this one](https://jcarroll.xyz/2022/06/29/currently-reading-start.html) after a few chapters because it started to get on my nerves. I think I hate-finished it. The author makes some more questionable connections (a bow needs to pulled *away* from the target... what?) and continues to write like the reader is definitely American. The argument that Apple fans and Harley riders like iPhones and Harleys because of *why* the respective companies do what they do never convinced me in the slightest. \n\nThe message that the *why* of a company should be prominent, consistent, and persistent seems fine, I just don't think I liked how that point was made (and taken too far).\n\nMuch of the book, particularly the final chapters are great examples of [survivorship bias](https://en.wikipedia.org/wiki/Survivorship_bias) but the author seems to either be deliberately overlooking that.\n\nI didn't particularly enjoy this book.\n\n<img src=\"https://cdn.uploads.micro.blog/64109/2022/34065cbf3c.jpg\" width=\"405\" height=\"600\" alt=\"don't make me tap the sign / survivorship bias\" />\n",
				"date_published": "2022-08-06T15:39:29+09:30",
				"url": "https://jcarroll.xyz/2022/08/06/finished-reading-start.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/08/06/finished-reading-sea.html",
				"title": "Finished reading: Sea of Tranquility: A novel by Emily St. John Mandel ",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9780593321454\">Sea of Tranquility: A novel</a> by Emily St. John Mandel</p>\n<p>I don&rsquo;t know if it was timely or unfortunate that I read this book so close to <a href=\"https://jcarroll.xyz/2022/07/09/finished-reading-the.html\">The End of Eternity</a> - both had very similar themes, but Asimov is just so good at weaving the threads together into an engrossing story. I think this was a recommendation from Twitter, and while I enjoyed it, it did feel oddly paced. The start felt quite slow - the first half of the book was spent introducing the characters, yet the conclusion seemed to be squashed into the final chapter. Without spoiling too much, there&rsquo;s some <a href=\"https://youtu.be/u4SEDzynMiQ\">bootstrap paradox</a> stuff (as any book involving time-travel should have) that just gets hand-waved away. It&rsquo;s fine if you don&rsquo;t think about it too hard.</p>\n<p>Overall, not bad. Recommended for a not-too-serious read.</p>\n",
				"content_text": "Finished reading: [Sea of Tranquility: A novel](https://micro.blog/books/9780593321454) by Emily St. John Mandel \n\nI don't know if it was timely or unfortunate that I read this book so close to [The End of Eternity](https://jcarroll.xyz/2022/07/09/finished-reading-the.html) - both had very similar themes, but Asimov is just so good at weaving the threads together into an engrossing story. I think this was a recommendation from Twitter, and while I enjoyed it, it did feel oddly paced. The start felt quite slow - the first half of the book was spent introducing the characters, yet the conclusion seemed to be squashed into the final chapter. Without spoiling too much, there's some [bootstrap paradox](https://youtu.be/u4SEDzynMiQ) stuff (as any book involving time-travel should have) that just gets hand-waved away. It's fine if you don't think about it too hard.\n\nOverall, not bad. Recommended for a not-too-serious read.\n",
				"date_published": "2022-08-06T15:16:57+09:30",
				"url": "https://jcarroll.xyz/2022/08/06/finished-reading-sea.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/07/31/160948.html",
				"title": "Finished reading: 12 Bytes: How We Got Here. Where We Might Go Next by Jeanette Winterson ",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9781473578258\">12 Bytes: How We Got Here. Where We Might Go Next</a> by Jeanette Winterson</p>\n<p>My library had several copies of this on the shelf, so I assumed it was popular or new. The latter is certainly true (2021). This is a collection of short essays detailing the journey from the first analytical machine towards AGI (Artificial General Intelligence; c.f. narrow AI such as a digital assistant), specifically noting the significant contributions of women (against the prejudices and biases which are only now slowly being dismantled).</p>\n<p>The stories shouldn&rsquo;t be new to anyone, but more light on them is a good thing. The author provides a great level of detail about the contributions and their historical contexts, but borders on misandry with their side remarks. &ldquo;Turn around is fair play&rdquo; one could argue, but I don&rsquo;t think it&rsquo;s helpful here. The (extremely talented) women who programmed the ENIAC (the domain experts on the mathematical equations they were programming the machine to solve) absolutely deserved the credit for their achievements that was withheld from them, but emphasising &ldquo;the men who built it couldn&rsquo;t program it&rdquo; as if to suggest they just stuck some electronics together and couldn&rsquo;t comprehend what they&rsquo;d built without the women seems disingenuous. Arguing that the &ldquo;I&rsquo;m a Mac / I&rsquo;m a PC&rdquo; ads specifically only had men in order to reinforce the stereotype that women don&rsquo;t use computers seems like a stretch.</p>\n<p>I enjoyed reading the historical content of this book. The commentary not so much. Others may enjoy it more than I did.</p>\n",
				"content_text": "Finished reading: [12 Bytes: How We Got Here. Where We Might Go Next](https://micro.blog/books/9781473578258) by Jeanette Winterson \n\nMy library had several copies of this on the shelf, so I assumed it was popular or new. The latter is certainly true (2021). This is a collection of short essays detailing the journey from the first analytical machine towards AGI (Artificial General Intelligence; c.f. narrow AI such as a digital assistant), specifically noting the significant contributions of women (against the prejudices and biases which are only now slowly being dismantled). \n\nThe stories shouldn't be new to anyone, but more light on them is a good thing. The author provides a great level of detail about the contributions and their historical contexts, but borders on misandry with their side remarks. \"Turn around is fair play\" one could argue, but I don't think it's helpful here. The (extremely talented) women who programmed the ENIAC (the domain experts on the mathematical equations they were programming the machine to solve) absolutely deserved the credit for their achievements that was withheld from them, but emphasising \"the men who built it couldn't program it\" as if to suggest they just stuck some electronics together and couldn't comprehend what they'd built without the women seems disingenuous. Arguing that the \"I'm a Mac / I'm a PC\" ads specifically only had men in order to reinforce the stereotype that women don't use computers seems like a stretch.\n\nI enjoyed reading the historical content of this book. The commentary not so much. Others may enjoy it more than I did.\n",
				"date_published": "2022-07-31T16:09:48+09:30",
				"url": "https://jcarroll.xyz/2022/07/31/160948.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/07/16/finished-reading-the.html",
				"title": "Finished reading: The New Childhood: Raising Kids to Thrive in a Connected World by Jordan Shapiro ",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9780316437257\">The New Childhood: Raising Kids to Thrive in a Connected World</a> by Jordan Shapiro</p>\n<p>Another break from biology, certainly more towards psychology. This one I found randomly (promoted) at the library and given that it&rsquo;s my kids' school holidays at the moment and they&rsquo;re constantly asking for screens, I figured it was worth a shot. To my surprise, by the end of this book I&rsquo;m encouraged to give my kids <em>more</em> screen time. The big qualifier is the content - the author makes convincing arguments that collaborative games and online chat are the new <a href=\"https://en.wikipedia.org/wiki/Agora\">agora</a>, and that kids growing into that world will need to understand, appreciate, and be able to &ldquo;read&rdquo; (&ldquo;be literate in&rdquo;) the new medium. I&rsquo;m not quite convinced that watching YouTube videos of someone playing an extremely basic free game has the same benefit as they propose comes from collaborative gaming or online forums, but I am convinced to start playing Minecraft <em>with</em> my kids.</p>\n<p>This book nicely balances historical psychology with up-to-date perspectives. I was surprised to learn that kindergarten (as a concept at all) is only a couple hundred years old. The framing of how previous generations of children have been raised within the applicable social setting (most of us are remnants of the industrial age), plus the entire home vs work distinction breaking down in the new internet-based world makes a lot of sense and encourages me to think about what outdated notions I&rsquo;m imposing on my own kids, especially how those can be limiting. In my current work I make use of mind maps and collaborative documents - why would I not want my children to use the same useful tools for their education?</p>\n<p>The latter sections of the book branched out into much wider social commentary - children are growing up within the evolving technological landscape, so it&rsquo;s entirely relevant - and I liked several well-made points about why &ldquo;uninformed inclusion&rdquo; might actually work against goals; why it&rsquo;s not sufficient to just connect everyone and hope they&rsquo;ll be nice; why some people form exclusions against others due to a lack of self-identity; and why online forums are so useful for connecting people, but to the detriment of serendipity.</p>\n<p>That last one really hit home - the R community largely calls Twitter home and it&rsquo;s been a fruitful source of friends, collaborators, and inspiration for me, but I do wonder how much of an echo chamber I&rsquo;m stuck it. Maybe it&rsquo;s time to follow some more python and javascript devs.</p>\n<p>I highly recommend this book to anyone with children who is uncertain about the amount of screen time they&rsquo;re getting. Also just a great read for better understanding the new digital world.</p>\n",
				"content_text": "Finished reading: [The New Childhood: Raising Kids to Thrive in a Connected World](https://micro.blog/books/9780316437257) by Jordan Shapiro \n\nAnother break from biology, certainly more towards psychology. This one I found randomly (promoted) at the library and given that it's my kids' school holidays at the moment and they're constantly asking for screens, I figured it was worth a shot. To my surprise, by the end of this book I'm encouraged to give my kids *more* screen time. The big qualifier is the content - the author makes convincing arguments that collaborative games and online chat are the new [agora](https://en.wikipedia.org/wiki/Agora), and that kids growing into that world will need to understand, appreciate, and be able to \"read\" (\"be literate in\") the new medium. I'm not quite convinced that watching YouTube videos of someone playing an extremely basic free game has the same benefit as they propose comes from collaborative gaming or online forums, but I am convinced to start playing Minecraft *with* my kids.\n\nThis book nicely balances historical psychology with up-to-date perspectives. I was surprised to learn that kindergarten (as a concept at all) is only a couple hundred years old. The framing of how previous generations of children have been raised within the applicable social setting (most of us are remnants of the industrial age), plus the entire home vs work distinction breaking down in the new internet-based world makes a lot of sense and encourages me to think about what outdated notions I'm imposing on my own kids, especially how those can be limiting. In my current work I make use of mind maps and collaborative documents - why would I not want my children to use the same useful tools for their education?\n\nThe latter sections of the book branched out into much wider social commentary - children are growing up within the evolving technological landscape, so it's entirely relevant - and I liked several well-made points about why \"uninformed inclusion\" might actually work against goals; why it's not sufficient to just connect everyone and hope they'll be nice; why some people form exclusions against others due to a lack of self-identity; and why online forums are so useful for connecting people, but to the detriment of serendipity.\n\nThat last one really hit home - the R community largely calls Twitter home and it's been a fruitful source of friends, collaborators, and inspiration for me, but I do wonder how much of an echo chamber I'm stuck it. Maybe it's time to follow some more python and javascript devs.\n\nI highly recommend this book to anyone with children who is uncertain about the amount of screen time they're getting. Also just a great read for better understanding the new digital world.\n",
				"date_published": "2022-07-16T20:15:27+09:30",
				"url": "https://jcarroll.xyz/2022/07/16/finished-reading-the.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/07/09/finished-reading-the.html",
				"title": "Finished reading: The End of Eternity by Isaac Asimov",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9780593160060\">The End of Eternity</a> by Isaac Asimov</p>\n<p>Easily one of the greatest science fiction writers of all time, and it&rsquo;s easy to see why. I&rsquo;ve loved many of them, but I haven&rsquo;t read anywhere near all of Asimov&rsquo;s works. I saw this one on a shelf and figured it would be a nice break from the much heavier non-fiction biology I&rsquo;ve been reading lately.</p>\n<p>The craftsmanship of Asimov&rsquo;s writing always leaves me pleased. Small callbacks throughout seem effortless; the words never seem to be shoehorned in order to tie together different threads (with other authors, certain sentences have a certain &lsquo;<a href=\"https://en.wikipedia.org/wiki/Chekhov%27s_gun\">Chekhov&rsquo;s gun</a>&rsquo; flavour to them).</p>\n<p>I enjoyed reading this book. Twists and turns, a careful balance of science and hand-waving, and a not-too-overwhelming set of characters. I&rsquo;ll certainly be keeping an eye out for more of Asimov&rsquo;s works to correct my lack of coverage. Recommended to time-travel and general sci-fi enthusiasts.</p>\n",
				"content_text": "Finished reading: [The End of Eternity](https://micro.blog/books/9780593160060) by Isaac Asimov \n\nEasily one of the greatest science fiction writers of all time, and it's easy to see why. I've loved many of them, but I haven't read anywhere near all of Asimov's works. I saw this one on a shelf and figured it would be a nice break from the much heavier non-fiction biology I've been reading lately.\n\nThe craftsmanship of Asimov's writing always leaves me pleased. Small callbacks throughout seem effortless; the words never seem to be shoehorned in order to tie together different threads (with other authors, certain sentences have a certain '[Chekhov's gun](https://en.wikipedia.org/wiki/Chekhov%27s_gun)' flavour to them).\n\nI enjoyed reading this book. Twists and turns, a careful balance of science and hand-waving, and a not-too-overwhelming set of characters. I'll certainly be keeping an eye out for more of Asimov's works to correct my lack of coverage. Recommended to time-travel and general sci-fi enthusiasts.\n",
				"date_published": "2022-07-09T17:07:59+09:30",
				"url": "https://jcarroll.xyz/2022/07/09/finished-reading-the.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/06/29/currently-reading-start.html",
				"title": "Currently reading: Start With Why by Simon Sinek ",
				"content_html": "<p>Currently reading: <a href=\"https://micro.blog/books/9780241958230\">Start With Why</a> by Simon Sinek</p>\n<p>I was recommended this book by someone whose opinion I hold in high regard, but so far I&rsquo;m not enjoying this book. Not necessarily for the material - I think I can appreciate the points being made about having a defined &lsquo;why&rsquo; behind a company and explanations of the various manipulations a company can leverage rather than actually being better than the competition, but rather the extreme &ldquo;American-ness&rdquo; of the author. Especially surprising since the author has a more diverse background than simply &lsquo;American&rsquo;.</p>\n<p>It took 48 pages before a single non-American company was mentioned (Ferarri), and even then it was in the context of</p>\n<blockquote>\n<p>&ldquo;if you have a family of six a two-seater Ferarri is not better. However, if you&rsquo;re looking for a great way to meet women, a Honda minivan is probably not better&rdquo;.</p>\n</blockquote>\n<p>I&rsquo;m long out of the dating scene, but that seems&hellip; like a terrible comparison. Is that part of the purchasing decision? I suppose maybe it is for some, but as a reliable consumer group?</p>\n<p>Multiple references to Apple Macs and iTunes being brilliant innovations &ldquo;because people connected with the why of the company&rdquo;. iTunes was a terrible product that was forced onto users in order to use the iPod (a distinct improvement over the removable media competition). My understanding is that it gained significant market share over CDs because it was easier (and potentially cheaper - if you wanted a single song). For myself and many others (the reason I believe it was actually innovative) it was <em>easier</em> than pirating music. A dollar for a song compared to a handful of dollars for a CD or the <em>hassle</em> of downloading and uploading a file - it solved a problem. I don&rsquo;t attribute that to Apple&rsquo;s &ldquo;why&rdquo; - another company that offered that might just as well have had the same success.</p>\n<p>Chapter 4 seems to end with the explanation that &ldquo;Harley Davidson riders want Harleys&rdquo; and &ldquo;Mac people want something starting with an <em>i</em>&rdquo; and that there&rsquo;s a cult aspect to this based on loyalty above actual product superiority but I don&rsquo;t believe this is grounded in any &ldquo;why&rdquo; of those companies. They&rsquo;ve each done well at convincing buyers to be part of their collective, and they&rsquo;ve each done well at having some features their buyers do appreciate (loud engines or smooth interfaces) but they&rsquo;re both viewed as objectively worse products by people who can be considered unbiased. The example of &ldquo;U2 being iconoclastic&rdquo; and so a joint promotional iPod &ldquo;makes sense&rdquo; got a genuine chuckle from me - did people buy more iPods because U2 were involved? From everything I saw of that time, it was ridiculed. Users had an entire album forced onto their devices that they had no interest in.</p>\n<p>Then more &ldquo;everyone is American&rdquo; - I actually had to put the book down during the chapter explaining &ldquo;the biology of belonging&rdquo; with the sentence</p>\n<blockquote>\n<p>&ldquo;Go abroad and you&rsquo;ll form instant bonds with other Americans you meet&rdquo;</p>\n</blockquote>\n<p>Other? I&rsquo;m Australian.</p>\n<p>I got really upset at repeated references to language structure having some &ldquo;hidden meaning&rdquo;. Is it a coincidence that the phrase is &ldquo;hearts and minds&rdquo; in that order? Or &ldquo;art and science&rdquo;&hellip; No. Not really. Sure, the rules are vague, but it&rsquo;s not particularly meaningful in the way the author hints at. There are <a href=\"https://www.cambridge.org/elt/blog/2017/08/31/chips-and-fish-word-order-in-english-collocations/\">accepted orderings</a> to some combinations of words known as &ldquo;collocations&rdquo; that &ldquo;make sense&rdquo; to a native English speaker - anyone who hears &ldquo;chips and fish&rdquo; will instantly recognise something is wrong. The &ldquo;i&rdquo; (/ɪ/) in both &ldquo;mind&rdquo; (/maɪnd/) and &ldquo;science&rdquo; (/ˈsaɪ.əns/) fits well into the regular pattern.</p>\n<p>The same allusion to the layout of the &ldquo;Golden Circle&rdquo; having some correlation with the physical brain structure reeks of ill-informed motivational speakers and those who say &ldquo;walnuts are good for your brain because they look like a brain&rdquo;.</p>\n<p>I&rsquo;m still going to give the rest of the book a chance, but so far it&rsquo;s not rating high.</p>\n",
				"content_text": "Currently reading: [Start With Why](https://micro.blog/books/9780241958230) by Simon Sinek \n\nI was recommended this book by someone whose opinion I hold in high regard, but so far I'm not enjoying this book. Not necessarily for the material - I think I can appreciate the points being made about having a defined 'why' behind a company and explanations of the various manipulations a company can leverage rather than actually being better than the competition, but rather the extreme \"American-ness\" of the author. Especially surprising since the author has a more diverse background than simply 'American'.\n\nIt took 48 pages before a single non-American company was mentioned (Ferarri), and even then it was in the context of\n\n> \"if you have a family of six a two-seater Ferarri is not better. However, if you're looking for a great way to meet women, a Honda minivan is probably not better\".\n\nI'm long out of the dating scene, but that seems... like a terrible comparison. Is that part of the purchasing decision? I suppose maybe it is for some, but as a reliable consumer group?\n\nMultiple references to Apple Macs and iTunes being brilliant innovations \"because people connected with the why of the company\". iTunes was a terrible product that was forced onto users in order to use the iPod (a distinct improvement over the removable media competition). My understanding is that it gained significant market share over CDs because it was easier (and potentially cheaper - if you wanted a single song). For myself and many others (the reason I believe it was actually innovative) it was *easier* than pirating music. A dollar for a song compared to a handful of dollars for a CD or the *hassle* of downloading and uploading a file - it solved a problem. I don't attribute that to Apple's \"why\" - another company that offered that might just as well have had the same success.\n\nChapter 4 seems to end with the explanation that \"Harley Davidson riders want Harleys\" and \"Mac people want something starting with an _i_\" and that there's a cult aspect to this based on loyalty above actual product superiority but I don't believe this is grounded in any \"why\" of those companies. They've each done well at convincing buyers to be part of their collective, and they've each done well at having some features their buyers do appreciate (loud engines or smooth interfaces) but they're both viewed as objectively worse products by people who can be considered unbiased. The example of \"U2 being iconoclastic\" and so a joint promotional iPod \"makes sense\" got a genuine chuckle from me - did people buy more iPods because U2 were involved? From everything I saw of that time, it was ridiculed. Users had an entire album forced onto their devices that they had no interest in.\n\nThen more \"everyone is American\" - I actually had to put the book down during the chapter explaining \"the biology of belonging\" with the sentence\n\n> \"Go abroad and you'll form instant bonds with other Americans you meet\"\n\nOther? I'm Australian.\n\nI got really upset at repeated references to language structure having some \"hidden meaning\". Is it a coincidence that the phrase is \"hearts and minds\" in that order? Or \"art and science\"... No. Not really. Sure, the rules are vague, but it's not particularly meaningful in the way the author hints at. There are [accepted orderings](https://www.cambridge.org/elt/blog/2017/08/31/chips-and-fish-word-order-in-english-collocations/) to some combinations of words known as \"collocations\" that \"make sense\" to a native English speaker - anyone who hears \"chips and fish\" will instantly recognise something is wrong. The \"i\" (/ɪ/) in both \"mind\" (/maɪnd/) and \"science\" (/ˈsaɪ.əns/) fits well into the regular pattern.\n\nThe same allusion to the layout of the \"Golden Circle\" having some correlation with the physical brain structure reeks of ill-informed motivational speakers and those who say \"walnuts are good for your brain because they look like a brain\".\n\nI'm still going to give the rest of the book a chance, but so far it's not rating high.\n",
				"date_published": "2022-06-29T22:45:19+09:30",
				"url": "https://jcarroll.xyz/2022/06/29/currently-reading-start.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/06/28/finished-reading-the.html",
				"title": "Finished reading: The Cell by Joshua Z. Rappoport 📚",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9781944648978\">The Cell</a> by Joshua Z. Rappoport 📚</p>\n<p>I enjoyed this book - it started with a good overview of the cellular biology but did move on to more organ-based systems, which was perfect for me. The explanations of the lab and microscopy techniques, advancements, innovations, and discoveries were particularly nice. The detour to examples of academic fraud took a dark turn for such a pleasant book. Recommended for those looking for a nice balance of in-depth science and casual explanations.</p>\n",
				"content_text": "Finished reading: [The Cell](https://micro.blog/books/9781944648978) by Joshua Z. Rappoport 📚\r\n\r\nI enjoyed this book - it started with a good overview of the cellular biology but did move on to more organ-based systems, which was perfect for me. The explanations of the lab and microscopy techniques, advancements, innovations, and discoveries were particularly nice. The detour to examples of academic fraud took a dark turn for such a pleasant book. Recommended for those looking for a nice balance of in-depth science and casual explanations.\n",
				"date_published": "2022-06-28T14:16:18+09:30",
				"url": "https://jcarroll.xyz/2022/06/28/finished-reading-the.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/06/11/currently-reading-the.html",
				"title": "Currently reading: The Cell: Discovering the Microscopic World that Determines our Health, our Consciousness, and our Future",
				"content_html": "<p>Currently reading: <a href=\"https://micro.blog/books/9781944648978\">The Cell: Discovering the Microscopic World that Determines our Health, our Consciousness, and our Future</a> by Joshua Z. Rappoport</p>\n<p>Continuing with the technical theme, so far this is a deep dive into the very specific mechanisms of molecular biology without (yet) too much emphasis on particular cells.</p>\n<p>What surprised me so far was that <a href=\"https://en.wikipedia.org/wiki/Polymerase_chain_reaction\">PCR</a> (as a technology) is only as old as I am. It&rsquo;s gained a lot of attention thanks to a particular virus we&rsquo;ve all heard too much about. I&rsquo;d never run one of these reactions myself (having not passed through a university biology department) and wasn&rsquo;t aware of the technical details. I had heard various claims by armchair biologists that the COVID PCR test was &ldquo;just detecting the flu&rdquo; and that &ldquo;if you run enough cycles you can find anything&rdquo; but with a better explanation of how it works - primers and temperature cycling - it&rsquo;s clear that&rsquo;s all just a load of nonsense. I&rsquo;m enjoying this one so far.</p>\n<p>Also news to me was that RT-PCR (Reverse Transcription-Polymerase Chain Reaction) is the name applicable to PCR of an RNA virus (as <a href=\"https://en.wikipedia.org/wiki/Severe_acute_respiratory_syndrome_coronavirus_2\">SARS-CoV-2</a> is) and not a meaningfully different version to PCR in that case, despite <a href=\"https://www.flysfo.com/travel-well/covid-19-testing\">some listings having both</a>.</p>\n",
				"content_text": "Currently reading: [The Cell: Discovering the Microscopic World that Determines our Health, our Consciousness, and our Future](https://micro.blog/books/9781944648978) by Joshua Z. Rappoport \n\nContinuing with the technical theme, so far this is a deep dive into the very specific mechanisms of molecular biology without (yet) too much emphasis on particular cells. \n\nWhat surprised me so far was that [PCR](https://en.wikipedia.org/wiki/Polymerase_chain_reaction) (as a technology) is only as old as I am. It's gained a lot of attention thanks to a particular virus we've all heard too much about. I'd never run one of these reactions myself (having not passed through a university biology department) and wasn't aware of the technical details. I had heard various claims by armchair biologists that the COVID PCR test was \"just detecting the flu\" and that \"if you run enough cycles you can find anything\" but with a better explanation of how it works - primers and temperature cycling - it's clear that's all just a load of nonsense. I'm enjoying this one so far.\n\nAlso news to me was that RT-PCR (Reverse Transcription-Polymerase Chain Reaction) is the name applicable to PCR of an RNA virus (as [SARS-CoV-2](https://en.wikipedia.org/wiki/Severe_acute_respiratory_syndrome_coronavirus_2) is) and not a meaningfully different version to PCR in that case, despite [some listings having both](https://www.flysfo.com/travel-well/covid-19-testing).\n",
				"date_published": "2022-06-11T17:06:26+09:30",
				"url": "https://jcarroll.xyz/2022/06/11/currently-reading-the.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/06/11/finished-reading-life.html",
				"title": "Finished reading: Life Unfolding: How the Human Body Creates Itself",
				"content_html": "<p><a href=\"https://micro.blog/books/9780199673537\">Life Unfolding: How the Human Body Creates Itself</a> by Jamie A. Davies</p>\n<p>How a single cell develops into a full human, and a lot of the molecular biology along the way. I thoroughly enjoyed this read - every chapter had highly interesting points about the particular pathways involved and how the cells end up &ldquo;choosing&rdquo; to do all the things they do; move where they need to move, align along directions, and proliferate/die. I spent a lot of time pausing my reading, looking up branches of other information and going down other rabbit holes. I read this as a library loan, but I enjoyed it so much I&rsquo;ve bought my own permanent copy.</p>\n<p>What surprised me the most (having taken a non-traditional route into biology via physics and programming) - but probably shouldn&rsquo;t have - was how the entire system efficiently re-use mechanisms and pathways for both very early development and for ongoing functionality. I recognised several genes from my cancer immunology work, but I always regarded these as &lsquo;just part of the genetic makeup of a person&rsquo;, not paying attention to how they were critical to actually creating the fully grown person, and are now being repurposed. It&rsquo;s perhaps obvious in hindsight, but there aren&rsquo;t a set of genes for pre-natal growth and another set for adult life. It makes the fact that sometimes these mechanisms fail to work perfectly all the more understandable.</p>\n<p>Highly recommend to anyone interested in the very technical details, but a well-presented resource for those generally interested.</p>\n<!-- raw HTML omitted -->\n",
				"content_text": "[Life Unfolding: How the Human Body Creates Itself](https://micro.blog/books/9780199673537) by Jamie A. Davies \n\nHow a single cell develops into a full human, and a lot of the molecular biology along the way. I thoroughly enjoyed this read - every chapter had highly interesting points about the particular pathways involved and how the cells end up \"choosing\" to do all the things they do; move where they need to move, align along directions, and proliferate/die. I spent a lot of time pausing my reading, looking up branches of other information and going down other rabbit holes. I read this as a library loan, but I enjoyed it so much I've bought my own permanent copy.\n\nWhat surprised me the most (having taken a non-traditional route into biology via physics and programming) - but probably shouldn't have - was how the entire system efficiently re-use mechanisms and pathways for both very early development and for ongoing functionality. I recognised several genes from my cancer immunology work, but I always regarded these as 'just part of the genetic makeup of a person', not paying attention to how they were critical to actually creating the fully grown person, and are now being repurposed. It's perhaps obvious in hindsight, but there aren't a set of genes for pre-natal growth and another set for adult life. It makes the fact that sometimes these mechanisms fail to work perfectly all the more understandable.\n\nHighly recommend to anyone interested in the very technical details, but a well-presented resource for those generally interested.\n\n<img src=\"https://cdn.uploads.micro.blog/64109/2022/d82072c1a2.jpg\" width=\"600\" height=\"800\" alt=\"\" />\n",
				"date_published": "2022-06-11T16:49:17+09:30",
				"url": "https://jcarroll.xyz/2022/06/11/finished-reading-life.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/06/11/163214.html",
				"title": "Finished reading: Life from an RNA World: The Ancestor Within",
				"content_html": "<p>(backlog from March 2022)</p>\n<p><a href=\"https://micro.blog/books/9780674050754\">Life from an RNA World: The Ancestor Within</a> by Michael Yarus</p>\n<p>This was a nice tour of how the complex mechanisms of DNA replication came to be, and how the process works to produce proteins and phenotypes. This was the first time I really felt I understood the difference between DNA and RNA, and how such a mechanism evolved. Highly recommend to anyone interested in genomics/genetics at a technical level.</p>\n",
				"content_text": "(backlog from March 2022)\n\n[Life from an RNA World: The Ancestor Within](https://micro.blog/books/9780674050754) by Michael Yarus\n\nThis was a nice tour of how the complex mechanisms of DNA replication came to be, and how the process works to produce proteins and phenotypes. This was the first time I really felt I understood the difference between DNA and RNA, and how such a mechanism evolved. Highly recommend to anyone interested in genomics/genetics at a technical level.\n",
				"date_published": "2022-06-11T16:48:07+09:30",
				"url": "https://jcarroll.xyz/2022/06/11/163214.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/04/07/interpolation-animation-in.html",
				"title": "Interpolation animation in Julia",
				"content_html": "<p>I <em>love</em> small projects for helping me learn, especially programming. I&rsquo;m still learning Julia, and have found myself wanting more &ldquo;little silly things&rdquo; I can digest and learn from. A lot of the projects I see in Julia are big mathematical models, and I&rsquo;m just not ready to dive that deep yet.</p>\n<p><a href=\"https://twitter.com/ted_dunning/status/1435027697386721280?s=20&amp;t=cDVb0XOQRJeOjXoTrOz54w\">This series of tweets</a> caught my eye, partly because of the cool animation, but also the bite-sized amount of information it was conveying - that interpolation in Julia can be specified so easily, thanks in large part to the multiple dispatch design of the language.</p>\n<p>&ldquo;Surely I could get those 7 lines of code to run&rdquo; I thought.</p>\n<p>Entering the code into VScode was straightforward enough, no problems there. I could define the interpolation function</p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">interpolate(a, b) = t -&gt; ((1.0-t)*a + t*b)\n</code></pre><p>however extending the <code>*</code> and <code>+</code> methods did require me to <code>import Base:*</code> and <code>import Base:+</code> which I think I knew but had forgotten.</p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">+(f::Function, g::Function) = x -&gt; f(x) + g(x)\n*(t::Number, g::Function) = x -&gt; t * g(x)\n</code></pre><p>Defining the secondary and tertiary interpolations, also straightforward</p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">bz1(p1, p2) = interpolate(p1, p2)\nbz2(p1, p2, p3) = interpolate(bz1(p1, p2), bz1(p2, p3))\nbz3(p1, p2, p3, p4) = interpolate(bz2(p1, p2, p3), bz2(p2, p3, p4))\n</code></pre><p>Now the tricky part - evaluating some of these. I knew that <code>a</code> and <code>b</code> represent points, but how to do that here? They&rsquo;re not single numbers, but coordinates. I tried a <code>Tuple</code> as <code>(1, 2)</code> but that doesn&rsquo;t seem to work. I do need to remember that <code>interpolate</code> is itself a function of <code>t</code>, so that needs to be specified as well. If I try to interpolate halfway between two &ldquo;points&rdquo; with <code>Tuple</code>s</p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">interpolate((0,1), (1,2))(0.5)\nERROR: MethodError: no method matching *(::Float64, ::Tuple{Int64,Int64})\nClosest candidates are:\n  *(::Any, ::Any, ::Any, ::Any...) at operators.jl:538\n  *(::Float64, ::Float64) at float.jl:405\n  *(::AbstractFloat, ::Bool) at bool.jl:112\n</code></pre><p>Okay, how about <code>Array</code>s?</p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">interpolate([0,1], [1,2])(0.5)\n2-element Array{Float64,1}:\n 0.5\n 1.5\n</code></pre><p>Huzzah!</p>\n<p>After that, it&rsquo;s a matter of generating the points specified by</p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">bz3(p1, p2, p3, p4)(t)(t)(t)\n</code></pre><p>for various values of <code>t</code>. I did that with a <code>map</code> and joined the results back into a single <code>Array</code></p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">dots = map(i -&gt; bz3(p1, p2, p3, p4)(i)(i)(i),collect(0:0.1:1))\ndots = hcat(dots...)\ndots\n2×11 Array{Float64,2}:\n 0.5  0.47535  0.5368  0.66245  …  1.36905  1.4872  1.53815  1.5\n 1.0  1.3124   1.5312  1.6588      1.3052   1.0128  0.6436   0.2\n</code></pre><p>That was, I&rsquo;d say, a success.</p>\n<p>Drunk with confidence, I wanted to try to reproduce the animation from the tweet, so I dug into the documentation. It didn&rsquo;t seem too bad, and I think I&rsquo;ve managed to reproduce it pretty well</p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">anim = @animate for t in collect(vcat(0:0.01:1,1:-0.01:0))\n    a = bz3(p1, p2, p3, p4)(t)(t)(t);\n    b1 = bz2(p1, p2, p3)(t)(t);\n    b2 = bz2(p2, p3, p4)(t)(t);\n    c1 = bz1(p1, p2)(t);\n    c2 = bz1(p2, p3)(t);\n    c3 = bz1(p3, p4)(t);\n    stars = hcat(p1, p2, p3, p4);\n    diamond1 = hcat(c1, c2);\n    diamond2 = hcat(c2, c3);\n    square = hcat(b1, b2);\n    plot(xlim = (-0.1,2.5), ylim = (-0.1,2.5), legend = false)\n    scatter!(dots[1,:], dots[2,:], markersize = 2)\n    plot!(diamond1[1,:], diamond1[2,:], markersize = 10, markershape = :diamond, color = :green)\n    plot!(diamond2[1,:], diamond2[2,:], markersize = 10, markershape = :diamond, color = :green)\n    plot!(square[1,:], square[2,:], markersize = 10, markershape = :square, color = :blue)\n    plot!(stars[1,:], stars[2,:], markersize = 10, markershape = :star, color = :purple)\n    scatter!(Tuple(a), markersize = 10, markershape = :circle, markercolor = :red)\nend\n\ngif(anim, fps = 24)\n</code></pre><p><img src=\"https://cdn.uploads.micro.blog/64109/2022/ea5f75012f.gif\" alt=\"\"></p>\n<p>Moving the points around, I get a new version all of my own</p>\n<p><img src=\"https://cdn.uploads.micro.blog/64109/2022/b776bf8259.gif\" alt=\"\"></p>\n<p>I&rsquo;m very happy with how these turned out, and I&rsquo;ve learned a lot! A gist of the code to make these is hosted here: <a href=\"https://gist.github.com/jonocarroll/27f9b57332424ea50ec2970e74d8e3b3\">https://gist.github.com/jonocarroll/27f9b57332424ea50ec2970e74d8e3b3</a></p>\n<p>If there are better ways to do any of the steps (there surely are) please feel free to let me know!</p>\n<p>Was this fun? You Bezier ass!</p>\n",
				"content_text": "I *love* small projects for helping me learn, especially programming. I'm still learning Julia, and have found myself wanting more \"little silly things\" I can digest and learn from. A lot of the projects I see in Julia are big mathematical models, and I'm just not ready to dive that deep yet.\n\n[This series of tweets](https://twitter.com/ted_dunning/status/1435027697386721280?s=20&t=cDVb0XOQRJeOjXoTrOz54w) caught my eye, partly because of the cool animation, but also the bite-sized amount of information it was conveying - that interpolation in Julia can be specified so easily, thanks in large part to the multiple dispatch design of the language.\n\n\"Surely I could get those 7 lines of code to run\" I thought.\n\nEntering the code into VScode was straightforward enough, no problems there. I could define the interpolation function \n```{julia}\ninterpolate(a, b) = t -> ((1.0-t)*a + t*b)\n```\nhowever extending the `*` and `+` methods did require me to `import Base:*` and `import Base:+` which I think I knew but had forgotten.\n```{julia}\n+(f::Function, g::Function) = x -> f(x) + g(x)\n*(t::Number, g::Function) = x -> t * g(x)\n```\nDefining the secondary and tertiary interpolations, also straightforward\n```{julia}\nbz1(p1, p2) = interpolate(p1, p2)\nbz2(p1, p2, p3) = interpolate(bz1(p1, p2), bz1(p2, p3))\nbz3(p1, p2, p3, p4) = interpolate(bz2(p1, p2, p3), bz2(p2, p3, p4))\n```\nNow the tricky part - evaluating some of these. I knew that `a` and `b` represent points, but how to do that here? They're not single numbers, but coordinates. I tried a `Tuple` as `(1, 2)` but that doesn't seem to work. I do need to remember that `interpolate` is itself a function of `t`, so that needs to be specified as well. If I try to interpolate halfway between two \"points\" with `Tuple`s\n```{julia}\ninterpolate((0,1), (1,2))(0.5)\nERROR: MethodError: no method matching *(::Float64, ::Tuple{Int64,Int64})\nClosest candidates are:\n  *(::Any, ::Any, ::Any, ::Any...) at operators.jl:538\n  *(::Float64, ::Float64) at float.jl:405\n  *(::AbstractFloat, ::Bool) at bool.jl:112\n```\nOkay, how about `Array`s?\n```{julia}\ninterpolate([0,1], [1,2])(0.5)\n2-element Array{Float64,1}:\n 0.5\n 1.5\n```\nHuzzah!\n\nAfter that, it's a matter of generating the points specified by\n```{julia}\nbz3(p1, p2, p3, p4)(t)(t)(t)\n```\nfor various values of `t`. I did that with a `map` and joined the results back into a single `Array`\n```{julia}\ndots = map(i -> bz3(p1, p2, p3, p4)(i)(i)(i),collect(0:0.1:1))\ndots = hcat(dots...)\ndots\n2×11 Array{Float64,2}:\n 0.5  0.47535  0.5368  0.66245  …  1.36905  1.4872  1.53815  1.5\n 1.0  1.3124   1.5312  1.6588      1.3052   1.0128  0.6436   0.2\n```\nThat was, I'd say, a success.\n\nDrunk with confidence, I wanted to try to reproduce the animation from the tweet, so I dug into the documentation. It didn't seem too bad, and I think I've managed to reproduce it pretty well\n```{julia}\nanim = @animate for t in collect(vcat(0:0.01:1,1:-0.01:0))\n    a = bz3(p1, p2, p3, p4)(t)(t)(t);\n    b1 = bz2(p1, p2, p3)(t)(t);\n    b2 = bz2(p2, p3, p4)(t)(t);\n    c1 = bz1(p1, p2)(t);\n    c2 = bz1(p2, p3)(t);\n    c3 = bz1(p3, p4)(t);\n    stars = hcat(p1, p2, p3, p4);\n    diamond1 = hcat(c1, c2);\n    diamond2 = hcat(c2, c3);\n    square = hcat(b1, b2);\n    plot(xlim = (-0.1,2.5), ylim = (-0.1,2.5), legend = false)\n    scatter!(dots[1,:], dots[2,:], markersize = 2)\n    plot!(diamond1[1,:], diamond1[2,:], markersize = 10, markershape = :diamond, color = :green)\n    plot!(diamond2[1,:], diamond2[2,:], markersize = 10, markershape = :diamond, color = :green)\n    plot!(square[1,:], square[2,:], markersize = 10, markershape = :square, color = :blue)\n    plot!(stars[1,:], stars[2,:], markersize = 10, markershape = :star, color = :purple)\n    scatter!(Tuple(a), markersize = 10, markershape = :circle, markercolor = :red)\nend\n\ngif(anim, fps = 24)\n```\n![](https://cdn.uploads.micro.blog/64109/2022/ea5f75012f.gif)\n\nMoving the points around, I get a new version all of my own\n\n![](https://cdn.uploads.micro.blog/64109/2022/b776bf8259.gif)\n\nI'm very happy with how these turned out, and I've learned a lot! A gist of the code to make these is hosted here: [https://gist.github.com/jonocarroll/27f9b57332424ea50ec2970e74d8e3b3](https://gist.github.com/jonocarroll/27f9b57332424ea50ec2970e74d8e3b3)\n\nIf there are better ways to do any of the steps (there surely are) please feel free to let me know!\n\nWas this fun? You Bezier ass!\n",
				"date_published": "2022-04-07T21:07:00+09:30",
				"url": "https://jcarroll.xyz/2022/04/07/interpolation-animation-in.html",
				"tags": ["Julia"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/03/25/r-challenge-contour.html",
				"title": "R challenge - contour in a matrix",
				"content_html": "<p>As part of what will hopefully become a larger post, I&rsquo;m interested in finding an R way to achieve the following: given an <code>n x n</code> matrix of zeroes with a single non-zero element of some value <code>v</code>, fill the surrounding entries such that each other element is at most one less than those surrounding it (up or down). For example, with an <code>8x8</code> matrix with a value of <code>5</code> at <code>c(5, 5)</code>, the result would be</p>\n<pre tabindex=\"0\"><code>     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n[1,]    0    0    0    0    1    0    0    0\n[2,]    0    0    0    1    2    1    0    0\n[3,]    0    0    1    2    3    2    1    0\n[4,]    0    0    2    3    4    3    2    1\n[5,]    1    2    3    4    5    4    3    2\n[6,]    0    1    2    3    4    3    2    1\n[7,]    0    0    1    2    3    2    1    0\n[8,]    0    0    0    1    2    1    0    0\n</code></pre><p>This is somewhat akin to imposing a contour density on top of a single peak, but I really can&rsquo;t find any suitable approaches. Convolutions came to mind, but I can&rsquo;t think of or find the appropriate kernel.</p>\n<p>Let me know if you have one!</p>\n<h2 id=\"update\">Update:</h2>\n<p>Thanks to <a href=\"https://twitter.com/yjunechoe/status/1507344665514848258?s=20&amp;t=27rn8zNl-36D-3ppsslAjw\">June Choe</a>, this code using <code>outer()</code> produces the desired matrix for a point at <code>c(vx, vy)</code> with value <code>vv</code> in a <code>n x n</code> matrix</p>\n<pre tabindex=\"0\"><code>vx &lt;- 4\nvy &lt;- 3\nvv &lt;- 5\nn &lt;- 8\nouter(1:n, 1:n, function(x, y) pmax(vv - abs(x - vx) - abs(y - vy), 0))\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n[1,]    0    1    2    1    0    0    0    0\n[2,]    1    2    3    2    1    0    0    0\n[3,]    2    3    4    3    2    1    0    0\n[4,]    3    4    5    4    3    2    1    0\n[5,]    2    3    4    3    2    1    0    0\n[6,]    1    2    3    2    1    0    0    0\n[7,]    0    1    2    1    0    0    0    0\n[8,]    0    0    1    0    0    0    0    0\n</code></pre>",
				"content_text": "As part of what will hopefully become a larger post, I'm interested in finding an R way to achieve the following: given an `n x n` matrix of zeroes with a single non-zero element of some value `v`, fill the surrounding entries such that each other element is at most one less than those surrounding it (up or down). For example, with an `8x8` matrix with a value of `5` at `c(5, 5)`, the result would be\n\n```\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n[1,]    0    0    0    0    1    0    0    0\n[2,]    0    0    0    1    2    1    0    0\n[3,]    0    0    1    2    3    2    1    0\n[4,]    0    0    2    3    4    3    2    1\n[5,]    1    2    3    4    5    4    3    2\n[6,]    0    1    2    3    4    3    2    1\n[7,]    0    0    1    2    3    2    1    0\n[8,]    0    0    0    1    2    1    0    0\n````\n\nThis is somewhat akin to imposing a contour density on top of a single peak, but I really can't find any suitable approaches. Convolutions came to mind, but I can't think of or find the appropriate kernel.\n\nLet me know if you have one!\n\n## Update:\n\nThanks to [June Choe](https://twitter.com/yjunechoe/status/1507344665514848258?s=20&t=27rn8zNl-36D-3ppsslAjw), this code using `outer()` produces the desired matrix for a point at `c(vx, vy)` with value `vv` in a `n x n` matrix \n```\nvx <- 4\nvy <- 3\nvv <- 5\nn <- 8\nouter(1:n, 1:n, function(x, y) pmax(vv - abs(x - vx) - abs(y - vy), 0))\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n[1,]    0    1    2    1    0    0    0    0\n[2,]    1    2    3    2    1    0    0    0\n[3,]    2    3    4    3    2    1    0    0\n[4,]    3    4    5    4    3    2    1    0\n[5,]    2    3    4    3    2    1    0    0\n[6,]    1    2    3    2    1    0    0    0\n[7,]    0    1    2    1    0    0    0    0\n[8,]    0    0    1    0    0    0    0    0\n```\n",
				"date_published": "2022-03-25T22:02:00+09:30",
				"url": "https://jcarroll.xyz/2022/03/25/r-challenge-contour.html",
				"tags": ["R"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/03/20/rowwise-optimizations-in.html",
				"title": "ByRow optimizations in Julia",
				"content_html": "<p>I&rsquo;m still fairly new to Julia, even though I&rsquo;ve been trying to learn it for a few years. It&rsquo;s <em>extremely</em> powerful (fast, expressive, &hellip; whatever metric you want to use) but with that comes some complexity.</p>\n<p>I saw <a href=\"https://bkamins.github.io/julialang/2022/02/25/anyall.html\">this post</a> in my feed and it seemed like a great bite-sized chunk of code to learn from. I <em>think</em> I understand everything that&rsquo;s happening, even if I certainly couldn&rsquo;t write that myself, with one exception.</p>\n<p>The connection that for <code>Bool</code> data, <code>all()</code> is equivalent to <code>minimum()</code> (it&rsquo;s false as soon as there is one 0, otherwise it&rsquo;s true) and <code>any()</code> is equivalent to <code>maximum()</code> (if there&rsquo;s a 1 it&rsquo;s true) took me a moment, but seems pretty cool. That wasn&rsquo;t the problem I had.</p>\n<p>The bit that surprised me was that for <code>ByRow</code> calculations on a <code>DataFrame</code>, <code>minimum()</code> is <strong>faster</strong> than <code>all()</code>. The reason this is so surprising for me is that I understand <code>all()</code> from an R-perspective and my understanding was that <code>all()</code> could short-circuit because as soon as it sees a <code>FALSE</code> it can ignore any other values - the result is guaranteed to be <code>FALSE</code> (yes, yes, up to missingness). Surely, a calculation of <code>minimum()</code> needs to evaluate every value at least once (?). Where this might (must?) fall apart is that I&rsquo;m thinking purely of vectors. Sure enough, checking out some timings on a vector in Julia shows <code>all()</code> is near-instantaneous (after compilation)</p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">x = rand(Bool, 100_000_000)\n\n@time all(x)\n  0.009047 seconds (218 allocations: 9.531 KiB, 99.85% compilation time)\nfalse\n\n@time all(x)\n  0.000002 seconds\nfalse\n\n@time minimum(x)\n  0.091183 seconds (85.03 k allocations: 4.461 MiB, 41.98% compilation time)\nfalse\n\n@time minimum(x)\n  0.052287 seconds\nfalse\n</code></pre><p>I get similar results, expectedly, from R</p>\n<pre tabindex=\"0\"><code class=\"language-{r}\" data-lang=\"{r}\">x &lt;- sample(c(TRUE, FALSE), 1e8, replace = TRUE)\nmicrobenchmark::microbenchmark(\n  min = max(x),\n  any = any(x),\n  times = 10\n)\n# Unit: nanoseconds\n#  expr       min        lq        mean    median        uq       max neval\n#   min 208741173 210539351 223219500.3 212388892 222673528 285974960    10\n#   any       160       187      2403.4       295      5095      7451    10\n</code></pre><p>So, what&rsquo;s going on? I <em>think</em> the answer is that we&rsquo;re not dealing with just a vector, it&rsquo;s rows from a <code>DataFrame</code>, right? Now, from the R side, that&rsquo;s complicated enough - <code>rowwise()</code> is a <a href=\"https://speakerdeck.com/jennybc/row-oriented-workflows-in-r-with-the-tidyverse\">necessary thing</a> because R stores a <code>data.frame</code> as a list of vectors representing <em>columns</em>, so extracting a row means slicing across those.</p>\n<p>I can reproduce the speedup in Julia (and honestly, I struggle to find a clean and fast way to do it in R) but the statement &ldquo;<a href=\"https://bkamins.github.io/julialang/2022/02/25/anyall.html#:~:text=This%20time%20things%20are%20very%20fast%2C%20as%20row%2Dwise%20aggregation%20for%20maximum%20and%20minimum%20is%20optimized.\">This time things are very fast, as row-wise aggregation for maximum and minimum is optimized.</a>&rdquo; got me thinking - where should I have learned that? Google isn&rsquo;t showing me any relevant results, so is this just a known thing? I can imagine that such an optimization for doing this might exist, but can anyone provide a reference or guide?? The author of the blog post used this optimization in a <a href=\"https://stackoverflow.com/a/71209103/4168169\">StackOverflow answer</a> without challenge (no reference provided) so I feel like it&rsquo;s potentially just something I should know.</p>\n",
				"content_text": "I'm still fairly new to Julia, even though I've been trying to learn it for a few years. It's *extremely* powerful (fast, expressive, ... whatever metric you want to use) but with that comes some complexity. \n\nI saw [this post](https://bkamins.github.io/julialang/2022/02/25/anyall.html) in my feed and it seemed like a great bite-sized chunk of code to learn from. I *think* I understand everything that's happening, even if I certainly couldn't write that myself, with one exception.\n\nThe connection that for `Bool` data, `all()` is equivalent to `minimum()` (it's false as soon as there is one 0, otherwise it's true) and `any()` is equivalent to `maximum()` (if there's a 1 it's true) took me a moment, but seems pretty cool. That wasn't the problem I had.\n\nThe bit that surprised me was that for `ByRow` calculations on a `DataFrame`, `minimum()` is **faster** than `all()`. The reason this is so surprising for me is that I understand `all()` from an R-perspective and my understanding was that `all()` could short-circuit because as soon as it sees a `FALSE` it can ignore any other values - the result is guaranteed to be `FALSE` (yes, yes, up to missingness). Surely, a calculation of `minimum()` needs to evaluate every value at least once (?). Where this might (must?) fall apart is that I'm thinking purely of vectors. Sure enough, checking out some timings on a vector in Julia shows `all()` is near-instantaneous (after compilation)\n```{julia}\nx = rand(Bool, 100_000_000)\n\n@time all(x)\n  0.009047 seconds (218 allocations: 9.531 KiB, 99.85% compilation time)\nfalse\n\n@time all(x)\n  0.000002 seconds\nfalse\n\n@time minimum(x)\n  0.091183 seconds (85.03 k allocations: 4.461 MiB, 41.98% compilation time)\nfalse\n\n@time minimum(x)\n  0.052287 seconds\nfalse\n```\nI get similar results, expectedly, from R\n```{r}\nx <- sample(c(TRUE, FALSE), 1e8, replace = TRUE)\nmicrobenchmark::microbenchmark(\n  min = max(x),\n  any = any(x),\n  times = 10\n)\n# Unit: nanoseconds\n#  expr       min        lq        mean    median        uq       max neval\n#   min 208741173 210539351 223219500.3 212388892 222673528 285974960    10\n#   any       160       187      2403.4       295      5095      7451    10\n```\nSo, what's going on? I *think* the answer is that we're not dealing with just a vector, it's rows from a `DataFrame`, right? Now, from the R side, that's complicated enough - `rowwise()` is a [necessary thing](https://speakerdeck.com/jennybc/row-oriented-workflows-in-r-with-the-tidyverse) because R stores a `data.frame` as a list of vectors representing *columns*, so extracting a row means slicing across those. \n\nI can reproduce the speedup in Julia (and honestly, I struggle to find a clean and fast way to do it in R) but the statement \"[This time things are very fast, as row-wise aggregation for maximum and minimum is optimized.](https://bkamins.github.io/julialang/2022/02/25/anyall.html#:~:text=This%20time%20things%20are%20very%20fast%2C%20as%20row%2Dwise%20aggregation%20for%20maximum%20and%20minimum%20is%20optimized.)\" got me thinking - where should I have learned that? Google isn't showing me any relevant results, so is this just a known thing? I can imagine that such an optimization for doing this might exist, but can anyone provide a reference or guide?? The author of the blog post used this optimization in a [StackOverflow answer](https://stackoverflow.com/a/71209103/4168169) without challenge (no reference provided) so I feel like it's potentially just something I should know.\n",
				"date_published": "2022-03-20T13:11:00+09:30",
				"url": "https://jcarroll.xyz/2022/03/20/rowwise-optimizations-in.html",
				"tags": ["R","Julia"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/03/20/first-post-on.html",
				"title": "First post on jcarroll.xyz",
				"content_html": "<p>I like blogging, but in the spirit of lowering the resistance to getting posts out, I&rsquo;ve started a micro blog <a href=\"https://jcarroll.xyz\">jcarroll.xyz</a> where I&rsquo;ll capture shorter, less polished pieces and random thoughts / snippets.</p>\n<p>This is my first post, testing all the functionality. DNS might still take a little while, so don&rsquo;t worry if you see my full blog when you click the link.</p>\n",
				"content_text": "I like blogging, but in the spirit of lowering the resistance to getting posts out, I've started a micro blog [jcarroll.xyz](https://jcarroll.xyz) where I'll capture shorter, less polished pieces and random thoughts / snippets.\n\nThis is my first post, testing all the functionality. DNS might still take a little while, so don't worry if you see my full blog when you click the link.\n",
				"date_published": "2022-03-20T11:28:39+09:30",
				"url": "https://jcarroll.xyz/2022/03/20/first-post-on.html"
			}
	]
}
