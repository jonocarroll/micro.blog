{
	"version": "https://jsonfeed.org/version/1",
	"title": "Jonathan Carroll's micro blog",
	"icon": "https://micro.blog/jonocarroll/avatar.jpg",
	"home_page_url": "https://jcarroll.xyz/",
	"feed_url": "https://jcarroll.xyz/feed.json",
	"items": [
		
			{
				"id": "http://jonocarroll.micro.blog/2022/03/25/r-challenge-contour.html",
				"title": "R challenge - contour in a matrix",
				"content_html": "<p>As part of what will hopefully become a larger post, I&rsquo;m interested in finding an R way to achieve the following: given an <code>n x n</code> matrix of zeroes with a single non-zero element of some value <code>v</code>, fill the surrounding entries such that each other element is at most one less than those surrounding it (up or down). For example, with an <code>8x8</code> matrix with a value of <code>5</code> at <code>c(5, 5)</code>, the result would be</p>\n<pre tabindex=\"0\"><code>     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n[1,]    0    0    0    0    1    0    0    0\n[2,]    0    0    0    1    2    1    0    0\n[3,]    0    0    1    2    3    2    1    0\n[4,]    0    0    2    3    4    3    2    1\n[5,]    1    2    3    4    5    4    3    2\n[6,]    0    1    2    3    4    3    2    1\n[7,]    0    0    1    2    3    2    1    0\n[8,]    0    0    0    1    2    1    0    0\n</code></pre><p>This is somewhat akin to imposing a contour density on top of a single peak, but I really can&rsquo;t find any suitable approaches. Convolutions came to mind, but I can&rsquo;t think of or find the appropriate kernel.</p>\n<p>Let me know if you have one!</p>\n<h2 id=\"update\">Update:</h2>\n<p>Thanks to <a href=\"https://twitter.com/yjunechoe/status/1507344665514848258?s=20&amp;t=27rn8zNl-36D-3ppsslAjw\">June Choe</a>, this code using <code>outer()</code> produces the desired matrix for a point at <code>c(vx, vy)</code> with value <code>vv</code> in a <code>n x n</code> matrix</p>\n<pre tabindex=\"0\"><code>vx &lt;- 4\nvy &lt;- 3\nvv &lt;- 5\nn &lt;- 8\nouter(1:n, 1:n, function(x, y) pmax(vv - abs(x - vx) - abs(y - vy), 0))\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n[1,]    0    1    2    1    0    0    0    0\n[2,]    1    2    3    2    1    0    0    0\n[3,]    2    3    4    3    2    1    0    0\n[4,]    3    4    5    4    3    2    1    0\n[5,]    2    3    4    3    2    1    0    0\n[6,]    1    2    3    2    1    0    0    0\n[7,]    0    1    2    1    0    0    0    0\n[8,]    0    0    1    0    0    0    0    0\n</code></pre>",
				"content_text": "As part of what will hopefully become a larger post, I'm interested in finding an R way to achieve the following: given an `n x n` matrix of zeroes with a single non-zero element of some value `v`, fill the surrounding entries such that each other element is at most one less than those surrounding it (up or down). For example, with an `8x8` matrix with a value of `5` at `c(5, 5)`, the result would be\n\n```\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n[1,]    0    0    0    0    1    0    0    0\n[2,]    0    0    0    1    2    1    0    0\n[3,]    0    0    1    2    3    2    1    0\n[4,]    0    0    2    3    4    3    2    1\n[5,]    1    2    3    4    5    4    3    2\n[6,]    0    1    2    3    4    3    2    1\n[7,]    0    0    1    2    3    2    1    0\n[8,]    0    0    0    1    2    1    0    0\n````\n\nThis is somewhat akin to imposing a contour density on top of a single peak, but I really can't find any suitable approaches. Convolutions came to mind, but I can't think of or find the appropriate kernel.\n\nLet me know if you have one!\n\n## Update:\n\nThanks to [June Choe](https://twitter.com/yjunechoe/status/1507344665514848258?s=20&t=27rn8zNl-36D-3ppsslAjw), this code using `outer()` produces the desired matrix for a point at `c(vx, vy)` with value `vv` in a `n x n` matrix \n```\nvx <- 4\nvy <- 3\nvv <- 5\nn <- 8\nouter(1:n, 1:n, function(x, y) pmax(vv - abs(x - vx) - abs(y - vy), 0))\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n[1,]    0    1    2    1    0    0    0    0\n[2,]    1    2    3    2    1    0    0    0\n[3,]    2    3    4    3    2    1    0    0\n[4,]    3    4    5    4    3    2    1    0\n[5,]    2    3    4    3    2    1    0    0\n[6,]    1    2    3    2    1    0    0    0\n[7,]    0    1    2    1    0    0    0    0\n[8,]    0    0    1    0    0    0    0    0\n```\n",
				"date_published": "2022-03-25T23:02:00+10:30",
				"url": "https://jcarroll.xyz/2022/03/25/r-challenge-contour.html",
				"tags": ["R"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/03/20/rowwise-optimizations-in.html",
				"title": "ByRow optimizations in Julia",
				"content_html": "<p>I&rsquo;m still fairly new to Julia, even though I&rsquo;ve been trying to learn it for a few years. It&rsquo;s <em>extremely</em> powerful (fast, expressive, &hellip; whatever metric you want to use) but with that comes some complexity.</p>\n<p>I saw <a href=\"https://bkamins.github.io/julialang/2022/02/25/anyall.html\">this post</a> in my feed and it seemed like a great bite-sized chunk of code to learn from. I <em>think</em> I understand everything that&rsquo;s happening, even if I certainly couldn&rsquo;t write that myself, with one exception.</p>\n<p>The connection that for <code>Bool</code> data, <code>all()</code> is equivalent to <code>minimum()</code> (it&rsquo;s false as soon as there is one 0, otherwise it&rsquo;s true) and <code>any()</code> is equivalent to <code>maximum()</code> (if there&rsquo;s a 1 it&rsquo;s true) took me a moment, but seems pretty cool. That wasn&rsquo;t the problem I had.</p>\n<p>The bit that surprised me was that for <code>ByRow</code> calculations on a <code>DataFrame</code>, <code>minimum()</code> is <strong>faster</strong> than <code>all()</code>. The reason this is so surprising for me is that I understand <code>all()</code> from an R-perspective and my understanding was that <code>all()</code> could short-circuit because as soon as it sees a <code>FALSE</code> it can ignore any other values - the result is guaranteed to be <code>FALSE</code> (yes, yes, up to missingness). Surely, a calculation of <code>minimum()</code> needs to evaluate every value at least once (?). Where this might (must?) fall apart is that I&rsquo;m thinking purely of vectors. Sure enough, checking out some timings on a vector in Julia shows <code>all()</code> is near-instantaneous (after compilation)</p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">x = rand(Bool, 100_000_000)\n\n@time all(x)\n  0.009047 seconds (218 allocations: 9.531 KiB, 99.85% compilation time)\nfalse\n\n@time all(x)\n  0.000002 seconds\nfalse\n\n@time minimum(x)\n  0.091183 seconds (85.03 k allocations: 4.461 MiB, 41.98% compilation time)\nfalse\n\n@time minimum(x)\n  0.052287 seconds\nfalse\n</code></pre><p>I get similar results, expectedly, from R</p>\n<pre tabindex=\"0\"><code class=\"language-{r}\" data-lang=\"{r}\">x &lt;- sample(c(TRUE, FALSE), 1e8, replace = TRUE)\nmicrobenchmark::microbenchmark(\n  min = max(x),\n  any = any(x),\n  times = 10\n)\n# Unit: nanoseconds\n#  expr       min        lq        mean    median        uq       max neval\n#   min 208741173 210539351 223219500.3 212388892 222673528 285974960    10\n#   any       160       187      2403.4       295      5095      7451    10\n</code></pre><p>So, what&rsquo;s going on? I <em>think</em> the answer is that we&rsquo;re not dealing with just a vector, it&rsquo;s rows from a <code>DataFrame</code>, right? Now, from the R side, that&rsquo;s complicated enough - <code>rowwise()</code> is a <a href=\"https://speakerdeck.com/jennybc/row-oriented-workflows-in-r-with-the-tidyverse\">necessary thing</a> because R stores a <code>data.frame</code> as a list of vectors representing <em>columns</em>, so extracting a row means slicing across those.</p>\n<p>I can reproduce the speedup in Julia (and honestly, I struggle to find a clean and fast way to do it in R) but the statement &ldquo;<a href=\"https://bkamins.github.io/julialang/2022/02/25/anyall.html#:~:text=This%20time%20things%20are%20very%20fast%2C%20as%20row%2Dwise%20aggregation%20for%20maximum%20and%20minimum%20is%20optimized.\">This time things are very fast, as row-wise aggregation for maximum and minimum is optimized.</a>&rdquo; got me thinking - where should I have learned that? Google isn&rsquo;t showing me any relevant results, so is this just a known thing? I can imagine that such an optimization for doing this might exist, but can anyone provide a reference or guide?? The author of the blog post used this optimization in a <a href=\"https://stackoverflow.com/a/71209103/4168169\">StackOverflow answer</a> without challenge (no reference provided) so I feel like it&rsquo;s potentially just something I should know.</p>\n",
				"content_text": "I'm still fairly new to Julia, even though I've been trying to learn it for a few years. It's *extremely* powerful (fast, expressive, ... whatever metric you want to use) but with that comes some complexity. \n\nI saw [this post](https://bkamins.github.io/julialang/2022/02/25/anyall.html) in my feed and it seemed like a great bite-sized chunk of code to learn from. I *think* I understand everything that's happening, even if I certainly couldn't write that myself, with one exception.\n\nThe connection that for `Bool` data, `all()` is equivalent to `minimum()` (it's false as soon as there is one 0, otherwise it's true) and `any()` is equivalent to `maximum()` (if there's a 1 it's true) took me a moment, but seems pretty cool. That wasn't the problem I had.\n\nThe bit that surprised me was that for `ByRow` calculations on a `DataFrame`, `minimum()` is **faster** than `all()`. The reason this is so surprising for me is that I understand `all()` from an R-perspective and my understanding was that `all()` could short-circuit because as soon as it sees a `FALSE` it can ignore any other values - the result is guaranteed to be `FALSE` (yes, yes, up to missingness). Surely, a calculation of `minimum()` needs to evaluate every value at least once (?). Where this might (must?) fall apart is that I'm thinking purely of vectors. Sure enough, checking out some timings on a vector in Julia shows `all()` is near-instantaneous (after compilation)\n```{julia}\nx = rand(Bool, 100_000_000)\n\n@time all(x)\n  0.009047 seconds (218 allocations: 9.531 KiB, 99.85% compilation time)\nfalse\n\n@time all(x)\n  0.000002 seconds\nfalse\n\n@time minimum(x)\n  0.091183 seconds (85.03 k allocations: 4.461 MiB, 41.98% compilation time)\nfalse\n\n@time minimum(x)\n  0.052287 seconds\nfalse\n```\nI get similar results, expectedly, from R\n```{r}\nx <- sample(c(TRUE, FALSE), 1e8, replace = TRUE)\nmicrobenchmark::microbenchmark(\n  min = max(x),\n  any = any(x),\n  times = 10\n)\n# Unit: nanoseconds\n#  expr       min        lq        mean    median        uq       max neval\n#   min 208741173 210539351 223219500.3 212388892 222673528 285974960    10\n#   any       160       187      2403.4       295      5095      7451    10\n```\nSo, what's going on? I *think* the answer is that we're not dealing with just a vector, it's rows from a `DataFrame`, right? Now, from the R side, that's complicated enough - `rowwise()` is a [necessary thing](https://speakerdeck.com/jennybc/row-oriented-workflows-in-r-with-the-tidyverse) because R stores a `data.frame` as a list of vectors representing *columns*, so extracting a row means slicing across those. \n\nI can reproduce the speedup in Julia (and honestly, I struggle to find a clean and fast way to do it in R) but the statement \"[This time things are very fast, as row-wise aggregation for maximum and minimum is optimized.](https://bkamins.github.io/julialang/2022/02/25/anyall.html#:~:text=This%20time%20things%20are%20very%20fast%2C%20as%20row%2Dwise%20aggregation%20for%20maximum%20and%20minimum%20is%20optimized.)\" got me thinking - where should I have learned that? Google isn't showing me any relevant results, so is this just a known thing? I can imagine that such an optimization for doing this might exist, but can anyone provide a reference or guide?? The author of the blog post used this optimization in a [StackOverflow answer](https://stackoverflow.com/a/71209103/4168169) without challenge (no reference provided) so I feel like it's potentially just something I should know.\n",
				"date_published": "2022-03-20T14:11:00+10:30",
				"url": "https://jcarroll.xyz/2022/03/20/rowwise-optimizations-in.html",
				"tags": ["R","Julia"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/03/20/first-post-on.html",
				"title": "First post on jcarroll.xyz",
				"content_html": "<p>I like blogging, but in the spirit of lowering the resistance to getting posts out, I&rsquo;ve started a micro blog <a href=\"https://jcarroll.xyz\">jcarroll.xyz</a> where I&rsquo;ll capture shorter, less polished pieces and random thoughts / snippets.</p>\n<p>This is my first post, testing all the functionality. DNS might still take a little while, so don&rsquo;t worry if you see my full blog when you click the link.</p>\n",
				"content_text": "I like blogging, but in the spirit of lowering the resistance to getting posts out, I've started a micro blog [jcarroll.xyz](https://jcarroll.xyz) where I'll capture shorter, less polished pieces and random thoughts / snippets.\n\nThis is my first post, testing all the functionality. DNS might still take a little while, so don't worry if you see my full blog when you click the link.\n",
				"date_published": "2022-03-20T12:28:39+10:30",
				"url": "https://jcarroll.xyz/2022/03/20/first-post-on.html"
			}
	]
}
