{
	"version": "https://jsonfeed.org/version/1",
	"title": "Jonathan Carroll's micro blog",
	"icon": "https://micro.blog/jonocarroll/avatar.jpg",
	"home_page_url": "https://jcarroll.xyz/",
	"feed_url": "https://jcarroll.xyz/feed.json",
	"items": [
		
			{
				"id": "http://jonocarroll.micro.blog/2023/03/12/finished-reading-chess.html",
				"title": "Finished reading: 500 Chess Questions Answered by Andrew Soltis ðŸ“š",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9781849947596\">500 Chess Questions Answered</a> by Andrew Soltis ðŸ“š</p>\n<p>Not a novel and not a textbook, but it took long enough to read that it deserves mention. This is full of valuable tips and notes, but aside from reading it cover to cover, it doesn&rsquo;t serve much use as a reference. There were a few points about calculating that I can incorporate into my games, but otherwise, it seems to be focused at beginners despite having some pretty complex examples.</p>\n<p>If you&rsquo;re new to the game, it&rsquo;s worth a read.</p>\n<p>I&rsquo;m jonocarroll on lichess.org and chess.com if anyone wants a game. My Elo is currently around 1100 (rapid).</p>\n",
				"content_text": "Finished reading: [500 Chess Questions Answered](https://micro.blog/books/9781849947596) by Andrew Soltis ðŸ“š\r\n\r\nNot a novel and not a textbook, but it took long enough to read that it deserves mention. This is full of valuable tips and notes, but aside from reading it cover to cover, it doesn't serve much use as a reference. There were a few points about calculating that I can incorporate into my games, but otherwise, it seems to be focused at beginners despite having some pretty complex examples.\r\n\r\nIf you're new to the game, it's worth a read.\r\n\r\nI'm jonocarroll on lichess.org and chess.com if anyone wants a game. My Elo is currently around 1100 (rapid).\n",
				"date_published": "2023-03-12T14:09:11+10:30",
				"url": "https://jcarroll.xyz/2023/03/12/finished-reading-chess.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/03/05/220456.html",
				"title": "Finished reading: The Apocalypse Seven by Gene Doucette ðŸ“š",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9780358418948\">The Apocalypse Seven</a> by Gene Doucette ðŸ“š</p>\n<p>As soon as I finished <a href=\"https://jcarroll.xyz/2023/03/05/finished-reading-the.html\">The Spaceship Next Door</a> I had a look for the author&rsquo;s other books. I got mixed up between a couple and I thought this one was the sequel. It&rsquo;s not, but I borrowed a copy anyway.</p>\n<p>This is a different story, but told with the same narrative style that again feels distinct from most other sci-fi I&rsquo;ve read. Still very enjoyable; I finished this one in just a few evenings.</p>\n<p>My only gripe with this book was that the author clearly had a familiarity with the area (they note that they spent quite a bit of time there in real life) but I&rsquo;ve never been to <a href=\"https://www.google.com/maps/search/Harvard+University,+Cambridge,+MA,+USA/@42.3733004,-71.1183839,14.64z\">Cambridge</a> and so the frequent specific references to real streets and landmarks were all lost on me. Despite that, I could certainly follow along and enjoyed the story.</p>\n<p>Another fun read. I&rsquo;m looking forward to getting a copy of the actual sequel to that first book.</p>\n",
				"content_text": "Finished reading: [The Apocalypse Seven](https://micro.blog/books/9780358418948) by Gene Doucette ðŸ“š\r\n\r\nAs soon as I finished [The Spaceship Next Door](https://jcarroll.xyz/2023/03/05/finished-reading-the.html) I had a look for the author's other books. I got mixed up between a couple and I thought this one was the sequel. It's not, but I borrowed a copy anyway.\r\n\r\nThis is a different story, but told with the same narrative style that again feels distinct from most other sci-fi I've read. Still very enjoyable; I finished this one in just a few evenings. \r\n\r\nMy only gripe with this book was that the author clearly had a familiarity with the area (they note that they spent quite a bit of time there in real life) but I've never been to [Cambridge](https://www.google.com/maps/search/Harvard+University,+Cambridge,+MA,+USA/@42.3733004,-71.1183839,14.64z) and so the frequent specific references to real streets and landmarks were all lost on me. Despite that, I could certainly follow along and enjoyed the story.\r\n\r\nAnother fun read. I'm looking forward to getting a copy of the actual sequel to that first book.\n",
				"date_published": "2023-03-05T22:04:56+10:30",
				"url": "https://jcarroll.xyz/2023/03/05/220456.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/03/05/215624.html",
				"title": "Finished reading: The Phoenix Project by Gene Kim ðŸ“š",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9781942788294\">The Phoenix Project</a> by Gene Kim ðŸ“š</p>\n<p>I was on the fence about this one; I&rsquo;ve managed a tech team before but I&rsquo;m not currently in charge of anyone so I&rsquo;ve about had my fill of &lsquo;mangement&rsquo; information books. With that said, this is a novel that tells a story which happens to describe some best practices and approaches for running (or being in) a tech team.</p>\n<p>The part I really like is <a href=\"https://itrevolution.com/articles/the-three-ways-principles-underpinning-devops/\">The Three Ways</a> principles and I think there&rsquo;s insight there for anyone working in a project of any kind. The story makes a lot of parallels between manufacturing physical goods and &lsquo;knowledge work&rsquo;, focussing on bottlenecks, and planning, and if you haven&rsquo;t thought about your project in that way then I&rsquo;d say definitely pick up this book. &ldquo;Go fast and break things&rdquo; runs counter to a lot of that, but eventually you&rsquo;re going to need to build something a bit more robust, and some planning will be of great benefit.</p>\n<p>The writing itself felt a little forced, but perhaps I just don&rsquo;t deal with people who talk like that (?).</p>\n<p>If you&rsquo;re near the top of a tech-focussed team, I recommend you have a read. There might not be anything new to you in there, but if there is, it&rsquo;ll be useful.</p>\n",
				"content_text": "Finished reading: [The Phoenix Project](https://micro.blog/books/9781942788294) by Gene Kim ðŸ“š\r\n\r\nI was on the fence about this one; I've managed a tech team before but I'm not currently in charge of anyone so I've about had my fill of 'mangement' information books. With that said, this is a novel that tells a story which happens to describe some best practices and approaches for running (or being in) a tech team.\r\n\r\nThe part I really like is [The Three Ways](https://itrevolution.com/articles/the-three-ways-principles-underpinning-devops/) principles and I think there's insight there for anyone working in a project of any kind. The story makes a lot of parallels between manufacturing physical goods and 'knowledge work', focussing on bottlenecks, and planning, and if you haven't thought about your project in that way then I'd say definitely pick up this book. \"Go fast and break things\" runs counter to a lot of that, but eventually you're going to need to build something a bit more robust, and some planning will be of great benefit.\r\n\r\nThe writing itself felt a little forced, but perhaps I just don't deal with people who talk like that (?).\r\n\r\nIf you're near the top of a tech-focussed team, I recommend you have a read. There might not be anything new to you in there, but if there is, it'll be useful.\n",
				"date_published": "2023-03-05T21:56:24+10:30",
				"url": "https://jcarroll.xyz/2023/03/05/215624.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/03/05/finished-reading-jellyfish.html",
				"title": "Finished reading: Jellyfish Age Backwards by Nicklas Brendborg ðŸ“š",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9781529387926\">Jellyfish Age Backwards</a> by Nicklas Brendborg ðŸ“š</p>\n<p>Another recommendation from social media, if I recall. This had a lot of really interesting information about aging across species, some things we&rsquo;ve discovered that influence it, and some things that don&rsquo;t. The focus extended beyond just humans, so this was a really nice broad exploration with neat comparisons and details about unique species.</p>\n<p>Nothing too complex in there, but well worth a read.</p>\n",
				"content_text": "Finished reading: [Jellyfish Age Backwards](https://micro.blog/books/9781529387926) by Nicklas Brendborg ðŸ“š\r\n\r\nAnother recommendation from social media, if I recall. This had a lot of really interesting information about aging across species, some things we've discovered that influence it, and some things that don't. The focus extended beyond just humans, so this was a really nice broad exploration with neat comparisons and details about unique species.\r\n\r\nNothing too complex in there, but well worth a read.\n",
				"date_published": "2023-03-05T21:45:44+10:30",
				"url": "https://jcarroll.xyz/2023/03/05/finished-reading-jellyfish.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/03/05/finished-reading-the.html",
				"title": "Finished reading: The Spaceship Next Door by Gene Doucette ðŸ“š",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9781328567543\">The Spaceship Next Door</a> by Gene Doucette ðŸ“š</p>\n<p>I like to mix in some fiction between more serious topics, and someone recommended this. I couldn&rsquo;t find a physical copy anywhere so I tried out my library&rsquo;s ebook offering (<a href=\"https://www.overdrive.com/apps/libby\">Libby</a>). I&rsquo;d have preferred to use my new Kindle Scribe, but this worked okay enough on my phone.</p>\n<p>The author has a refreshing narrative style for sci-fi; something I can&rsquo;t quite put my finger on, but it was a very enjoyable read. Some twists and turns and none of it felt too forced or strayed too far from the main storyline. I&rsquo;m not quite sure it&rsquo;s the kind of story I&rsquo;d come back to again and again but I genuinely enjoyed it and have a hold on a physical copy of the sequel already (plus another from the author).</p>\n<p>Thumbs up, worth a read.</p>\n",
				"content_text": "Finished reading: [The Spaceship Next Door](https://micro.blog/books/9781328567543) by Gene Doucette ðŸ“š\r\n\r\nI like to mix in some fiction between more serious topics, and someone recommended this. I couldn't find a physical copy anywhere so I tried out my library's ebook offering ([Libby](https://www.overdrive.com/apps/libby)). I'd have preferred to use my new Kindle Scribe, but this worked okay enough on my phone.\r\n\r\nThe author has a refreshing narrative style for sci-fi; something I can't quite put my finger on, but it was a very enjoyable read. Some twists and turns and none of it felt too forced or strayed too far from the main storyline. I'm not quite sure it's the kind of story I'd come back to again and again but I genuinely enjoyed it and have a hold on a physical copy of the sequel already (plus another from the author).\r\n\r\nThumbs up, worth a read.\n",
				"date_published": "2023-03-05T21:41:05+10:30",
				"url": "https://jcarroll.xyz/2023/03/05/finished-reading-the.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/03/05/finished-reading-human.html",
				"title": "Finished reading: 10% Human: How Your Bodyâ€™s Microbes Hold The Key To Health And Happiness by Alanna Collen ðŸ“š",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9780007584048\">10% Human: How Your Bodyâ€™s Microbes Hold The Key To Health And Happiness</a> by Alanna Collen ðŸ“š</p>\n<p>I had this one on my shelf for a while and I&rsquo;m very happy I finally got around to reading it. I knew (roughly) that we have a vast microbiome within our gut, but I hadn&rsquo;t really seen most of the details about just how impactful we now know that to be to our health. In particular, I wasn&rsquo;t aware of the connection to eating fiber; my understanding only extended as far as fiber being something indigestible that helped keep things moving right. As it turns out, there&rsquo;s a whole lot more to it, and a lot involves gut bacteria.</p>\n<p>Sure enough, I&rsquo;ve vastly increased my fiber intake (gradually) after reading this. I&rsquo;m also very curious about what we might be able to learn about the intersection of autoimmune (and other) diseases and the microbiome.</p>\n<p>I&rsquo;ve since been recommended a slightly newer <a href=\"https://micro.blog/books/9780062368621\">book</a> on this topic which I now have a copy of.</p>\n<p>Highly recommended - if you read this and don&rsquo;t increase your fiber intake / support your microbiome, I&rsquo;ll be surprised.</p>\n",
				"content_text": "Finished reading: [10% Human: How Your Bodyâ€™s Microbes Hold The Key To Health And Happiness](https://micro.blog/books/9780007584048) by Alanna Collen ðŸ“š\n\nI had this one on my shelf for a while and I'm very happy I finally got around to reading it. I knew (roughly) that we have a vast microbiome within our gut, but I hadn't really seen most of the details about just how impactful we now know that to be to our health. In particular, I wasn't aware of the connection to eating fiber; my understanding only extended as far as fiber being something indigestible that helped keep things moving right. As it turns out, there's a whole lot more to it, and a lot involves gut bacteria.\n\nSure enough, I've vastly increased my fiber intake (gradually) after reading this. I'm also very curious about what we might be able to learn about the intersection of autoimmune (and other) diseases and the microbiome.\n\nI've since been recommended a slightly newer [book](https://micro.blog/books/9780062368621) on this topic which I now have a copy of.\n\nHighly recommended - if you read this and don't increase your fiber intake / support your microbiome, I'll be surprised.\n",
				"date_published": "2023-03-05T21:34:13+10:30",
				"url": "https://jcarroll.xyz/2023/03/05/finished-reading-human.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/03/05/finished-reading-once.html",
				"title": "Finished reading: Once Upon an Algorithm by Martin Erwig ðŸ“š",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9780262545297\">Once Upon an Algorithm</a> by Martin Erwig ðŸ“š</p>\n<p>I liked the premise of this book - algorithms taught with examples from classic children&rsquo;s tales. I didn&rsquo;t finish it, however - it was just too wordy (I got about halfway through). In fairness, I started with a very similar approach to <a href=\"https://beyondspreadsheetswithr.com/\">my own book</a> which for a while had a working title of &ldquo;The R Handyman&rdquo; with allusions to power tools, tool belts, hand tools, etc&hellip; but the metaphors felt too forced after a while and we changed tack to focus on the programming without them.</p>\n<p>What I did read was well presented and went into some decent detail about software design, algorithms, and complexity. At some point, though, I think some sort of implementations were necessary to bring it all together, and this book lacked that.</p>\n<p>Worth a try, but if you&rsquo;re really into algorithms I&rsquo;d say get a book with implementations (e.g. <a href=\"https://jcarroll.xyz/2023/01/29/finished-reading-the.html\">this one</a>).</p>\n",
				"content_text": "Finished reading: [Once Upon an Algorithm](https://micro.blog/books/9780262545297) by Martin Erwig ðŸ“š\r\n\r\nI liked the premise of this book - algorithms taught with examples from classic children's tales. I didn't finish it, however - it was just too wordy (I got about halfway through). In fairness, I started with a very similar approach to [my own book](https://beyondspreadsheetswithr.com/) which for a while had a working title of \"The R Handyman\" with allusions to power tools, tool belts, hand tools, etc... but the metaphors felt too forced after a while and we changed tack to focus on the programming without them.\r\n\r\nWhat I did read was well presented and went into some decent detail about software design, algorithms, and complexity. At some point, though, I think some sort of implementations were necessary to bring it all together, and this book lacked that.\r\n\r\nWorth a try, but if you're really into algorithms I'd say get a book with implementations (e.g. [this one](https://jcarroll.xyz/2023/01/29/finished-reading-the.html)).\n",
				"date_published": "2023-03-05T21:22:04+10:30",
				"url": "https://jcarroll.xyz/2023/03/05/finished-reading-once.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/03/01/finished-reading-the.html",
				"title": "Finished reading: The Book of Why by Judea Pearl ðŸ“š",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9780241242643\">The Book of Why</a> by Judea Pearl ðŸ“š</p>\n<p>This was the topic of a book club at work but I&rsquo;m really glad I read it. My scepticism going in was probably typical of someone not all that familiar with causal analysis, believing that we can just throw all the variables at a regression model and get an answer - anything uncorrelated will have a small coefficient and we can dispose of it. This book - while it takes a slightly arrogant/high-and-mighty approach to getting there - carefully explains that this approach works <em>only</em> if there is no dependency between the variables. This is, of course, structured into the regression model assumptions that the covariates are &ldquo;<em>independent</em> and identically distributed&rdquo; (i.i.d.) but who checks assumptions? It goes into depth about the different ways that covariates can be connected; how to route around some of them; and how to figure out which ones to include.</p>\n<p>Some of the examples seemed a bit too strawman for my liking, but I do think the general foundation is pretty solid. It&rsquo;s a bit odd to have what should really be a textbook in causal analysis as a prose-heavy combination of history and wordy examples, but then again I can&rsquo;t say I&rsquo;d have picked up the textbook and read it cover-to-cover like this.</p>\n<p>Overall, I think this should be on any data scientist&rsquo;s reading list at some point. I have a bunch of follow-on reading to get through now, but I&rsquo;m much less likely to make the simple errors in my own statistical analyses (even if I do need to find an analyst who <em>can</em> work it out).</p>\n",
				"content_text": "Finished reading: [The Book of Why](https://micro.blog/books/9780241242643) by Judea Pearl ðŸ“š\r\n\r\nThis was the topic of a book club at work but I'm really glad I read it. My scepticism going in was probably typical of someone not all that familiar with causal analysis, believing that we can just throw all the variables at a regression model and get an answer - anything uncorrelated will have a small coefficient and we can dispose of it. This book - while it takes a slightly arrogant/high-and-mighty approach to getting there - carefully explains that this approach works _only_ if there is no dependency between the variables. This is, of course, structured into the regression model assumptions that the covariates are \"*independent* and identically distributed\" (i.i.d.) but who checks assumptions? It goes into depth about the different ways that covariates can be connected; how to route around some of them; and how to figure out which ones to include.\r\n\r\nSome of the examples seemed a bit too strawman for my liking, but I do think the general foundation is pretty solid. It's a bit odd to have what should really be a textbook in causal analysis as a prose-heavy combination of history and wordy examples, but then again I can't say I'd have picked up the textbook and read it cover-to-cover like this.\r\n\r\nOverall, I think this should be on any data scientist's reading list at some point. I have a bunch of follow-on reading to get through now, but I'm much less likely to make the simple errors in my own statistical analyses (even if I do need to find an analyst who _can_ work it out).\n",
				"date_published": "2023-03-01T18:57:26+10:30",
				"url": "https://jcarroll.xyz/2023/03/01/finished-reading-the.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/01/29/finished-reading-the.html",
				"title": "Finished reading: The Self-Taught Computer Scientist by Cory Althoff ðŸ“š",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9781119724339\">The Self-Taught Computer Scientist</a> by Cory Althoff ðŸ“š</p>\n<p>This is the book I wish I&rsquo;d read before doing <a href=\"https://adventofcode.com/2022\">Advent of Code</a> - a full blog post on that will eventually be on my <a href=\"https://jcarroll.com.au\">main blog</a>; I finished both parts of all 25 exercises in (strictly) base R, and am more than halfway through re-doing all of them in Rust. I was surprised at how much computer science was needed to solve these, but I did enjoy what I learned along the way, so actually reading up on some of it seemed like a good idea.</p>\n<p>This book is the follow-on from <a href=\"https://micro.blog/books/9781472147097\">&lsquo;The Self Taught Programmer&rsquo;</a> (now on my to-read list) and does a really good job of walking through the concepts, partly framed at setting the reader up for being able to solve the typical software engineering interview questions. The code is python, which is approachable enough. There&rsquo;s some minor funkiness of seeing</p>\n<pre tabindex=\"0\"><code class=\"language-{python}\" data-lang=\"{python}\">if condition:\r\n  return True\r\nelse:\r\n  return False\r\n</code></pre><p>rather than just returning <code>condition</code> but otherwise the code is carefully explained. I believe this has the best explanations I&rsquo;ve seen of &lsquo;big O notation&rsquo; for time complexity and how the different variations arise. Similarly, this is the first time I&rsquo;ve understood what a linked list and binary tree are (and how/why someone may want to invert them - I&rsquo;ve only seen the stereotypical interview question).</p>\n<p>As always, the more you learn about programming in one language the more you learn about all the other languages you know, so now I&rsquo;m interested in understanding some of these concepts from an R perspective. I certainly made use of <code>VecDeque</code> and <code>HashMap</code> in my Rust AoC solutions, but in R I was stuck with poorly-performing <code>vector</code> and <code>list</code> objects, which I occasionally improved with an <code>environment</code>. I was very happy to see that R 4.2.2 gains <code>utils::hashtab()</code> (<a href=\"https://stat.ethz.ch/R-manual/R-devel/library/utils/html/hashtab.html\">link</a>)!.</p>\n<p>Overall I was happy with this book. A great introduction to the concepts, and some useful approaches to interview questions (if you&rsquo;re likely to be asked them).</p>\n",
				"content_text": "Finished reading: [The Self-Taught Computer Scientist](https://micro.blog/books/9781119724339) by Cory Althoff ðŸ“š\r\n\r\nThis is the book I wish I'd read before doing [Advent of Code](https://adventofcode.com/2022) - a full blog post on that will eventually be on my [main blog](https://jcarroll.com.au); I finished both parts of all 25 exercises in (strictly) base R, and am more than halfway through re-doing all of them in Rust. I was surprised at how much computer science was needed to solve these, but I did enjoy what I learned along the way, so actually reading up on some of it seemed like a good idea.\r\n\r\nThis book is the follow-on from ['The Self Taught Programmer'](https://micro.blog/books/9781472147097) (now on my to-read list) and does a really good job of walking through the concepts, partly framed at setting the reader up for being able to solve the typical software engineering interview questions. The code is python, which is approachable enough. There's some minor funkiness of seeing\r\n\r\n```{python}\r\nif condition:\r\n  return True\r\nelse:\r\n  return False\r\n```\r\n\r\nrather than just returning `condition` but otherwise the code is carefully explained. I believe this has the best explanations I've seen of 'big O notation' for time complexity and how the different variations arise. Similarly, this is the first time I've understood what a linked list and binary tree are (and how/why someone may want to invert them - I've only seen the stereotypical interview question).\r\n\r\nAs always, the more you learn about programming in one language the more you learn about all the other languages you know, so now I'm interested in understanding some of these concepts from an R perspective. I certainly made use of `VecDeque` and `HashMap` in my Rust AoC solutions, but in R I was stuck with poorly-performing `vector` and `list` objects, which I occasionally improved with an `environment`. I was very happy to see that R 4.2.2 gains `utils::hashtab()` ([link](https://stat.ethz.ch/R-manual/R-devel/library/utils/html/hashtab.html))!. \r\n\r\nOverall I was happy with this book. A great introduction to the concepts, and some useful approaches to interview questions (if you're likely to be asked them).\n",
				"date_published": "2023-01-29T15:38:08+10:30",
				"url": "https://jcarroll.xyz/2023/01/29/finished-reading-the.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/01/26/finished-reading-living.html",
				"title": "Finished reading: Living in Data by Jer Thorp ðŸ“š",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9781250849151\">Living in Data</a> by Jer Thorp ðŸ“š</p>\n<p>(<a href=\"https://jcarroll.xyz/2023/01/20/currently-reading-living.html\">previously</a>)</p>\n<p>As a data person, this book spoke to me deeply. As someone who has worked with collected data many times, it offered a fresh insight into understanding nuances of data, where it has come from, how it is <em>never</em> collected without human involvement, and how biases are embedded into every bit and byte.</p>\n<p>Reading this at the same time as <a href=\"https://jcarroll.xyz/2023/01/26/finished-reading-the.html\">The Checklist Manifesto</a> was timely as there is a lot of overlap between the ideas in terms of gathering data.</p>\n<p>There were many great examples of &ldquo;practical visualisations&rdquo; and real-world projects involving an intersection of art and (data) science. One of the most interesting was a project involving planting genetically identical trees across a wide area, the idea being that &ldquo;how they grow&rdquo; reflects the local conditions, and as such they are a proxy for data about each area. It&rsquo;s a <a href=\"https://www.deeproot.com/blog/blog-entries/onetrees-the-forgotten-tree-art-project/\">somewhat lost project</a> it seems, but interesting nonetheless.</p>\n<p>My very minor nitpick about this one was the very common American-ism of assuming everyone is in the Northern Hemisphere, and as such &ldquo;winter&rdquo; and &ldquo;spring&rdquo; refer to unique times of the year. It reminded me of the bias inherent in the construction of the &lsquo;north is up&rsquo; mental model of the world</p>\n<!-- raw HTML omitted -->\n<p>(you do have to choose some direction, and any is as good as any other, but it&rsquo;s a choice).</p>\n<p>I loved reading this book, and I will be strongly recommending it to everyone who works with data. I am very happy that I picked up this one - sometimes browsing the shelves randomly works.</p>\n",
				"content_text": "Finished reading: [Living in Data](https://micro.blog/books/9781250849151) by Jer Thorp ðŸ“š\n\n([previously](https://jcarroll.xyz/2023/01/20/currently-reading-living.html))\n\nAs a data person, this book spoke to me deeply. As someone who has worked with collected data many times, it offered a fresh insight into understanding nuances of data, where it has come from, how it is *never* collected without human involvement, and how biases are embedded into every bit and byte.\n\nReading this at the same time as [The Checklist Manifesto](https://jcarroll.xyz/2023/01/26/finished-reading-the.html) was timely as there is a lot of overlap between the ideas in terms of gathering data.\n\nThere were many great examples of \"practical visualisations\" and real-world projects involving an intersection of art and (data) science. One of the most interesting was a project involving planting genetically identical trees across a wide area, the idea being that \"how they grow\" reflects the local conditions, and as such they are a proxy for data about each area. It's a [somewhat lost project](https://www.deeproot.com/blog/blog-entries/onetrees-the-forgotten-tree-art-project/) it seems, but interesting nonetheless.\n\nMy very minor nitpick about this one was the very common American-ism of assuming everyone is in the Northern Hemisphere, and as such \"winter\" and \"spring\" refer to unique times of the year. It reminded me of the bias inherent in the construction of the 'north is up' mental model of the world\n\n<img src=\"uploads/2023/5254ada67e.jpg\" width=\"600\" height=\"366\" alt=\"\">\n\n(you do have to choose some direction, and any is as good as any other, but it's a choice).\n\nI loved reading this book, and I will be strongly recommending it to everyone who works with data. I am very happy that I picked up this one - sometimes browsing the shelves randomly works.\n",
				"date_published": "2023-01-26T15:28:23+10:30",
				"url": "https://jcarroll.xyz/2023/01/26/finished-reading-living.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/01/26/finished-reading-the.html",
				"title": "Finished reading: The Checklist Manifesto by Atul Gawande ðŸ“š",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9781846683145\">The Checklist Manifesto</a> by Atul Gawande ðŸ“š</p>\n<p>I honestly didn&rsquo;t know what I was getting when I placed a library hold on this book - a recommendation from somewhere, but I assumed it was about something like how to write good checklists or manage priorities. This is not that book. This is a wild ride through the ways that some checklists have been used by the author and others throughout history. Not just any checklists, mind you - it&rsquo;s a tour of how a very important checklist was designed, refined, and implemented. The side-stories are often confronting, impactful, and very entertainingly spun together. I clicked &lsquo;confirm purchase&rsquo; on my own copy of this book before I had finished reading it. I suspect I&rsquo;ll come back to this one again.</p>\n<p>Highly recommended to anyone and everyone, but especially anyone who wants to ensure that things actually get done.</p>\n",
				"content_text": "Finished reading: [The Checklist Manifesto](https://micro.blog/books/9781846683145) by Atul Gawande ðŸ“š\r\n\r\nI honestly didn't know what I was getting when I placed a library hold on this book - a recommendation from somewhere, but I assumed it was about something like how to write good checklists or manage priorities. This is not that book. This is a wild ride through the ways that some checklists have been used by the author and others throughout history. Not just any checklists, mind you - it's a tour of how a very important checklist was designed, refined, and implemented. The side-stories are often confronting, impactful, and very entertainingly spun together. I clicked 'confirm purchase' on my own copy of this book before I had finished reading it. I suspect I'll come back to this one again.\r\n\r\nHighly recommended to anyone and everyone, but especially anyone who wants to ensure that things actually get done.\n",
				"date_published": "2023-01-26T15:06:38+10:30",
				"url": "https://jcarroll.xyz/2023/01/26/finished-reading-the.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/01/26/finished-reading-our.html",
				"title": "Finished reading: Our Data, Ourselves by Jacqueline D. Lipton ðŸ“š",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9780520390508\">Our Data, Ourselves</a> by Jacqueline D. Lipton ðŸ“š</p>\n<p>I abandoned this book after a few chapters. I wasn&rsquo;t sure how much I really wanted to read a book about technology and data where the author claims on page 10 that</p>\n<blockquote>\n<p>&ldquo;RFID can be monitored at a distance. You do not need a digital reader in the proximity of the device to locate and &lsquo;read&rsquo; its information. RFID microchips are implanted in livestock and pets to help find them if they are lost. They are implanted into digital devices, notably automobiles, to find them if they become stolen or lost, or simply to track them for work or other purposes.&rdquo;</p>\n</blockquote>\n<p>This is&hellip; somewhere between blatantly wrong and misunderstood. RFID <em>is</em> used for these things (microchips in animals, automobile assembly lines, books at a library) but it&rsquo;s used over very short distances, and is entirely passive (the tag is not powered). Someone has apparently managed to <a href=\"https://www.theregister.com/2006/01/30/dutch_biometric_passport_crack/\">read a passport</a> from about 10 metres using special equipment, but that&rsquo;s far from standard usage. I don&rsquo;t think you can just &ldquo;find&rdquo; an RFID tag in the wild with any reader. You <em>can</em> use one to identify a <em>found</em> animal, or which automobile is passing a sensor in a factory, or which book is being checked out, but there&rsquo;s definitely some strong notion of &ldquo;proximity&rdquo; involved, as far as I&rsquo;m aware (please correct me if I&rsquo;m wrong). I believe RFID is used in automated highway toll collection, but it involves significant power, likely not passively.</p>\n<p>That left a bad enough taste in my (mind)mouth that I wasn&rsquo;t particularly open to reading in great depth about (very specifically) American law</p>\n<blockquote>\n<p>This book focuses on the American position on individual privacy</p>\n</blockquote>\n<p>especially with the note that</p>\n<blockquote>\n<p>our powerful First Amendment protections of free speech-that is, speech free from government interference-have been regarded as limiting laws that restrict what we can say about each other.</p>\n</blockquote>\n<p>I can only read so many &ldquo;Someone vs Someone&rdquo; names of legal precedents and US-specific names of agencies, court jurisdictions, etc. before giving up. This may be of more interest to someone in the US interested in specific legal aspects, but it&rsquo;s not for me.</p>\n",
				"content_text": "Finished reading: [Our Data, Ourselves](https://micro.blog/books/9780520390508) by Jacqueline D. Lipton ðŸ“š\r\n\r\nI abandoned this book after a few chapters. I wasn't sure how much I really wanted to read a book about technology and data where the author claims on page 10 that\r\n\r\n> \"RFID can be monitored at a distance. You do not need a digital reader in the proximity of the device to locate and 'read' its information. RFID microchips are implanted in livestock and pets to help find them if they are lost. They are implanted into digital devices, notably automobiles, to find them if they become stolen or lost, or simply to track them for work or other purposes.\"\r\n\r\nThis is... somewhere between blatantly wrong and misunderstood. RFID _is_ used for these things (microchips in animals, automobile assembly lines, books at a library) but it's used over very short distances, and is entirely passive (the tag is not powered). Someone has apparently managed to [read a passport](https://www.theregister.com/2006/01/30/dutch_biometric_passport_crack/) from about 10 metres using special equipment, but that's far from standard usage. I don't think you can just \"find\" an RFID tag in the wild with any reader. You _can_ use one to identify a _found_ animal, or which automobile is passing a sensor in a factory, or which book is being checked out, but there's definitely some strong notion of \"proximity\" involved, as far as I'm aware (please correct me if I'm wrong). I believe RFID is used in automated highway toll collection, but it involves significant power, likely not passively.\r\n\r\nThat left a bad enough taste in my (mind)mouth that I wasn't particularly open to reading in great depth about (very specifically) American law \r\n\r\n> This book focuses on the American position on individual privacy\r\n\r\nespecially with the note that \r\n\r\n> our powerful First Amendment protections of free speech-that is, speech free from government interference-have been regarded as limiting laws that restrict what we can say about each other.\r\n\r\nI can only read so many \"Someone vs Someone\" names of legal precedents and US-specific names of agencies, court jurisdictions, etc. before giving up. This may be of more interest to someone in the US interested in specific legal aspects, but it's not for me.\r\n\r\n",
				"date_published": "2023-01-26T15:00:22+10:30",
				"url": "https://jcarroll.xyz/2023/01/26/finished-reading-our.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/01/20/currently-reading-living.html",
				
				"content_html": "<p>Currently reading: <a href=\"https://micro.blog/books/9781250849151\">Living in Data</a> by Jer Thorp ðŸ“š</p>\n<p>I picked this up browsing shelves in a (particularly <a href=\"https://playandgo.com.au/dymocks-book-store-rundle-mall-adelaide-review/\">beautiful</a>) brick and mortar book store thanks to a voucher I received for a journal article review. So far I&rsquo;m loving it. This was my first introduction to Johanna Drucker&rsquo;s framing of <a href=\"http://www.digitalhumanities.org/dhq/vol/5/1/000091/000091.html\">&ldquo;capta&rdquo;</a> rather than &ldquo;data&rdquo;, the former better reflecting the essence of information being &ldquo;taken and constructed&rdquo; rather than given. Lots to get through yet, but so far very entertaining and insightful.</p>\n",
				"content_text": "Currently reading: [Living in Data](https://micro.blog/books/9781250849151) by Jer Thorp ðŸ“š\n\nI picked this up browsing shelves in a (particularly [beautiful](https://playandgo.com.au/dymocks-book-store-rundle-mall-adelaide-review/)) brick and mortar book store thanks to a voucher I received for a journal article review. So far I'm loving it. This was my first introduction to Johanna Drucker's framing of [\"capta\"](http://www.digitalhumanities.org/dhq/vol/5/1/000091/000091.html) rather than \"data\", the former better reflecting the essence of information being \"taken and constructed\" rather than given. Lots to get through yet, but so far very entertaining and insightful.\n",
				"date_published": "2023-01-20T22:11:45+10:30",
				"url": "https://jcarroll.xyz/2023/01/20/currently-reading-living.html"
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/01/08/finished-reading-loonshots.html",
				"title": "Finished reading: Loonshots by Safi Bahcall ðŸ“š",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9781250185976\">Loonshots</a> by Safi Bahcall ðŸ“š</p>\n<p>This was recommended by someone at work and this time I&rsquo;m very glad they did. The author carefully details the history of some of the most significant breakthroughs and, as a physicist, isn&rsquo;t shy with the specifics. It was staggering to me at the start of the book how intertwined the &ldquo;big&rdquo; computer tech (and by extension, media; Lucasfilm, Pixar, &hellip;) companies are and the history they share. By the end of the book these connections are much clearer. I hadn&rsquo;t expected quite the history lesson, but the prevalence of persisting English technology over the much older Chinese inventions becomes well-reasoned. Less fun is the contemplation that maybe we don&rsquo;t currently have an equivalent of Bell Labs fostering such speculative exploration without the need to be profitable in the near future. Even the well-funded but negative revenue companies have the plan to be highly profitable, not a plan to make something better. The <a href=\"https://www.bcorporation.net/en-us/certification\">B corporations</a> are a good exception, but they&rsquo;re still not quite &ldquo;loonshot nurseries&rdquo;.</p>\n<p>One of the key learnings for me, as someone who works in a Silicon-valley-adjacent biotech startup (hence the recommendation), was that the attitude of creating a &ldquo;disruptive&rdquo; technology is backwards. Many technologies can be seen as disruptive in hindsight, but they never start out with that attitude. Incremental improvement with the support to try something different certainly leads there, but it&rsquo;s perhaps too large a leap to try to get there sooner. Having the support to try something different that could be better is the first step towards making something incredible, and it certainly won&rsquo;t work every time, but not trying will absolutely lead to not making it.</p>\n<p>Lastly, I don&rsquo;t think it really sunk in while I was working there for nearly five years since I wasn&rsquo;t so read-up on the history, but seeing Genentech mentioned in many of these recent books always makes me do a double-take.</p>\n<p>I thoroughly enjoyed this book and recommend it to anyone interested in how big ideas come about and survive, and why others don&rsquo;t.</p>\n",
				"content_text": "Finished reading: [Loonshots](https://micro.blog/books/9781250185976) by Safi Bahcall ðŸ“š\r\n\r\nThis was recommended by someone at work and this time I'm very glad they did. The author carefully details the history of some of the most significant breakthroughs and, as a physicist, isn't shy with the specifics. It was staggering to me at the start of the book how intertwined the \"big\" computer tech (and by extension, media; Lucasfilm, Pixar, ...) companies are and the history they share. By the end of the book these connections are much clearer. I hadn't expected quite the history lesson, but the prevalence of persisting English technology over the much older Chinese inventions becomes well-reasoned. Less fun is the contemplation that maybe we don't currently have an equivalent of Bell Labs fostering such speculative exploration without the need to be profitable in the near future. Even the well-funded but negative revenue companies have the plan to be highly profitable, not a plan to make something better. The [B corporations](https://www.bcorporation.net/en-us/certification) are a good exception, but they're still not quite \"loonshot nurseries\".\r\n\r\nOne of the key learnings for me, as someone who works in a Silicon-valley-adjacent biotech startup (hence the recommendation), was that the attitude of creating a \"disruptive\" technology is backwards. Many technologies can be seen as disruptive in hindsight, but they never start out with that attitude. Incremental improvement with the support to try something different certainly leads there, but it's perhaps too large a leap to try to get there sooner. Having the support to try something different that could be better is the first step towards making something incredible, and it certainly won't work every time, but not trying will absolutely lead to not making it.\r\n\r\nLastly, I don't think it really sunk in while I was working there for nearly five years since I wasn't so read-up on the history, but seeing Genentech mentioned in many of these recent books always makes me do a double-take.\r\n\r\nI thoroughly enjoyed this book and recommend it to anyone interested in how big ideas come about and survive, and why others don't.\n",
				"date_published": "2023-01-08T14:05:31+10:30",
				"url": "https://jcarroll.xyz/2023/01/08/finished-reading-loonshots.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/01/06/implicit-or-explicit.html",
				"title": "Implicit or Explicit connection object?",
				"content_html": "<p>I&rsquo;m wrapping a (stateless, hit-every-time) REST API and my design was challenged with an alternative opinion - which is great! I get to have a more serious think about design and what might work best. I have an internal function which does the actual talking to the server, e.g. <code>.get_from_API()</code> which needs to know the URL, auth key, and query parameters. I originally designed my package to fetch these from environment variables depending on the API instance (e.g. &lsquo;prod&rsquo; vs &lsquo;dev&rsquo;) and the user (their user-specific key). Individual endpoint wrappers essentially boil down to</p>\n<pre tabindex=\"0\"><code class=\"language-{r}\" data-lang=\"{r}\">get_this &lt;- function(something) {\r\n    .get_from_API(construct_endpoint(something))\r\n}\r\n</code></pre><p>I asked the following question on some of the social sites I use:</p>\n<hr>\n<p>Is there a good reason to use one of these vs the other when wrapping an API?</p>\n<p>A:</p>\n<pre tabindex=\"0\"><code class=\"language-{r}\" data-lang=\"{r}\">get_this(x, ...) # GET\r\nget_that(x, ...) # GET\r\nset_this(x, y, ...) # SET\r\nset_that(x, y, ...) # SET\r\n</code></pre><p>with something like this within each of these</p>\n<pre tabindex=\"0\"><code class=\"language-{r}\" data-lang=\"{r}\">greedy_con &lt;- .connect(Sys.getenv(implicit_api_vars), ...)\r\n</code></pre><p>OR</p>\n<p>B:</p>\n<pre tabindex=\"0\"><code class=\"language-{r}\" data-lang=\"{r}\">lazy_con &lt;- .connect(explicit_api_vars, ...)\r\nthis(lazy_con, x, ...) # GET\r\nthat(lazy_con, x, ...) # GET\r\nthis(lazy_con, x) &lt;- y # SET\r\nthat(lazy_con, x) &lt;- y # SET\r\n</code></pre><p>(Or some third option)?</p>\n<hr>\n<p>The motivation for the second option may have come from python where methods on objects are much more common. Indeed, the canonical python version of this wrapper uses</p>\n<pre tabindex=\"0\"><code class=\"language-{python}\" data-lang=\"{python}\">lazy_con = NameOfAPI(url = {}, key = {})\r\n\r\nlazy_con.this()\r\nlazy_con.that()\r\n</code></pre><p>In R we have dispatch (e.g. S3) so I <em>could</em> assign a class <code>mycon</code> to <code>lazy_con</code> and methods <code>this.mycon()</code> and <code>that.mycon()</code> but this seems very overengineered. Apparently BioConductor also uses this method syntax but there the standard is S4 dispatch (and typically larger data) so a more explicit object might make more sense.</p>\n<p>Methods on classes seems to be a common frustration for me in python and rust where I&rsquo;m constantly trying to use some function (e.g. <code>abs(x-y)</code>) which is actually a method (<code>(x-y).abs()</code>) but I think I understand <em>why</em> they&rsquo;re built that way.</p>\n<p>So far the responses seem to lean entirely towards hiding the complexity of the connection away. That said, adopting the &lsquo;setter&rsquo; assignment syntax would mean I could do away with the explicit &lsquo;get&rsquo; in the getter function names.</p>\n<p>Do you have an opinion on this? Let me know!</p>\n",
				"content_text": "I'm wrapping a (stateless, hit-every-time) REST API and my design was challenged with an alternative opinion - which is great! I get to have a more serious think about design and what might work best. I have an internal function which does the actual talking to the server, e.g. `.get_from_API()` which needs to know the URL, auth key, and query parameters. I originally designed my package to fetch these from environment variables depending on the API instance (e.g. 'prod' vs 'dev') and the user (their user-specific key). Individual endpoint wrappers essentially boil down to\r\n\r\n```{r}\r\nget_this <- function(something) {\r\n    .get_from_API(construct_endpoint(something))\r\n}\r\n```\r\n\r\nI asked the following question on some of the social sites I use:\r\n\r\n---\r\n\r\nIs there a good reason to use one of these vs the other when wrapping an API?\r\n\r\nA: \r\n\r\n```{r}\r\nget_this(x, ...) # GET\r\nget_that(x, ...) # GET\r\nset_this(x, y, ...) # SET\r\nset_that(x, y, ...) # SET\r\n```\r\n\r\nwith something like this within each of these\r\n\r\n```{r}\r\ngreedy_con <- .connect(Sys.getenv(implicit_api_vars), ...)\r\n```\r\n\r\nOR\r\n\r\nB:\r\n\r\n```{r}\r\nlazy_con <- .connect(explicit_api_vars, ...)\r\nthis(lazy_con, x, ...) # GET\r\nthat(lazy_con, x, ...) # GET\r\nthis(lazy_con, x) <- y # SET\r\nthat(lazy_con, x) <- y # SET\r\n```\r\n\r\n(Or some third option)?\r\n\r\n---\r\n\r\nThe motivation for the second option may have come from python where methods on objects are much more common. Indeed, the canonical python version of this wrapper uses\r\n\r\n```{python}\r\nlazy_con = NameOfAPI(url = {}, key = {})\r\n\r\nlazy_con.this()\r\nlazy_con.that()\r\n```\r\n\r\nIn R we have dispatch (e.g. S3) so I *could* assign a class `mycon` to `lazy_con` and methods `this.mycon()` and `that.mycon()` but this seems very overengineered. Apparently BioConductor also uses this method syntax but there the standard is S4 dispatch (and typically larger data) so a more explicit object might make more sense.\r\n\r\nMethods on classes seems to be a common frustration for me in python and rust where I'm constantly trying to use some function (e.g. `abs(x-y)`) which is actually a method (`(x-y).abs()`) but I think I understand *why* they're built that way. \r\n\r\nSo far the responses seem to lean entirely towards hiding the complexity of the connection away. That said, adopting the 'setter' assignment syntax would mean I could do away with the explicit 'get' in the getter function names.\r\n\r\nDo you have an opinion on this? Let me know!\n",
				"date_published": "2023-01-06T15:57:11+10:30",
				"url": "https://jcarroll.xyz/2023/01/06/implicit-or-explicit.html",
				"tags": ["R"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2023/01/04/finished-reading-neuromancer.html",
				"title": "Finished reading: Neuromancer by William Gibson ðŸ“š",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9783608504880\">Neuromancer</a> by William Gibson ðŸ“š</p>\n<p>I was recommended this on one of the socials and figured it was about time to get around to it. As the &lsquo;first&rsquo; &ldquo;cyber&rdquo; sci-fi book it was well-written and despite being conservative in its predictions for the future, many of these time has proven to be accurate. The pace is reasonable, but by the end it felt a bit like one short story without many offshoots - I&rsquo;m not complaining; perhaps I&rsquo;ve read too many books whose author tried to fill the pages with unnecessary side stories. Worth the read, but probably not one I&rsquo;ll come back to too often.</p>\n",
				"content_text": "Finished reading: [Neuromancer](https://micro.blog/books/9783608504880) by William Gibson ðŸ“š\n\nI was recommended this on one of the socials and figured it was about time to get around to it. As the 'first' \"cyber\" sci-fi book it was well-written and despite being conservative in its predictions for the future, many of these time has proven to be accurate. The pace is reasonable, but by the end it felt a bit like one short story without many offshoots - I'm not complaining; perhaps I've read too many books whose author tried to fill the pages with unnecessary side stories. Worth the read, but probably not one I'll come back to too often.\n",
				"date_published": "2023-01-04T18:44:09+10:30",
				"url": "https://jcarroll.xyz/2023/01/04/finished-reading-neuromancer.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/08/06/finished-reading-start.html",
				"title": "Finished reading: Start with Why: How Great Leaders Inspire Everyone to Take Action by Simon Sinek ",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9781591846444\">Start with Why: How Great Leaders Inspire Everyone to Take Action</a> by Simon Sinek</p>\n<p>I <a href=\"https://jcarroll.xyz/2022/06/29/currently-reading-start.html\">posted about this one</a> after a few chapters because it started to get on my nerves. I think I hate-finished it. The author makes some more questionable connections (a bow needs to pulled <em>away</em> from the target&hellip; what?) and continues to write like the reader is definitely American. The argument that Apple fans and Harley riders like iPhones and Harleys because of <em>why</em> the respective companies do what they do never convinced me in the slightest.</p>\n<p>The message that the <em>why</em> of a company should be prominent, consistent, and persistent seems fine, I just don&rsquo;t think I liked how that point was made (and taken too far).</p>\n<p>Much of the book, particularly the final chapters are great examples of <a href=\"https://en.wikipedia.org/wiki/Survivorship_bias\">survivorship bias</a> but the author seems to either be deliberately overlooking that.</p>\n<p>I didn&rsquo;t particularly enjoy this book.</p>\n<!-- raw HTML omitted -->\n",
				"content_text": "Finished reading: [Start with Why: How Great Leaders Inspire Everyone to Take Action](https://micro.blog/books/9781591846444) by Simon Sinek \n\nI [posted about this one](https://jcarroll.xyz/2022/06/29/currently-reading-start.html) after a few chapters because it started to get on my nerves. I think I hate-finished it. The author makes some more questionable connections (a bow needs to pulled *away* from the target... what?) and continues to write like the reader is definitely American. The argument that Apple fans and Harley riders like iPhones and Harleys because of *why* the respective companies do what they do never convinced me in the slightest. \n\nThe message that the *why* of a company should be prominent, consistent, and persistent seems fine, I just don't think I liked how that point was made (and taken too far).\n\nMuch of the book, particularly the final chapters are great examples of [survivorship bias](https://en.wikipedia.org/wiki/Survivorship_bias) but the author seems to either be deliberately overlooking that.\n\nI didn't particularly enjoy this book.\n\n<img src=\"uploads/2022/34065cbf3c.jpg\" width=\"405\" height=\"600\" alt=\"don't make me tap the sign / survivorship bias\" />\n",
				"date_published": "2022-08-06T16:39:29+10:30",
				"url": "https://jcarroll.xyz/2022/08/06/finished-reading-start.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/08/06/finished-reading-sea.html",
				"title": "Finished reading: Sea of Tranquility: A novel by Emily St. John Mandel ",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9780593321454\">Sea of Tranquility: A novel</a> by Emily St. John Mandel</p>\n<p>I don&rsquo;t know if it was timely or unfortunate that I read this book so close to <a href=\"https://jcarroll.xyz/2022/07/09/finished-reading-the.html\">The End of Eternity</a> - both had very similar themes, but Asimov is just so good at weaving the threads together into an engrossing story. I think this was a recommendation from Twitter, and while I enjoyed it, it did feel oddly paced. The start felt quite slow - the first half of the book was spent introducing the characters, yet the conclusion seemed to be squashed into the final chapter. Without spoiling too much, there&rsquo;s some <a href=\"https://youtu.be/u4SEDzynMiQ\">bootstrap paradox</a> stuff (as any book involving time-travel should have) that just gets hand-waved away. It&rsquo;s fine if you don&rsquo;t think about it too hard.</p>\n<p>Overall, not bad. Recommended for a not-too-serious read.</p>\n",
				"content_text": "Finished reading: [Sea of Tranquility: A novel](https://micro.blog/books/9780593321454) by Emily St. John Mandel \n\nI don't know if it was timely or unfortunate that I read this book so close to [The End of Eternity](https://jcarroll.xyz/2022/07/09/finished-reading-the.html) - both had very similar themes, but Asimov is just so good at weaving the threads together into an engrossing story. I think this was a recommendation from Twitter, and while I enjoyed it, it did feel oddly paced. The start felt quite slow - the first half of the book was spent introducing the characters, yet the conclusion seemed to be squashed into the final chapter. Without spoiling too much, there's some [bootstrap paradox](https://youtu.be/u4SEDzynMiQ) stuff (as any book involving time-travel should have) that just gets hand-waved away. It's fine if you don't think about it too hard.\n\nOverall, not bad. Recommended for a not-too-serious read.\n",
				"date_published": "2022-08-06T16:16:57+10:30",
				"url": "https://jcarroll.xyz/2022/08/06/finished-reading-sea.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/07/31/160948.html",
				"title": "Finished reading: 12 Bytes: How We Got Here. Where We Might Go Next by Jeanette Winterson ",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9781473578258\">12 Bytes: How We Got Here. Where We Might Go Next</a> by Jeanette Winterson</p>\n<p>My library had several copies of this on the shelf, so I assumed it was popular or new. The latter is certainly true (2021). This is a collection of short essays detailing the journey from the first analytical machine towards AGI (Artificial General Intelligence; c.f. narrow AI such as a digital assistant), specifically noting the significant contributions of women (against the prejudices and biases which are only now slowly being dismantled).</p>\n<p>The stories shouldn&rsquo;t be new to anyone, but more light on them is a good thing. The author provides a great level of detail about the contributions and their historical contexts, but borders on misandry with their side remarks. &ldquo;Turn around is fair play&rdquo; one could argue, but I don&rsquo;t think it&rsquo;s helpful here. The (extremely talented) women who programmed the ENIAC (the domain experts on the mathematical equations they were programming the machine to solve) absolutely deserved the credit for their achievements that was withheld from them, but emphasising &ldquo;the men who built it couldn&rsquo;t program it&rdquo; as if to suggest they just stuck some electronics together and couldn&rsquo;t comprehend what they&rsquo;d built without the women seems disingenuous. Arguing that the &ldquo;I&rsquo;m a Mac / I&rsquo;m a PC&rdquo; ads specifically only had men in order to reinforce the stereotype that women don&rsquo;t use computers seems like a stretch.</p>\n<p>I enjoyed reading the historical content of this book. The commentary not so much. Others may enjoy it more than I did.</p>\n",
				"content_text": "Finished reading: [12 Bytes: How We Got Here. Where We Might Go Next](https://micro.blog/books/9781473578258) by Jeanette Winterson \n\nMy library had several copies of this on the shelf, so I assumed it was popular or new. The latter is certainly true (2021). This is a collection of short essays detailing the journey from the first analytical machine towards AGI (Artificial General Intelligence; c.f. narrow AI such as a digital assistant), specifically noting the significant contributions of women (against the prejudices and biases which are only now slowly being dismantled). \n\nThe stories shouldn't be new to anyone, but more light on them is a good thing. The author provides a great level of detail about the contributions and their historical contexts, but borders on misandry with their side remarks. \"Turn around is fair play\" one could argue, but I don't think it's helpful here. The (extremely talented) women who programmed the ENIAC (the domain experts on the mathematical equations they were programming the machine to solve) absolutely deserved the credit for their achievements that was withheld from them, but emphasising \"the men who built it couldn't program it\" as if to suggest they just stuck some electronics together and couldn't comprehend what they'd built without the women seems disingenuous. Arguing that the \"I'm a Mac / I'm a PC\" ads specifically only had men in order to reinforce the stereotype that women don't use computers seems like a stretch.\n\nI enjoyed reading the historical content of this book. The commentary not so much. Others may enjoy it more than I did.\n",
				"date_published": "2022-07-31T17:09:48+10:30",
				"url": "https://jcarroll.xyz/2022/07/31/160948.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/07/16/finished-reading-the.html",
				"title": "Finished reading: The New Childhood: Raising Kids to Thrive in a Connected World by Jordan Shapiro ",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9780316437257\">The New Childhood: Raising Kids to Thrive in a Connected World</a> by Jordan Shapiro</p>\n<p>Another break from biology, certainly more towards psychology. This one I found randomly (promoted) at the library and given that it&rsquo;s my kids' school holidays at the moment and they&rsquo;re constantly asking for screens, I figured it was worth a shot. To my surprise, by the end of this book I&rsquo;m encouraged to give my kids <em>more</em> screen time. The big qualifier is the content - the author makes convincing arguments that collaborative games and online chat are the new <a href=\"https://en.wikipedia.org/wiki/Agora\">agora</a>, and that kids growing into that world will need to understand, appreciate, and be able to &ldquo;read&rdquo; (&ldquo;be literate in&rdquo;) the new medium. I&rsquo;m not quite convinced that watching YouTube videos of someone playing an extremely basic free game has the same benefit as they propose comes from collaborative gaming or online forums, but I am convinced to start playing Minecraft <em>with</em> my kids.</p>\n<p>This book nicely balances historical psychology with up-to-date perspectives. I was surprised to learn that kindergarten (as a concept at all) is only a couple hundred years old. The framing of how previous generations of children have been raised within the applicable social setting (most of us are remnants of the industrial age), plus the entire home vs work distinction breaking down in the new internet-based world makes a lot of sense and encourages me to think about what outdated notions I&rsquo;m imposing on my own kids, especially how those can be limiting. In my current work I make use of mind maps and collaborative documents - why would I not want my children to use the same useful tools for their education?</p>\n<p>The latter sections of the book branched out into much wider social commentary - children are growing up within the evolving technological landscape, so it&rsquo;s entirely relevant - and I liked several well-made points about why &ldquo;uninformed inclusion&rdquo; might actually work against goals; why it&rsquo;s not sufficient to just connect everyone and hope they&rsquo;ll be nice; why some people form exclusions against others due to a lack of self-identity; and why online forums are so useful for connecting people, but to the detriment of serendipity.</p>\n<p>That last one really hit home - the R community largely calls Twitter home and it&rsquo;s been a fruitful source of friends, collaborators, and inspiration for me, but I do wonder how much of an echo chamber I&rsquo;m stuck it. Maybe it&rsquo;s time to follow some more python and javascript devs.</p>\n<p>I highly recommend this book to anyone with children who is uncertain about the amount of screen time they&rsquo;re getting. Also just a great read for better understanding the new digital world.</p>\n",
				"content_text": "Finished reading: [The New Childhood: Raising Kids to Thrive in a Connected World](https://micro.blog/books/9780316437257) by Jordan Shapiro \n\nAnother break from biology, certainly more towards psychology. This one I found randomly (promoted) at the library and given that it's my kids' school holidays at the moment and they're constantly asking for screens, I figured it was worth a shot. To my surprise, by the end of this book I'm encouraged to give my kids *more* screen time. The big qualifier is the content - the author makes convincing arguments that collaborative games and online chat are the new [agora](https://en.wikipedia.org/wiki/Agora), and that kids growing into that world will need to understand, appreciate, and be able to \"read\" (\"be literate in\") the new medium. I'm not quite convinced that watching YouTube videos of someone playing an extremely basic free game has the same benefit as they propose comes from collaborative gaming or online forums, but I am convinced to start playing Minecraft *with* my kids.\n\nThis book nicely balances historical psychology with up-to-date perspectives. I was surprised to learn that kindergarten (as a concept at all) is only a couple hundred years old. The framing of how previous generations of children have been raised within the applicable social setting (most of us are remnants of the industrial age), plus the entire home vs work distinction breaking down in the new internet-based world makes a lot of sense and encourages me to think about what outdated notions I'm imposing on my own kids, especially how those can be limiting. In my current work I make use of mind maps and collaborative documents - why would I not want my children to use the same useful tools for their education?\n\nThe latter sections of the book branched out into much wider social commentary - children are growing up within the evolving technological landscape, so it's entirely relevant - and I liked several well-made points about why \"uninformed inclusion\" might actually work against goals; why it's not sufficient to just connect everyone and hope they'll be nice; why some people form exclusions against others due to a lack of self-identity; and why online forums are so useful for connecting people, but to the detriment of serendipity.\n\nThat last one really hit home - the R community largely calls Twitter home and it's been a fruitful source of friends, collaborators, and inspiration for me, but I do wonder how much of an echo chamber I'm stuck it. Maybe it's time to follow some more python and javascript devs.\n\nI highly recommend this book to anyone with children who is uncertain about the amount of screen time they're getting. Also just a great read for better understanding the new digital world.\n",
				"date_published": "2022-07-16T21:15:27+10:30",
				"url": "https://jcarroll.xyz/2022/07/16/finished-reading-the.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/07/09/finished-reading-the.html",
				"title": "Finished reading: The End of Eternity by Isaac Asimov",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9780593160060\">The End of Eternity</a> by Isaac Asimov</p>\n<p>Easily one of the greatest science fiction writers of all time, and it&rsquo;s easy to see why. I&rsquo;ve loved many of them, but I haven&rsquo;t read anywhere near all of Asimov&rsquo;s works. I saw this one on a shelf and figured it would be a nice break from the much heavier non-fiction biology I&rsquo;ve been reading lately.</p>\n<p>The craftsmanship of Asimov&rsquo;s writing always leaves me pleased. Small callbacks throughout seem effortless; the words never seem to be shoehorned in order to tie together different threads (with other authors, certain sentences have a certain &lsquo;<a href=\"https://en.wikipedia.org/wiki/Chekhov%27s_gun\">Chekhov&rsquo;s gun</a>&rsquo; flavour to them).</p>\n<p>I enjoyed reading this book. Twists and turns, a careful balance of science and hand-waving, and a not-too-overwhelming set of characters. I&rsquo;ll certainly be keeping an eye out for more of Asimov&rsquo;s works to correct my lack of coverage. Recommended to time-travel and general sci-fi enthusiasts.</p>\n",
				"content_text": "Finished reading: [The End of Eternity](https://micro.blog/books/9780593160060) by Isaac Asimov \n\nEasily one of the greatest science fiction writers of all time, and it's easy to see why. I've loved many of them, but I haven't read anywhere near all of Asimov's works. I saw this one on a shelf and figured it would be a nice break from the much heavier non-fiction biology I've been reading lately.\n\nThe craftsmanship of Asimov's writing always leaves me pleased. Small callbacks throughout seem effortless; the words never seem to be shoehorned in order to tie together different threads (with other authors, certain sentences have a certain '[Chekhov's gun](https://en.wikipedia.org/wiki/Chekhov%27s_gun)' flavour to them).\n\nI enjoyed reading this book. Twists and turns, a careful balance of science and hand-waving, and a not-too-overwhelming set of characters. I'll certainly be keeping an eye out for more of Asimov's works to correct my lack of coverage. Recommended to time-travel and general sci-fi enthusiasts.\n",
				"date_published": "2022-07-09T18:07:59+10:30",
				"url": "https://jcarroll.xyz/2022/07/09/finished-reading-the.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/06/29/currently-reading-start.html",
				"title": "Currently reading: Start With Why by Simon Sinek ",
				"content_html": "<p>Currently reading: <a href=\"https://micro.blog/books/9780241958230\">Start With Why</a> by Simon Sinek</p>\n<p>I was recommended this book by someone whose opinion I hold in high regard, but so far I&rsquo;m not enjoying this book. Not necessarily for the material - I think I can appreciate the points being made about having a defined &lsquo;why&rsquo; behind a company and explanations of the various manipulations a company can leverage rather than actually being better than the competition, but rather the extreme &ldquo;American-ness&rdquo; of the author. Especially surprising since the author has a more diverse background than simply &lsquo;American&rsquo;.</p>\n<p>It took 48 pages before a single non-American company was mentioned (Ferarri), and even then it was in the context of</p>\n<blockquote>\n<p>&ldquo;if you have a family of six a two-seater Ferarri is not better. However, if you&rsquo;re looking for a great way to meet women, a Honda minivan is probably not better&rdquo;.</p>\n</blockquote>\n<p>I&rsquo;m long out of the dating scene, but that seems&hellip; like a terrible comparison. Is that part of the purchasing decision? I suppose maybe it is for some, but as a reliable consumer group?</p>\n<p>Multiple references to Apple Macs and iTunes being brilliant innovations &ldquo;because people connected with the why of the company&rdquo;. iTunes was a terrible product that was forced onto users in order to use the iPod (a distinct improvement over the removable media competition). My understanding is that it gained significant market share over CDs because it was easier (and potentially cheaper - if you wanted a single song). For myself and many others (the reason I believe it was actually innovative) it was <em>easier</em> than pirating music. A dollar for a song compared to a handful of dollars for a CD or the <em>hassle</em> of downloading and uploading a file - it solved a problem. I don&rsquo;t attribute that to Apple&rsquo;s &ldquo;why&rdquo; - another company that offered that might just as well have had the same success.</p>\n<p>Chapter 4 seems to end with the explanation that &ldquo;Harley Davidson riders want Harleys&rdquo; and &ldquo;Mac people want something starting with an <em>i</em>&rdquo; and that there&rsquo;s a cult aspect to this based on loyalty above actual product superiority but I don&rsquo;t believe this is grounded in any &ldquo;why&rdquo; of those companies. They&rsquo;ve each done well at convincing buyers to be part of their collective, and they&rsquo;ve each done well at having some features their buyers do appreciate (loud engines or smooth interfaces) but they&rsquo;re both viewed as objectively worse products by people who can be considered unbiased. The example of &ldquo;U2 being iconoclastic&rdquo; and so a joint promotional iPod &ldquo;makes sense&rdquo; got a genuine chuckle from me - did people buy more iPods because U2 were involved? From everything I saw of that time, it was ridiculed. Users had an entire album forced onto their devices that they had no interest in.</p>\n<p>Then more &ldquo;everyone is American&rdquo; - I actually had to put the book down during the chapter explaining &ldquo;the biology of belonging&rdquo; with the sentence</p>\n<blockquote>\n<p>&ldquo;Go abroad and you&rsquo;ll form instant bonds with other Americans you meet&rdquo;</p>\n</blockquote>\n<p>Other? I&rsquo;m Australian.</p>\n<p>I got really upset at repeated references to language structure having some &ldquo;hidden meaning&rdquo;. Is it a coincidence that the phrase is &ldquo;hearts and minds&rdquo; in that order? Or &ldquo;art and science&rdquo;&hellip; No. Not really. Sure, the rules are vague, but it&rsquo;s not particularly meaningful in the way the author hints at. There are <a href=\"https://www.cambridge.org/elt/blog/2017/08/31/chips-and-fish-word-order-in-english-collocations/\">accepted orderings</a> to some combinations of words known as &ldquo;collocations&rdquo; that &ldquo;make sense&rdquo; to a native English speaker - anyone who hears &ldquo;chips and fish&rdquo; will instantly recognise something is wrong. The &ldquo;i&rdquo; (/Éª/) in both &ldquo;mind&rdquo; (/maÉªnd/) and &ldquo;science&rdquo; (/ËˆsaÉª.É™ns/) fits well into the regular pattern.</p>\n<p>The same allusion to the layout of the &ldquo;Golden Circle&rdquo; having some correlation with the physical brain structure reeks of ill-informed motivational speakers and those who say &ldquo;walnuts are good for your brain because they look like a brain&rdquo;.</p>\n<p>I&rsquo;m still going to give the rest of the book a chance, but so far it&rsquo;s not rating high.</p>\n",
				"content_text": "Currently reading: [Start With Why](https://micro.blog/books/9780241958230) by Simon Sinek \n\nI was recommended this book by someone whose opinion I hold in high regard, but so far I'm not enjoying this book. Not necessarily for the material - I think I can appreciate the points being made about having a defined 'why' behind a company and explanations of the various manipulations a company can leverage rather than actually being better than the competition, but rather the extreme \"American-ness\" of the author. Especially surprising since the author has a more diverse background than simply 'American'.\n\nIt took 48 pages before a single non-American company was mentioned (Ferarri), and even then it was in the context of\n\n> \"if you have a family of six a two-seater Ferarri is not better. However, if you're looking for a great way to meet women, a Honda minivan is probably not better\".\n\nI'm long out of the dating scene, but that seems... like a terrible comparison. Is that part of the purchasing decision? I suppose maybe it is for some, but as a reliable consumer group?\n\nMultiple references to Apple Macs and iTunes being brilliant innovations \"because people connected with the why of the company\". iTunes was a terrible product that was forced onto users in order to use the iPod (a distinct improvement over the removable media competition). My understanding is that it gained significant market share over CDs because it was easier (and potentially cheaper - if you wanted a single song). For myself and many others (the reason I believe it was actually innovative) it was *easier* than pirating music. A dollar for a song compared to a handful of dollars for a CD or the *hassle* of downloading and uploading a file - it solved a problem. I don't attribute that to Apple's \"why\" - another company that offered that might just as well have had the same success.\n\nChapter 4 seems to end with the explanation that \"Harley Davidson riders want Harleys\" and \"Mac people want something starting with an _i_\" and that there's a cult aspect to this based on loyalty above actual product superiority but I don't believe this is grounded in any \"why\" of those companies. They've each done well at convincing buyers to be part of their collective, and they've each done well at having some features their buyers do appreciate (loud engines or smooth interfaces) but they're both viewed as objectively worse products by people who can be considered unbiased. The example of \"U2 being iconoclastic\" and so a joint promotional iPod \"makes sense\" got a genuine chuckle from me - did people buy more iPods because U2 were involved? From everything I saw of that time, it was ridiculed. Users had an entire album forced onto their devices that they had no interest in.\n\nThen more \"everyone is American\" - I actually had to put the book down during the chapter explaining \"the biology of belonging\" with the sentence\n\n> \"Go abroad and you'll form instant bonds with other Americans you meet\"\n\nOther? I'm Australian.\n\nI got really upset at repeated references to language structure having some \"hidden meaning\". Is it a coincidence that the phrase is \"hearts and minds\" in that order? Or \"art and science\"... No. Not really. Sure, the rules are vague, but it's not particularly meaningful in the way the author hints at. There are [accepted orderings](https://www.cambridge.org/elt/blog/2017/08/31/chips-and-fish-word-order-in-english-collocations/) to some combinations of words known as \"collocations\" that \"make sense\" to a native English speaker - anyone who hears \"chips and fish\" will instantly recognise something is wrong. The \"i\" (/Éª/) in both \"mind\" (/maÉªnd/) and \"science\" (/ËˆsaÉª.É™ns/) fits well into the regular pattern.\n\nThe same allusion to the layout of the \"Golden Circle\" having some correlation with the physical brain structure reeks of ill-informed motivational speakers and those who say \"walnuts are good for your brain because they look like a brain\".\n\nI'm still going to give the rest of the book a chance, but so far it's not rating high.\n",
				"date_published": "2022-06-29T23:45:19+10:30",
				"url": "https://jcarroll.xyz/2022/06/29/currently-reading-start.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/06/28/finished-reading-the.html",
				"title": "Finished reading: The Cell by Joshua Z. Rappoport ðŸ“š",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9781944648978\">The Cell</a> by Joshua Z. Rappoport ðŸ“š</p>\n<p>I enjoyed this book - it started with a good overview of the cellular biology but did move on to more organ-based systems, which was perfect for me. The explanations of the lab and microscopy techniques, advancements, innovations, and discoveries were particularly nice. The detour to examples of academic fraud took a dark turn for such a pleasant book. Recommended for those looking for a nice balance of in-depth science and casual explanations.</p>\n",
				"content_text": "Finished reading: [The Cell](https://micro.blog/books/9781944648978) by Joshua Z. Rappoport ðŸ“š\r\n\r\nI enjoyed this book - it started with a good overview of the cellular biology but did move on to more organ-based systems, which was perfect for me. The explanations of the lab and microscopy techniques, advancements, innovations, and discoveries were particularly nice. The detour to examples of academic fraud took a dark turn for such a pleasant book. Recommended for those looking for a nice balance of in-depth science and casual explanations.\n",
				"date_published": "2022-06-28T15:16:18+10:30",
				"url": "https://jcarroll.xyz/2022/06/28/finished-reading-the.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/06/11/currently-reading-the.html",
				"title": "Currently reading: The Cell: Discovering the Microscopic World that Determines our Health, our Consciousness, and our Future",
				"content_html": "<p>Currently reading: <a href=\"https://micro.blog/books/9781944648978\">The Cell: Discovering the Microscopic World that Determines our Health, our Consciousness, and our Future</a> by Joshua Z. Rappoport</p>\n<p>Continuing with the technical theme, so far this is a deep dive into the very specific mechanisms of molecular biology without (yet) too much emphasis on particular cells.</p>\n<p>What surprised me so far was that <a href=\"https://en.wikipedia.org/wiki/Polymerase_chain_reaction\">PCR</a> (as a technology) is only as old as I am. It&rsquo;s gained a lot of attention thanks to a particular virus we&rsquo;ve all heard too much about. I&rsquo;d never run one of these reactions myself (having not passed through a university biology department) and wasn&rsquo;t aware of the technical details. I had heard various claims by armchair biologists that the COVID PCR test was &ldquo;just detecting the flu&rdquo; and that &ldquo;if you run enough cycles you can find anything&rdquo; but with a better explanation of how it works - primers and temperature cycling - it&rsquo;s clear that&rsquo;s all just a load of nonsense. I&rsquo;m enjoying this one so far.</p>\n<p>Also news to me was that RT-PCR (Reverse Transcription-Polymerase Chain Reaction) is the name applicable to PCR of an RNA virus (as <a href=\"https://en.wikipedia.org/wiki/Severe_acute_respiratory_syndrome_coronavirus_2\">SARS-CoV-2</a> is) and not a meaningfully different version to PCR in that case, despite <a href=\"https://www.flysfo.com/travel-well/covid-19-testing\">some listings having both</a>.</p>\n",
				"content_text": "Currently reading: [The Cell: Discovering the Microscopic World that Determines our Health, our Consciousness, and our Future](https://micro.blog/books/9781944648978) by Joshua Z. Rappoport \n\nContinuing with the technical theme, so far this is a deep dive into the very specific mechanisms of molecular biology without (yet) too much emphasis on particular cells. \n\nWhat surprised me so far was that [PCR](https://en.wikipedia.org/wiki/Polymerase_chain_reaction) (as a technology) is only as old as I am. It's gained a lot of attention thanks to a particular virus we've all heard too much about. I'd never run one of these reactions myself (having not passed through a university biology department) and wasn't aware of the technical details. I had heard various claims by armchair biologists that the COVID PCR test was \"just detecting the flu\" and that \"if you run enough cycles you can find anything\" but with a better explanation of how it works - primers and temperature cycling - it's clear that's all just a load of nonsense. I'm enjoying this one so far.\n\nAlso news to me was that RT-PCR (Reverse Transcription-Polymerase Chain Reaction) is the name applicable to PCR of an RNA virus (as [SARS-CoV-2](https://en.wikipedia.org/wiki/Severe_acute_respiratory_syndrome_coronavirus_2) is) and not a meaningfully different version to PCR in that case, despite [some listings having both](https://www.flysfo.com/travel-well/covid-19-testing).\n",
				"date_published": "2022-06-11T18:06:26+10:30",
				"url": "https://jcarroll.xyz/2022/06/11/currently-reading-the.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/06/11/finished-reading-life.html",
				"title": "Finished reading: Life Unfolding: How the Human Body Creates Itself",
				"content_html": "<p><a href=\"https://micro.blog/books/9780199673537\">Life Unfolding: How the Human Body Creates Itself</a> by Jamie A. Davies</p>\n<p>How a single cell develops into a full human, and a lot of the molecular biology along the way. I thoroughly enjoyed this read - every chapter had highly interesting points about the particular pathways involved and how the cells end up &ldquo;choosing&rdquo; to do all the things they do; move where they need to move, align along directions, and proliferate/die. I spent a lot of time pausing my reading, looking up branches of other information and going down other rabbit holes. I read this as a library loan, but I enjoyed it so much I&rsquo;ve bought my own permanent copy.</p>\n<p>What surprised me the most (having taken a non-traditional route into biology via physics and programming) - but probably shouldn&rsquo;t have - was how the entire system efficiently re-use mechanisms and pathways for both very early development and for ongoing functionality. I recognised several genes from my cancer immunology work, but I always regarded these as &lsquo;just part of the genetic makeup of a person&rsquo;, not paying attention to how they were critical to actually creating the fully grown person, and are now being repurposed. It&rsquo;s perhaps obvious in hindsight, but there aren&rsquo;t a set of genes for pre-natal growth and another set for adult life. It makes the fact that sometimes these mechanisms fail to work perfectly all the more understandable.</p>\n<p>Highly recommend to anyone interested in the very technical details, but a well-presented resource for those generally interested.</p>\n<!-- raw HTML omitted -->\n",
				"content_text": "[Life Unfolding: How the Human Body Creates Itself](https://micro.blog/books/9780199673537) by Jamie A. Davies \n\nHow a single cell develops into a full human, and a lot of the molecular biology along the way. I thoroughly enjoyed this read - every chapter had highly interesting points about the particular pathways involved and how the cells end up \"choosing\" to do all the things they do; move where they need to move, align along directions, and proliferate/die. I spent a lot of time pausing my reading, looking up branches of other information and going down other rabbit holes. I read this as a library loan, but I enjoyed it so much I've bought my own permanent copy.\n\nWhat surprised me the most (having taken a non-traditional route into biology via physics and programming) - but probably shouldn't have - was how the entire system efficiently re-use mechanisms and pathways for both very early development and for ongoing functionality. I recognised several genes from my cancer immunology work, but I always regarded these as 'just part of the genetic makeup of a person', not paying attention to how they were critical to actually creating the fully grown person, and are now being repurposed. It's perhaps obvious in hindsight, but there aren't a set of genes for pre-natal growth and another set for adult life. It makes the fact that sometimes these mechanisms fail to work perfectly all the more understandable.\n\nHighly recommend to anyone interested in the very technical details, but a well-presented resource for those generally interested.\n\n<img src=\"uploads/2022/d82072c1a2.jpg\" width=\"600\" height=\"800\" alt=\"\" />\n",
				"date_published": "2022-06-11T17:49:17+10:30",
				"url": "https://jcarroll.xyz/2022/06/11/finished-reading-life.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/06/11/163214.html",
				"title": "Finished reading: Life from an RNA World: The Ancestor Within",
				"content_html": "<p>(backlog from March 2022)</p>\n<p><a href=\"https://micro.blog/books/9780674050754\">Life from an RNA World: The Ancestor Within</a> by Michael Yarus</p>\n<p>This was a nice tour of how the complex mechanisms of DNA replication came to be, and how the process works to produce proteins and phenotypes. This was the first time I really felt I understood the difference between DNA and RNA, and how such a mechanism evolved. Highly recommend to anyone interested in genomics/genetics at a technical level.</p>\n",
				"content_text": "(backlog from March 2022)\n\n[Life from an RNA World: The Ancestor Within](https://micro.blog/books/9780674050754) by Michael Yarus\n\nThis was a nice tour of how the complex mechanisms of DNA replication came to be, and how the process works to produce proteins and phenotypes. This was the first time I really felt I understood the difference between DNA and RNA, and how such a mechanism evolved. Highly recommend to anyone interested in genomics/genetics at a technical level.\n",
				"date_published": "2022-06-11T17:48:07+10:30",
				"url": "https://jcarroll.xyz/2022/06/11/163214.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/04/07/interpolation-animation-in.html",
				"title": "Interpolation animation in Julia",
				"content_html": "<p>I <em>love</em> small projects for helping me learn, especially programming. I&rsquo;m still learning Julia, and have found myself wanting more &ldquo;little silly things&rdquo; I can digest and learn from. A lot of the projects I see in Julia are big mathematical models, and I&rsquo;m just not ready to dive that deep yet.</p>\n<p><a href=\"https://twitter.com/ted_dunning/status/1435027697386721280?s=20&amp;t=cDVb0XOQRJeOjXoTrOz54w\">This series of tweets</a> caught my eye, partly because of the cool animation, but also the bite-sized amount of information it was conveying - that interpolation in Julia can be specified so easily, thanks in large part to the multiple dispatch design of the language.</p>\n<p>&ldquo;Surely I could get those 7 lines of code to run&rdquo; I thought.</p>\n<p>Entering the code into VScode was straightforward enough, no problems there. I could define the interpolation function</p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">interpolate(a, b) = t -&gt; ((1.0-t)*a + t*b)\n</code></pre><p>however extending the <code>*</code> and <code>+</code> methods did require me to <code>import Base:*</code> and <code>import Base:+</code> which I think I knew but had forgotten.</p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">+(f::Function, g::Function) = x -&gt; f(x) + g(x)\n*(t::Number, g::Function) = x -&gt; t * g(x)\n</code></pre><p>Defining the secondary and tertiary interpolations, also straightforward</p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">bz1(p1, p2) = interpolate(p1, p2)\nbz2(p1, p2, p3) = interpolate(bz1(p1, p2), bz1(p2, p3))\nbz3(p1, p2, p3, p4) = interpolate(bz2(p1, p2, p3), bz2(p2, p3, p4))\n</code></pre><p>Now the tricky part - evaluating some of these. I knew that <code>a</code> and <code>b</code> represent points, but how to do that here? They&rsquo;re not single numbers, but coordinates. I tried a <code>Tuple</code> as <code>(1, 2)</code> but that doesn&rsquo;t seem to work. I do need to remember that <code>interpolate</code> is itself a function of <code>t</code>, so that needs to be specified as well. If I try to interpolate halfway between two &ldquo;points&rdquo; with <code>Tuple</code>s</p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">interpolate((0,1), (1,2))(0.5)\nERROR: MethodError: no method matching *(::Float64, ::Tuple{Int64,Int64})\nClosest candidates are:\n  *(::Any, ::Any, ::Any, ::Any...) at operators.jl:538\n  *(::Float64, ::Float64) at float.jl:405\n  *(::AbstractFloat, ::Bool) at bool.jl:112\n</code></pre><p>Okay, how about <code>Array</code>s?</p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">interpolate([0,1], [1,2])(0.5)\n2-element Array{Float64,1}:\n 0.5\n 1.5\n</code></pre><p>Huzzah!</p>\n<p>After that, it&rsquo;s a matter of generating the points specified by</p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">bz3(p1, p2, p3, p4)(t)(t)(t)\n</code></pre><p>for various values of <code>t</code>. I did that with a <code>map</code> and joined the results back into a single <code>Array</code></p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">dots = map(i -&gt; bz3(p1, p2, p3, p4)(i)(i)(i),collect(0:0.1:1))\ndots = hcat(dots...)\ndots\n2Ã—11 Array{Float64,2}:\n 0.5  0.47535  0.5368  0.66245  â€¦  1.36905  1.4872  1.53815  1.5\n 1.0  1.3124   1.5312  1.6588      1.3052   1.0128  0.6436   0.2\n</code></pre><p>That was, I&rsquo;d say, a success.</p>\n<p>Drunk with confidence, I wanted to try to reproduce the animation from the tweet, so I dug into the documentation. It didn&rsquo;t seem too bad, and I think I&rsquo;ve managed to reproduce it pretty well</p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">anim = @animate for t in collect(vcat(0:0.01:1,1:-0.01:0))\n    a = bz3(p1, p2, p3, p4)(t)(t)(t);\n    b1 = bz2(p1, p2, p3)(t)(t);\n    b2 = bz2(p2, p3, p4)(t)(t);\n    c1 = bz1(p1, p2)(t);\n    c2 = bz1(p2, p3)(t);\n    c3 = bz1(p3, p4)(t);\n    stars = hcat(p1, p2, p3, p4);\n    diamond1 = hcat(c1, c2);\n    diamond2 = hcat(c2, c3);\n    square = hcat(b1, b2);\n    plot(xlim = (-0.1,2.5), ylim = (-0.1,2.5), legend = false)\n    scatter!(dots[1,:], dots[2,:], markersize = 2)\n    plot!(diamond1[1,:], diamond1[2,:], markersize = 10, markershape = :diamond, color = :green)\n    plot!(diamond2[1,:], diamond2[2,:], markersize = 10, markershape = :diamond, color = :green)\n    plot!(square[1,:], square[2,:], markersize = 10, markershape = :square, color = :blue)\n    plot!(stars[1,:], stars[2,:], markersize = 10, markershape = :star, color = :purple)\n    scatter!(Tuple(a), markersize = 10, markershape = :circle, markercolor = :red)\nend\n\ngif(anim, fps = 24)\n</code></pre><p><img src=\"https://jcarroll.xyz/uploads/2022/ea5f75012f.gif\" alt=\"\"></p>\n<p>Moving the points around, I get a new version all of my own</p>\n<p><img src=\"https://jcarroll.xyz/uploads/2022/b776bf8259.gif\" alt=\"\"></p>\n<p>I&rsquo;m very happy with how these turned out, and I&rsquo;ve learned a lot! A gist of the code to make these is hosted here: <a href=\"https://gist.github.com/jonocarroll/27f9b57332424ea50ec2970e74d8e3b3\">https://gist.github.com/jonocarroll/27f9b57332424ea50ec2970e74d8e3b3</a></p>\n<p>If there are better ways to do any of the steps (there surely are) please feel free to let me know!</p>\n<p>Was this fun? You Bezier ass!</p>\n",
				"content_text": "I *love* small projects for helping me learn, especially programming. I'm still learning Julia, and have found myself wanting more \"little silly things\" I can digest and learn from. A lot of the projects I see in Julia are big mathematical models, and I'm just not ready to dive that deep yet.\n\n[This series of tweets](https://twitter.com/ted_dunning/status/1435027697386721280?s=20&t=cDVb0XOQRJeOjXoTrOz54w) caught my eye, partly because of the cool animation, but also the bite-sized amount of information it was conveying - that interpolation in Julia can be specified so easily, thanks in large part to the multiple dispatch design of the language.\n\n\"Surely I could get those 7 lines of code to run\" I thought.\n\nEntering the code into VScode was straightforward enough, no problems there. I could define the interpolation function \n```{julia}\ninterpolate(a, b) = t -> ((1.0-t)*a + t*b)\n```\nhowever extending the `*` and `+` methods did require me to `import Base:*` and `import Base:+` which I think I knew but had forgotten.\n```{julia}\n+(f::Function, g::Function) = x -> f(x) + g(x)\n*(t::Number, g::Function) = x -> t * g(x)\n```\nDefining the secondary and tertiary interpolations, also straightforward\n```{julia}\nbz1(p1, p2) = interpolate(p1, p2)\nbz2(p1, p2, p3) = interpolate(bz1(p1, p2), bz1(p2, p3))\nbz3(p1, p2, p3, p4) = interpolate(bz2(p1, p2, p3), bz2(p2, p3, p4))\n```\nNow the tricky part - evaluating some of these. I knew that `a` and `b` represent points, but how to do that here? They're not single numbers, but coordinates. I tried a `Tuple` as `(1, 2)` but that doesn't seem to work. I do need to remember that `interpolate` is itself a function of `t`, so that needs to be specified as well. If I try to interpolate halfway between two \"points\" with `Tuple`s\n```{julia}\ninterpolate((0,1), (1,2))(0.5)\nERROR: MethodError: no method matching *(::Float64, ::Tuple{Int64,Int64})\nClosest candidates are:\n  *(::Any, ::Any, ::Any, ::Any...) at operators.jl:538\n  *(::Float64, ::Float64) at float.jl:405\n  *(::AbstractFloat, ::Bool) at bool.jl:112\n```\nOkay, how about `Array`s?\n```{julia}\ninterpolate([0,1], [1,2])(0.5)\n2-element Array{Float64,1}:\n 0.5\n 1.5\n```\nHuzzah!\n\nAfter that, it's a matter of generating the points specified by\n```{julia}\nbz3(p1, p2, p3, p4)(t)(t)(t)\n```\nfor various values of `t`. I did that with a `map` and joined the results back into a single `Array`\n```{julia}\ndots = map(i -> bz3(p1, p2, p3, p4)(i)(i)(i),collect(0:0.1:1))\ndots = hcat(dots...)\ndots\n2Ã—11 Array{Float64,2}:\n 0.5  0.47535  0.5368  0.66245  â€¦  1.36905  1.4872  1.53815  1.5\n 1.0  1.3124   1.5312  1.6588      1.3052   1.0128  0.6436   0.2\n```\nThat was, I'd say, a success.\n\nDrunk with confidence, I wanted to try to reproduce the animation from the tweet, so I dug into the documentation. It didn't seem too bad, and I think I've managed to reproduce it pretty well\n```{julia}\nanim = @animate for t in collect(vcat(0:0.01:1,1:-0.01:0))\n    a = bz3(p1, p2, p3, p4)(t)(t)(t);\n    b1 = bz2(p1, p2, p3)(t)(t);\n    b2 = bz2(p2, p3, p4)(t)(t);\n    c1 = bz1(p1, p2)(t);\n    c2 = bz1(p2, p3)(t);\n    c3 = bz1(p3, p4)(t);\n    stars = hcat(p1, p2, p3, p4);\n    diamond1 = hcat(c1, c2);\n    diamond2 = hcat(c2, c3);\n    square = hcat(b1, b2);\n    plot(xlim = (-0.1,2.5), ylim = (-0.1,2.5), legend = false)\n    scatter!(dots[1,:], dots[2,:], markersize = 2)\n    plot!(diamond1[1,:], diamond1[2,:], markersize = 10, markershape = :diamond, color = :green)\n    plot!(diamond2[1,:], diamond2[2,:], markersize = 10, markershape = :diamond, color = :green)\n    plot!(square[1,:], square[2,:], markersize = 10, markershape = :square, color = :blue)\n    plot!(stars[1,:], stars[2,:], markersize = 10, markershape = :star, color = :purple)\n    scatter!(Tuple(a), markersize = 10, markershape = :circle, markercolor = :red)\nend\n\ngif(anim, fps = 24)\n```\n![](https://jcarroll.xyz/uploads/2022/ea5f75012f.gif)\n\nMoving the points around, I get a new version all of my own\n\n![](https://jcarroll.xyz/uploads/2022/b776bf8259.gif)\n\nI'm very happy with how these turned out, and I've learned a lot! A gist of the code to make these is hosted here: [https://gist.github.com/jonocarroll/27f9b57332424ea50ec2970e74d8e3b3](https://gist.github.com/jonocarroll/27f9b57332424ea50ec2970e74d8e3b3)\n\nIf there are better ways to do any of the steps (there surely are) please feel free to let me know!\n\nWas this fun? You Bezier ass!\n",
				"date_published": "2022-04-07T22:07:00+10:30",
				"url": "https://jcarroll.xyz/2022/04/07/interpolation-animation-in.html",
				"tags": ["Julia"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/03/25/r-challenge-contour.html",
				"title": "R challenge - contour in a matrix",
				"content_html": "<p>As part of what will hopefully become a larger post, I&rsquo;m interested in finding an R way to achieve the following: given an <code>n x n</code> matrix of zeroes with a single non-zero element of some value <code>v</code>, fill the surrounding entries such that each other element is at most one less than those surrounding it (up or down). For example, with an <code>8x8</code> matrix with a value of <code>5</code> at <code>c(5, 5)</code>, the result would be</p>\n<pre tabindex=\"0\"><code>     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n[1,]    0    0    0    0    1    0    0    0\n[2,]    0    0    0    1    2    1    0    0\n[3,]    0    0    1    2    3    2    1    0\n[4,]    0    0    2    3    4    3    2    1\n[5,]    1    2    3    4    5    4    3    2\n[6,]    0    1    2    3    4    3    2    1\n[7,]    0    0    1    2    3    2    1    0\n[8,]    0    0    0    1    2    1    0    0\n</code></pre><p>This is somewhat akin to imposing a contour density on top of a single peak, but I really can&rsquo;t find any suitable approaches. Convolutions came to mind, but I can&rsquo;t think of or find the appropriate kernel.</p>\n<p>Let me know if you have one!</p>\n<h2 id=\"update\">Update:</h2>\n<p>Thanks to <a href=\"https://twitter.com/yjunechoe/status/1507344665514848258?s=20&amp;t=27rn8zNl-36D-3ppsslAjw\">June Choe</a>, this code using <code>outer()</code> produces the desired matrix for a point at <code>c(vx, vy)</code> with value <code>vv</code> in a <code>n x n</code> matrix</p>\n<pre tabindex=\"0\"><code>vx &lt;- 4\nvy &lt;- 3\nvv &lt;- 5\nn &lt;- 8\nouter(1:n, 1:n, function(x, y) pmax(vv - abs(x - vx) - abs(y - vy), 0))\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n[1,]    0    1    2    1    0    0    0    0\n[2,]    1    2    3    2    1    0    0    0\n[3,]    2    3    4    3    2    1    0    0\n[4,]    3    4    5    4    3    2    1    0\n[5,]    2    3    4    3    2    1    0    0\n[6,]    1    2    3    2    1    0    0    0\n[7,]    0    1    2    1    0    0    0    0\n[8,]    0    0    1    0    0    0    0    0\n</code></pre>",
				"content_text": "As part of what will hopefully become a larger post, I'm interested in finding an R way to achieve the following: given an `n x n` matrix of zeroes with a single non-zero element of some value `v`, fill the surrounding entries such that each other element is at most one less than those surrounding it (up or down). For example, with an `8x8` matrix with a value of `5` at `c(5, 5)`, the result would be\n\n```\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n[1,]    0    0    0    0    1    0    0    0\n[2,]    0    0    0    1    2    1    0    0\n[3,]    0    0    1    2    3    2    1    0\n[4,]    0    0    2    3    4    3    2    1\n[5,]    1    2    3    4    5    4    3    2\n[6,]    0    1    2    3    4    3    2    1\n[7,]    0    0    1    2    3    2    1    0\n[8,]    0    0    0    1    2    1    0    0\n````\n\nThis is somewhat akin to imposing a contour density on top of a single peak, but I really can't find any suitable approaches. Convolutions came to mind, but I can't think of or find the appropriate kernel.\n\nLet me know if you have one!\n\n## Update:\n\nThanks to [June Choe](https://twitter.com/yjunechoe/status/1507344665514848258?s=20&t=27rn8zNl-36D-3ppsslAjw), this code using `outer()` produces the desired matrix for a point at `c(vx, vy)` with value `vv` in a `n x n` matrix \n```\nvx <- 4\nvy <- 3\nvv <- 5\nn <- 8\nouter(1:n, 1:n, function(x, y) pmax(vv - abs(x - vx) - abs(y - vy), 0))\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n[1,]    0    1    2    1    0    0    0    0\n[2,]    1    2    3    2    1    0    0    0\n[3,]    2    3    4    3    2    1    0    0\n[4,]    3    4    5    4    3    2    1    0\n[5,]    2    3    4    3    2    1    0    0\n[6,]    1    2    3    2    1    0    0    0\n[7,]    0    1    2    1    0    0    0    0\n[8,]    0    0    1    0    0    0    0    0\n```\n",
				"date_published": "2022-03-25T23:02:00+10:30",
				"url": "https://jcarroll.xyz/2022/03/25/r-challenge-contour.html",
				"tags": ["R"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/03/20/rowwise-optimizations-in.html",
				"title": "ByRow optimizations in Julia",
				"content_html": "<p>I&rsquo;m still fairly new to Julia, even though I&rsquo;ve been trying to learn it for a few years. It&rsquo;s <em>extremely</em> powerful (fast, expressive, &hellip; whatever metric you want to use) but with that comes some complexity.</p>\n<p>I saw <a href=\"https://bkamins.github.io/julialang/2022/02/25/anyall.html\">this post</a> in my feed and it seemed like a great bite-sized chunk of code to learn from. I <em>think</em> I understand everything that&rsquo;s happening, even if I certainly couldn&rsquo;t write that myself, with one exception.</p>\n<p>The connection that for <code>Bool</code> data, <code>all()</code> is equivalent to <code>minimum()</code> (it&rsquo;s false as soon as there is one 0, otherwise it&rsquo;s true) and <code>any()</code> is equivalent to <code>maximum()</code> (if there&rsquo;s a 1 it&rsquo;s true) took me a moment, but seems pretty cool. That wasn&rsquo;t the problem I had.</p>\n<p>The bit that surprised me was that for <code>ByRow</code> calculations on a <code>DataFrame</code>, <code>minimum()</code> is <strong>faster</strong> than <code>all()</code>. The reason this is so surprising for me is that I understand <code>all()</code> from an R-perspective and my understanding was that <code>all()</code> could short-circuit because as soon as it sees a <code>FALSE</code> it can ignore any other values - the result is guaranteed to be <code>FALSE</code> (yes, yes, up to missingness). Surely, a calculation of <code>minimum()</code> needs to evaluate every value at least once (?). Where this might (must?) fall apart is that I&rsquo;m thinking purely of vectors. Sure enough, checking out some timings on a vector in Julia shows <code>all()</code> is near-instantaneous (after compilation)</p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">x = rand(Bool, 100_000_000)\n\n@time all(x)\n  0.009047 seconds (218 allocations: 9.531 KiB, 99.85% compilation time)\nfalse\n\n@time all(x)\n  0.000002 seconds\nfalse\n\n@time minimum(x)\n  0.091183 seconds (85.03 k allocations: 4.461 MiB, 41.98% compilation time)\nfalse\n\n@time minimum(x)\n  0.052287 seconds\nfalse\n</code></pre><p>I get similar results, expectedly, from R</p>\n<pre tabindex=\"0\"><code class=\"language-{r}\" data-lang=\"{r}\">x &lt;- sample(c(TRUE, FALSE), 1e8, replace = TRUE)\nmicrobenchmark::microbenchmark(\n  min = max(x),\n  any = any(x),\n  times = 10\n)\n# Unit: nanoseconds\n#  expr       min        lq        mean    median        uq       max neval\n#   min 208741173 210539351 223219500.3 212388892 222673528 285974960    10\n#   any       160       187      2403.4       295      5095      7451    10\n</code></pre><p>So, what&rsquo;s going on? I <em>think</em> the answer is that we&rsquo;re not dealing with just a vector, it&rsquo;s rows from a <code>DataFrame</code>, right? Now, from the R side, that&rsquo;s complicated enough - <code>rowwise()</code> is a <a href=\"https://speakerdeck.com/jennybc/row-oriented-workflows-in-r-with-the-tidyverse\">necessary thing</a> because R stores a <code>data.frame</code> as a list of vectors representing <em>columns</em>, so extracting a row means slicing across those.</p>\n<p>I can reproduce the speedup in Julia (and honestly, I struggle to find a clean and fast way to do it in R) but the statement &ldquo;<a href=\"https://bkamins.github.io/julialang/2022/02/25/anyall.html#:~:text=This%20time%20things%20are%20very%20fast%2C%20as%20row%2Dwise%20aggregation%20for%20maximum%20and%20minimum%20is%20optimized.\">This time things are very fast, as row-wise aggregation for maximum and minimum is optimized.</a>&rdquo; got me thinking - where should I have learned that? Google isn&rsquo;t showing me any relevant results, so is this just a known thing? I can imagine that such an optimization for doing this might exist, but can anyone provide a reference or guide?? The author of the blog post used this optimization in a <a href=\"https://stackoverflow.com/a/71209103/4168169\">StackOverflow answer</a> without challenge (no reference provided) so I feel like it&rsquo;s potentially just something I should know.</p>\n",
				"content_text": "I'm still fairly new to Julia, even though I've been trying to learn it for a few years. It's *extremely* powerful (fast, expressive, ... whatever metric you want to use) but with that comes some complexity. \n\nI saw [this post](https://bkamins.github.io/julialang/2022/02/25/anyall.html) in my feed and it seemed like a great bite-sized chunk of code to learn from. I *think* I understand everything that's happening, even if I certainly couldn't write that myself, with one exception.\n\nThe connection that for `Bool` data, `all()` is equivalent to `minimum()` (it's false as soon as there is one 0, otherwise it's true) and `any()` is equivalent to `maximum()` (if there's a 1 it's true) took me a moment, but seems pretty cool. That wasn't the problem I had.\n\nThe bit that surprised me was that for `ByRow` calculations on a `DataFrame`, `minimum()` is **faster** than `all()`. The reason this is so surprising for me is that I understand `all()` from an R-perspective and my understanding was that `all()` could short-circuit because as soon as it sees a `FALSE` it can ignore any other values - the result is guaranteed to be `FALSE` (yes, yes, up to missingness). Surely, a calculation of `minimum()` needs to evaluate every value at least once (?). Where this might (must?) fall apart is that I'm thinking purely of vectors. Sure enough, checking out some timings on a vector in Julia shows `all()` is near-instantaneous (after compilation)\n```{julia}\nx = rand(Bool, 100_000_000)\n\n@time all(x)\n  0.009047 seconds (218 allocations: 9.531 KiB, 99.85% compilation time)\nfalse\n\n@time all(x)\n  0.000002 seconds\nfalse\n\n@time minimum(x)\n  0.091183 seconds (85.03 k allocations: 4.461 MiB, 41.98% compilation time)\nfalse\n\n@time minimum(x)\n  0.052287 seconds\nfalse\n```\nI get similar results, expectedly, from R\n```{r}\nx <- sample(c(TRUE, FALSE), 1e8, replace = TRUE)\nmicrobenchmark::microbenchmark(\n  min = max(x),\n  any = any(x),\n  times = 10\n)\n# Unit: nanoseconds\n#  expr       min        lq        mean    median        uq       max neval\n#   min 208741173 210539351 223219500.3 212388892 222673528 285974960    10\n#   any       160       187      2403.4       295      5095      7451    10\n```\nSo, what's going on? I *think* the answer is that we're not dealing with just a vector, it's rows from a `DataFrame`, right? Now, from the R side, that's complicated enough - `rowwise()` is a [necessary thing](https://speakerdeck.com/jennybc/row-oriented-workflows-in-r-with-the-tidyverse) because R stores a `data.frame` as a list of vectors representing *columns*, so extracting a row means slicing across those. \n\nI can reproduce the speedup in Julia (and honestly, I struggle to find a clean and fast way to do it in R) but the statement \"[This time things are very fast, as row-wise aggregation for maximum and minimum is optimized.](https://bkamins.github.io/julialang/2022/02/25/anyall.html#:~:text=This%20time%20things%20are%20very%20fast%2C%20as%20row%2Dwise%20aggregation%20for%20maximum%20and%20minimum%20is%20optimized.)\" got me thinking - where should I have learned that? Google isn't showing me any relevant results, so is this just a known thing? I can imagine that such an optimization for doing this might exist, but can anyone provide a reference or guide?? The author of the blog post used this optimization in a [StackOverflow answer](https://stackoverflow.com/a/71209103/4168169) without challenge (no reference provided) so I feel like it's potentially just something I should know.\n",
				"date_published": "2022-03-20T14:11:00+10:30",
				"url": "https://jcarroll.xyz/2022/03/20/rowwise-optimizations-in.html",
				"tags": ["R","Julia"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/03/20/first-post-on.html",
				"title": "First post on jcarroll.xyz",
				"content_html": "<p>I like blogging, but in the spirit of lowering the resistance to getting posts out, I&rsquo;ve started a micro blog <a href=\"https://jcarroll.xyz\">jcarroll.xyz</a> where I&rsquo;ll capture shorter, less polished pieces and random thoughts / snippets.</p>\n<p>This is my first post, testing all the functionality. DNS might still take a little while, so don&rsquo;t worry if you see my full blog when you click the link.</p>\n",
				"content_text": "I like blogging, but in the spirit of lowering the resistance to getting posts out, I've started a micro blog [jcarroll.xyz](https://jcarroll.xyz) where I'll capture shorter, less polished pieces and random thoughts / snippets.\n\nThis is my first post, testing all the functionality. DNS might still take a little while, so don't worry if you see my full blog when you click the link.\n",
				"date_published": "2022-03-20T12:28:39+10:30",
				"url": "https://jcarroll.xyz/2022/03/20/first-post-on.html"
			}
	]
}
