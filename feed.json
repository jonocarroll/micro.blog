{
	"version": "https://jsonfeed.org/version/1",
	"title": "Jonathan Carroll's micro blog",
	"icon": "https://micro.blog/jonocarroll/avatar.jpg",
	"home_page_url": "https://jcarroll.xyz/",
	"feed_url": "https://jcarroll.xyz/feed.json",
	"items": [
		
			{
				"id": "http://jonocarroll.micro.blog/2022/07/09/finished-reading-the.html",
				"title": "Finished reading: The End of Eternity by Isaac Asimov",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9780593160060\">The End of Eternity</a> by Isaac Asimov</p>\n<p>Easily one of the greatest science fiction writers of all time, and it&rsquo;s easy to see why. I&rsquo;ve loved many of them, but I haven&rsquo;t read anywhere near all of Asimov&rsquo;s works. I saw this one on a shelf and figured it would be a nice break from the much heavier non-fiction biology I&rsquo;ve been reading lately.</p>\n<p>The craftsmanship of Asimov&rsquo;s writing always leaves me pleased. Small callbacks throughout seem effortless; the words never seem to be shoehorned in order to tie together different threads (with other authors, certain sentences have a certain &lsquo;<a href=\"https://en.wikipedia.org/wiki/Chekhov%27s_gun\">Chekhov&rsquo;s gun</a>&rsquo; flavour to them).</p>\n<p>I enjoyed reading this book. Twists and turns, a careful balance of science and hand-waving, and a not-too-overwhelming set of characters. I&rsquo;ll certainly be keeping an eye out for more of Asimov&rsquo;s works to correct my lack of coverage. Recommended to time-travel and general sci-fi enthusiasts.</p>\n",
				"content_text": "Finished reading: [The End of Eternity](https://micro.blog/books/9780593160060) by Isaac Asimov \n\nEasily one of the greatest science fiction writers of all time, and it's easy to see why. I've loved many of them, but I haven't read anywhere near all of Asimov's works. I saw this one on a shelf and figured it would be a nice break from the much heavier non-fiction biology I've been reading lately.\n\nThe craftsmanship of Asimov's writing always leaves me pleased. Small callbacks throughout seem effortless; the words never seem to be shoehorned in order to tie together different threads (with other authors, certain sentences have a certain '[Chekhov's gun](https://en.wikipedia.org/wiki/Chekhov%27s_gun)' flavour to them).\n\nI enjoyed reading this book. Twists and turns, a careful balance of science and hand-waving, and a not-too-overwhelming set of characters. I'll certainly be keeping an eye out for more of Asimov's works to correct my lack of coverage. Recommended to time-travel and general sci-fi enthusiasts.\n",
				"date_published": "2022-07-09T17:07:59+09:30",
				"url": "https://jcarroll.xyz/2022/07/09/finished-reading-the.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/06/29/currently-reading-start.html",
				"title": "Currently reading: Start With Why by Simon Sinek ",
				"content_html": "<p>Currently reading: <a href=\"https://micro.blog/books/9780241958230\">Start With Why</a> by Simon Sinek</p>\n<p>I was recommended this book by someone whose opinion I hold in high regard, but so far I&rsquo;m not enjoying this book. Not necessarily for the material - I think I can appreciate the points being made about having a defined &lsquo;why&rsquo; behind a company and explanations of the various manipulations a company can leverage rather than actually being better than the competition, but rather the extreme &ldquo;American-ness&rdquo; of the author. Especially surprising since the author has a more diverse background than simply &lsquo;American&rsquo;.</p>\n<p>It took 48 pages before a single non-American company was mentioned (Ferarri), and even then it was in the context of</p>\n<blockquote>\n<p>&ldquo;if you have a family of six a two-seater Ferarri is not better. However, if you&rsquo;re looking for a great way to meet women, a Honda minivan is probably not better&rdquo;.</p>\n</blockquote>\n<p>I&rsquo;m long out of the dating scene, but that seems&hellip; like a terrible comparison. Is that part of the purchasing decision? I suppose maybe it is for some, but as a reliable consumer group?</p>\n<p>Multiple references to Apple Macs and iTunes being brilliant innovations &ldquo;because people connected with the why of the company&rdquo;. iTunes was a terrible product that was forced onto users in order to use the iPod (a distinct improvement over the removable media competition). My understanding is that it gained significant market share over CDs because it was easier (and potentially cheaper - if you wanted a single song). For myself and many others (the reason I believe it was actually innovative) it was <em>easier</em> than pirating music. A dollar for a song compared to a handful of dollars for a CD or the <em>hassle</em> of downloading and uploading a file - it solved a problem. I don&rsquo;t attribute that to Apple&rsquo;s &ldquo;why&rdquo; - another company that offered that might just as well have had the same success.</p>\n<p>Chapter 4 seems to end with the explanation that &ldquo;Harley Davidson riders want Harleys&rdquo; and &ldquo;Mac people want something starting with an <em>i</em>&rdquo; and that there&rsquo;s a cult aspect to this based on loyalty above actual product superiority but I don&rsquo;t believe this is grounded in any &ldquo;why&rdquo; of those companies. They&rsquo;ve each done well at convincing buyers to be part of their collective, and they&rsquo;ve each done well at having some features their buyers do appreciate (loud engines or smooth interfaces) but they&rsquo;re both viewed as objectively worse products by people who can be considered unbiased. The example of &ldquo;U2 being iconoclastic&rdquo; and so a joint promotional iPod &ldquo;makes sense&rdquo; got a genuine chuckle from me - did people buy more iPods because U2 were involved? From everything I saw of that time, it was ridiculed. Users had an entire album forced onto their devices that they had no interest in.</p>\n<p>Then more &ldquo;everyone is American&rdquo; - I actually had to put the book down during the chapter explaining &ldquo;the biology of belonging&rdquo; with the sentence</p>\n<blockquote>\n<p>&ldquo;Go abroad and you&rsquo;ll form instant bonds with other Americans you meet&rdquo;</p>\n</blockquote>\n<p>Other? I&rsquo;m Australian.</p>\n<p>I got really upset at repeated references to language structure having some &ldquo;hidden meaning&rdquo;. Is it a coincidence that the phrase is &ldquo;hearts and minds&rdquo; in that order? Or &ldquo;art and science&rdquo;&hellip; No. Not really. Sure, the rules are vague, but it&rsquo;s not particularly meaningful in the way the author hints at. There are <a href=\"https://www.cambridge.org/elt/blog/2017/08/31/chips-and-fish-word-order-in-english-collocations/\">accepted orderings</a> to some combinations of words known as &ldquo;collocations&rdquo; that &ldquo;make sense&rdquo; to a native English speaker - anyone who hears &ldquo;chips and fish&rdquo; will instantly recognise something is wrong. The &ldquo;i&rdquo; (/ɪ/) in both &ldquo;mind&rdquo; (/maɪnd/) and &ldquo;science&rdquo; (/ˈsaɪ.əns/) fits well into the regular pattern.</p>\n<p>The same allusion to the layout of the &ldquo;Golden Circle&rdquo; having some correlation with the physical brain structure reeks of ill-informed motivational speakers and those who say &ldquo;walnuts are good for your brain because they look like a brain&rdquo;.</p>\n<p>I&rsquo;m still going to give the rest of the book a chance, but so far it&rsquo;s not rating high.</p>\n",
				"content_text": "Currently reading: [Start With Why](https://micro.blog/books/9780241958230) by Simon Sinek \n\nI was recommended this book by someone whose opinion I hold in high regard, but so far I'm not enjoying this book. Not necessarily for the material - I think I can appreciate the points being made about having a defined 'why' behind a company and explanations of the various manipulations a company can leverage rather than actually being better than the competition, but rather the extreme \"American-ness\" of the author. Especially surprising since the author has a more diverse background than simply 'American'.\n\nIt took 48 pages before a single non-American company was mentioned (Ferarri), and even then it was in the context of\n\n> \"if you have a family of six a two-seater Ferarri is not better. However, if you're looking for a great way to meet women, a Honda minivan is probably not better\".\n\nI'm long out of the dating scene, but that seems... like a terrible comparison. Is that part of the purchasing decision? I suppose maybe it is for some, but as a reliable consumer group?\n\nMultiple references to Apple Macs and iTunes being brilliant innovations \"because people connected with the why of the company\". iTunes was a terrible product that was forced onto users in order to use the iPod (a distinct improvement over the removable media competition). My understanding is that it gained significant market share over CDs because it was easier (and potentially cheaper - if you wanted a single song). For myself and many others (the reason I believe it was actually innovative) it was *easier* than pirating music. A dollar for a song compared to a handful of dollars for a CD or the *hassle* of downloading and uploading a file - it solved a problem. I don't attribute that to Apple's \"why\" - another company that offered that might just as well have had the same success.\n\nChapter 4 seems to end with the explanation that \"Harley Davidson riders want Harleys\" and \"Mac people want something starting with an _i_\" and that there's a cult aspect to this based on loyalty above actual product superiority but I don't believe this is grounded in any \"why\" of those companies. They've each done well at convincing buyers to be part of their collective, and they've each done well at having some features their buyers do appreciate (loud engines or smooth interfaces) but they're both viewed as objectively worse products by people who can be considered unbiased. The example of \"U2 being iconoclastic\" and so a joint promotional iPod \"makes sense\" got a genuine chuckle from me - did people buy more iPods because U2 were involved? From everything I saw of that time, it was ridiculed. Users had an entire album forced onto their devices that they had no interest in.\n\nThen more \"everyone is American\" - I actually had to put the book down during the chapter explaining \"the biology of belonging\" with the sentence\n\n> \"Go abroad and you'll form instant bonds with other Americans you meet\"\n\nOther? I'm Australian.\n\nI got really upset at repeated references to language structure having some \"hidden meaning\". Is it a coincidence that the phrase is \"hearts and minds\" in that order? Or \"art and science\"... No. Not really. Sure, the rules are vague, but it's not particularly meaningful in the way the author hints at. There are [accepted orderings](https://www.cambridge.org/elt/blog/2017/08/31/chips-and-fish-word-order-in-english-collocations/) to some combinations of words known as \"collocations\" that \"make sense\" to a native English speaker - anyone who hears \"chips and fish\" will instantly recognise something is wrong. The \"i\" (/ɪ/) in both \"mind\" (/maɪnd/) and \"science\" (/ˈsaɪ.əns/) fits well into the regular pattern.\n\nThe same allusion to the layout of the \"Golden Circle\" having some correlation with the physical brain structure reeks of ill-informed motivational speakers and those who say \"walnuts are good for your brain because they look like a brain\".\n\nI'm still going to give the rest of the book a chance, but so far it's not rating high.\n",
				"date_published": "2022-06-29T22:45:19+09:30",
				"url": "https://jcarroll.xyz/2022/06/29/currently-reading-start.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/06/28/finished-reading-the.html",
				"title": "Finished reading: The Cell by Joshua Z. Rappoport 📚",
				"content_html": "<p>Finished reading: <a href=\"https://micro.blog/books/9781944648978\">The Cell</a> by Joshua Z. Rappoport 📚</p>\n<p>I enjoyed this book - it started with a good overview of the cellular biology but did move on to more organ-based systems, which was perfect for me. The explanations of the lab and microscopy techniques, advancements, innovations, and discoveries were particularly nice. The detour to examples of academic fraud took a dark turn for such a pleasant book. Recommended for those looking for a nice balance of in-depth science and casual explanations.</p>\n",
				"content_text": "Finished reading: [The Cell](https://micro.blog/books/9781944648978) by Joshua Z. Rappoport 📚\r\n\r\nI enjoyed this book - it started with a good overview of the cellular biology but did move on to more organ-based systems, which was perfect for me. The explanations of the lab and microscopy techniques, advancements, innovations, and discoveries were particularly nice. The detour to examples of academic fraud took a dark turn for such a pleasant book. Recommended for those looking for a nice balance of in-depth science and casual explanations.\n",
				"date_published": "2022-06-28T14:16:18+09:30",
				"url": "https://jcarroll.xyz/2022/06/28/finished-reading-the.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/06/11/currently-reading-the.html",
				"title": "Currently reading: The Cell: Discovering the Microscopic World that Determines our Health, our Consciousness, and our Future",
				"content_html": "<p>Currently reading: <a href=\"https://micro.blog/books/9781944648978\">The Cell: Discovering the Microscopic World that Determines our Health, our Consciousness, and our Future</a> by Joshua Z. Rappoport</p>\n<p>Continuing with the technical theme, so far this is a deep dive into the very specific mechanisms of molecular biology without (yet) too much emphasis on particular cells.</p>\n<p>What surprised me so far was that <a href=\"https://en.wikipedia.org/wiki/Polymerase_chain_reaction\">PCR</a> (as a technology) is only as old as I am. It&rsquo;s gained a lot of attention thanks to a particular virus we&rsquo;ve all heard too much about. I&rsquo;d never run one of these reactions myself (having not passed through a university biology department) and wasn&rsquo;t aware of the technical details. I had heard various claims by armchair biologists that the COVID PCR test was &ldquo;just detecting the flu&rdquo; and that &ldquo;if you run enough cycles you can find anything&rdquo; but with a better explanation of how it works - primers and temperature cycling - it&rsquo;s clear that&rsquo;s all just a load of nonsense. I&rsquo;m enjoying this one so far.</p>\n<p>Also news to me was that RT-PCR (Reverse Transcription-Polymerase Chain Reaction) is the name applicable to PCR of an RNA virus (as <a href=\"https://en.wikipedia.org/wiki/Severe_acute_respiratory_syndrome_coronavirus_2\">SARS-CoV-2</a> is) and not a meaningfully different version to PCR in that case, despite <a href=\"https://www.flysfo.com/travel-well/covid-19-testing\">some listings having both</a>.</p>\n",
				"content_text": "Currently reading: [The Cell: Discovering the Microscopic World that Determines our Health, our Consciousness, and our Future](https://micro.blog/books/9781944648978) by Joshua Z. Rappoport \n\nContinuing with the technical theme, so far this is a deep dive into the very specific mechanisms of molecular biology without (yet) too much emphasis on particular cells. \n\nWhat surprised me so far was that [PCR](https://en.wikipedia.org/wiki/Polymerase_chain_reaction) (as a technology) is only as old as I am. It's gained a lot of attention thanks to a particular virus we've all heard too much about. I'd never run one of these reactions myself (having not passed through a university biology department) and wasn't aware of the technical details. I had heard various claims by armchair biologists that the COVID PCR test was \"just detecting the flu\" and that \"if you run enough cycles you can find anything\" but with a better explanation of how it works - primers and temperature cycling - it's clear that's all just a load of nonsense. I'm enjoying this one so far.\n\nAlso news to me was that RT-PCR (Reverse Transcription-Polymerase Chain Reaction) is the name applicable to PCR of an RNA virus (as [SARS-CoV-2](https://en.wikipedia.org/wiki/Severe_acute_respiratory_syndrome_coronavirus_2) is) and not a meaningfully different version to PCR in that case, despite [some listings having both](https://www.flysfo.com/travel-well/covid-19-testing).\n",
				"date_published": "2022-06-11T17:06:26+09:30",
				"url": "https://jcarroll.xyz/2022/06/11/currently-reading-the.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/06/11/finished-reading-life.html",
				"title": "Finished reading: Life Unfolding: How the Human Body Creates Itself",
				"content_html": "<p><a href=\"https://micro.blog/books/9780199673537\">Life Unfolding: How the Human Body Creates Itself</a> by Jamie A. Davies</p>\n<p>How a single cell develops into a full human, and a lot of the molecular biology along the way. I thoroughly enjoyed this read - every chapter had highly interesting points about the particular pathways involved and how the cells end up &ldquo;choosing&rdquo; to do all the things they do; move where they need to move, align along directions, and proliferate/die. I spent a lot of time pausing my reading, looking up branches of other information and going down other rabbit holes. I read this as a library loan, but I enjoyed it so much I&rsquo;ve bought my own permanent copy.</p>\n<p>What surprised me the most (having taken a non-traditional route into biology via physics and programming) - but probably shouldn&rsquo;t have - was how the entire system efficiently re-use mechanisms and pathways for both very early development and for ongoing functionality. I recognised several genes from my cancer immunology work, but I always regarded these as &lsquo;just part of the genetic makeup of a person&rsquo;, not paying attention to how they were critical to actually creating the fully grown person, and are now being repurposed. It&rsquo;s perhaps obvious in hindsight, but there aren&rsquo;t a set of genes for pre-natal growth and another set for adult life. It makes the fact that sometimes these mechanisms fail to work perfectly all the more understandable.</p>\n<p>Highly recommend to anyone interested in the very technical details, but a well-presented resource for those generally interested.</p>\n<!-- raw HTML omitted -->\n",
				"content_text": "[Life Unfolding: How the Human Body Creates Itself](https://micro.blog/books/9780199673537) by Jamie A. Davies \n\nHow a single cell develops into a full human, and a lot of the molecular biology along the way. I thoroughly enjoyed this read - every chapter had highly interesting points about the particular pathways involved and how the cells end up \"choosing\" to do all the things they do; move where they need to move, align along directions, and proliferate/die. I spent a lot of time pausing my reading, looking up branches of other information and going down other rabbit holes. I read this as a library loan, but I enjoyed it so much I've bought my own permanent copy.\n\nWhat surprised me the most (having taken a non-traditional route into biology via physics and programming) - but probably shouldn't have - was how the entire system efficiently re-use mechanisms and pathways for both very early development and for ongoing functionality. I recognised several genes from my cancer immunology work, but I always regarded these as 'just part of the genetic makeup of a person', not paying attention to how they were critical to actually creating the fully grown person, and are now being repurposed. It's perhaps obvious in hindsight, but there aren't a set of genes for pre-natal growth and another set for adult life. It makes the fact that sometimes these mechanisms fail to work perfectly all the more understandable.\n\nHighly recommend to anyone interested in the very technical details, but a well-presented resource for those generally interested.\n\n<img src=\"uploads/2022/d82072c1a2.jpg\" width=\"600\" height=\"800\" alt=\"\" />\n",
				"date_published": "2022-06-11T16:49:17+09:30",
				"url": "https://jcarroll.xyz/2022/06/11/finished-reading-life.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/06/11/163214.html",
				"title": "Finished reading: Life from an RNA World: The Ancestor Within",
				"content_html": "<p>(backlog from March 2022)</p>\n<p><a href=\"https://micro.blog/books/9780674050754\">Life from an RNA World: The Ancestor Within</a> by Michael Yarus</p>\n<p>This was a nice tour of how the complex mechanisms of DNA replication came to be, and how the process works to produce proteins and phenotypes. This was the first time I really felt I understood the difference between DNA and RNA, and how such a mechanism evolved. Highly recommend to anyone interested in genomics/genetics at a technical level.</p>\n",
				"content_text": "(backlog from March 2022)\n\n[Life from an RNA World: The Ancestor Within](https://micro.blog/books/9780674050754) by Michael Yarus\n\nThis was a nice tour of how the complex mechanisms of DNA replication came to be, and how the process works to produce proteins and phenotypes. This was the first time I really felt I understood the difference between DNA and RNA, and how such a mechanism evolved. Highly recommend to anyone interested in genomics/genetics at a technical level.\n",
				"date_published": "2022-06-11T16:48:07+09:30",
				"url": "https://jcarroll.xyz/2022/06/11/163214.html",
				"tags": ["Books"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/04/07/interpolation-animation-in.html",
				"title": "Interpolation animation in Julia",
				"content_html": "<p>I <em>love</em> small projects for helping me learn, especially programming. I&rsquo;m still learning Julia, and have found myself wanting more &ldquo;little silly things&rdquo; I can digest and learn from. A lot of the projects I see in Julia are big mathematical models, and I&rsquo;m just not ready to dive that deep yet.</p>\n<p><a href=\"https://twitter.com/ted_dunning/status/1435027697386721280?s=20&amp;t=cDVb0XOQRJeOjXoTrOz54w\">This series of tweets</a> caught my eye, partly because of the cool animation, but also the bite-sized amount of information it was conveying - that interpolation in Julia can be specified so easily, thanks in large part to the multiple dispatch design of the language.</p>\n<p>&ldquo;Surely I could get those 7 lines of code to run&rdquo; I thought.</p>\n<p>Entering the code into VScode was straightforward enough, no problems there. I could define the interpolation function</p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">interpolate(a, b) = t -&gt; ((1.0-t)*a + t*b)\n</code></pre><p>however extending the <code>*</code> and <code>+</code> methods did require me to <code>import Base:*</code> and <code>import Base:+</code> which I think I knew but had forgotten.</p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">+(f::Function, g::Function) = x -&gt; f(x) + g(x)\n*(t::Number, g::Function) = x -&gt; t * g(x)\n</code></pre><p>Defining the secondary and tertiary interpolations, also straightforward</p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">bz1(p1, p2) = interpolate(p1, p2)\nbz2(p1, p2, p3) = interpolate(bz1(p1, p2), bz1(p2, p3))\nbz3(p1, p2, p3, p4) = interpolate(bz2(p1, p2, p3), bz2(p2, p3, p4))\n</code></pre><p>Now the tricky part - evaluating some of these. I knew that <code>a</code> and <code>b</code> represent points, but how to do that here? They&rsquo;re not single numbers, but coordinates. I tried a <code>Tuple</code> as <code>(1, 2)</code> but that doesn&rsquo;t seem to work. I do need to remember that <code>interpolate</code> is itself a function of <code>t</code>, so that needs to be specified as well. If I try to interpolate halfway between two &ldquo;points&rdquo; with <code>Tuple</code>s</p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">interpolate((0,1), (1,2))(0.5)\nERROR: MethodError: no method matching *(::Float64, ::Tuple{Int64,Int64})\nClosest candidates are:\n  *(::Any, ::Any, ::Any, ::Any...) at operators.jl:538\n  *(::Float64, ::Float64) at float.jl:405\n  *(::AbstractFloat, ::Bool) at bool.jl:112\n</code></pre><p>Okay, how about <code>Array</code>s?</p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">interpolate([0,1], [1,2])(0.5)\n2-element Array{Float64,1}:\n 0.5\n 1.5\n</code></pre><p>Huzzah!</p>\n<p>After that, it&rsquo;s a matter of generating the points specified by</p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">bz3(p1, p2, p3, p4)(t)(t)(t)\n</code></pre><p>for various values of <code>t</code>. I did that with a <code>map</code> and joined the results back into a single <code>Array</code></p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">dots = map(i -&gt; bz3(p1, p2, p3, p4)(i)(i)(i),collect(0:0.1:1))\ndots = hcat(dots...)\ndots\n2×11 Array{Float64,2}:\n 0.5  0.47535  0.5368  0.66245  …  1.36905  1.4872  1.53815  1.5\n 1.0  1.3124   1.5312  1.6588      1.3052   1.0128  0.6436   0.2\n</code></pre><p>That was, I&rsquo;d say, a success.</p>\n<p>Drunk with confidence, I wanted to try to reproduce the animation from the tweet, so I dug into the documentation. It didn&rsquo;t seem too bad, and I think I&rsquo;ve managed to reproduce it pretty well</p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">anim = @animate for t in collect(vcat(0:0.01:1,1:-0.01:0))\n    a = bz3(p1, p2, p3, p4)(t)(t)(t);\n    b1 = bz2(p1, p2, p3)(t)(t);\n    b2 = bz2(p2, p3, p4)(t)(t);\n    c1 = bz1(p1, p2)(t);\n    c2 = bz1(p2, p3)(t);\n    c3 = bz1(p3, p4)(t);\n    stars = hcat(p1, p2, p3, p4);\n    diamond1 = hcat(c1, c2);\n    diamond2 = hcat(c2, c3);\n    square = hcat(b1, b2);\n    plot(xlim = (-0.1,2.5), ylim = (-0.1,2.5), legend = false)\n    scatter!(dots[1,:], dots[2,:], markersize = 2)\n    plot!(diamond1[1,:], diamond1[2,:], markersize = 10, markershape = :diamond, color = :green)\n    plot!(diamond2[1,:], diamond2[2,:], markersize = 10, markershape = :diamond, color = :green)\n    plot!(square[1,:], square[2,:], markersize = 10, markershape = :square, color = :blue)\n    plot!(stars[1,:], stars[2,:], markersize = 10, markershape = :star, color = :purple)\n    scatter!(Tuple(a), markersize = 10, markershape = :circle, markercolor = :red)\nend\n\ngif(anim, fps = 24)\n</code></pre><p><img src=\"https://jcarroll.xyz/uploads/2022/ea5f75012f.gif\" alt=\"\"></p>\n<p>Moving the points around, I get a new version all of my own</p>\n<p><img src=\"https://jcarroll.xyz/uploads/2022/b776bf8259.gif\" alt=\"\"></p>\n<p>I&rsquo;m very happy with how these turned out, and I&rsquo;ve learned a lot! A gist of the code to make these is hosted here: <a href=\"https://gist.github.com/jonocarroll/27f9b57332424ea50ec2970e74d8e3b3\">https://gist.github.com/jonocarroll/27f9b57332424ea50ec2970e74d8e3b3</a></p>\n<p>If there are better ways to do any of the steps (there surely are) please feel free to let me know!</p>\n<p>Was this fun? You Bezier ass!</p>\n",
				"content_text": "I *love* small projects for helping me learn, especially programming. I'm still learning Julia, and have found myself wanting more \"little silly things\" I can digest and learn from. A lot of the projects I see in Julia are big mathematical models, and I'm just not ready to dive that deep yet.\n\n[This series of tweets](https://twitter.com/ted_dunning/status/1435027697386721280?s=20&t=cDVb0XOQRJeOjXoTrOz54w) caught my eye, partly because of the cool animation, but also the bite-sized amount of information it was conveying - that interpolation in Julia can be specified so easily, thanks in large part to the multiple dispatch design of the language.\n\n\"Surely I could get those 7 lines of code to run\" I thought.\n\nEntering the code into VScode was straightforward enough, no problems there. I could define the interpolation function \n```{julia}\ninterpolate(a, b) = t -> ((1.0-t)*a + t*b)\n```\nhowever extending the `*` and `+` methods did require me to `import Base:*` and `import Base:+` which I think I knew but had forgotten.\n```{julia}\n+(f::Function, g::Function) = x -> f(x) + g(x)\n*(t::Number, g::Function) = x -> t * g(x)\n```\nDefining the secondary and tertiary interpolations, also straightforward\n```{julia}\nbz1(p1, p2) = interpolate(p1, p2)\nbz2(p1, p2, p3) = interpolate(bz1(p1, p2), bz1(p2, p3))\nbz3(p1, p2, p3, p4) = interpolate(bz2(p1, p2, p3), bz2(p2, p3, p4))\n```\nNow the tricky part - evaluating some of these. I knew that `a` and `b` represent points, but how to do that here? They're not single numbers, but coordinates. I tried a `Tuple` as `(1, 2)` but that doesn't seem to work. I do need to remember that `interpolate` is itself a function of `t`, so that needs to be specified as well. If I try to interpolate halfway between two \"points\" with `Tuple`s\n```{julia}\ninterpolate((0,1), (1,2))(0.5)\nERROR: MethodError: no method matching *(::Float64, ::Tuple{Int64,Int64})\nClosest candidates are:\n  *(::Any, ::Any, ::Any, ::Any...) at operators.jl:538\n  *(::Float64, ::Float64) at float.jl:405\n  *(::AbstractFloat, ::Bool) at bool.jl:112\n```\nOkay, how about `Array`s?\n```{julia}\ninterpolate([0,1], [1,2])(0.5)\n2-element Array{Float64,1}:\n 0.5\n 1.5\n```\nHuzzah!\n\nAfter that, it's a matter of generating the points specified by\n```{julia}\nbz3(p1, p2, p3, p4)(t)(t)(t)\n```\nfor various values of `t`. I did that with a `map` and joined the results back into a single `Array`\n```{julia}\ndots = map(i -> bz3(p1, p2, p3, p4)(i)(i)(i),collect(0:0.1:1))\ndots = hcat(dots...)\ndots\n2×11 Array{Float64,2}:\n 0.5  0.47535  0.5368  0.66245  …  1.36905  1.4872  1.53815  1.5\n 1.0  1.3124   1.5312  1.6588      1.3052   1.0128  0.6436   0.2\n```\nThat was, I'd say, a success.\n\nDrunk with confidence, I wanted to try to reproduce the animation from the tweet, so I dug into the documentation. It didn't seem too bad, and I think I've managed to reproduce it pretty well\n```{julia}\nanim = @animate for t in collect(vcat(0:0.01:1,1:-0.01:0))\n    a = bz3(p1, p2, p3, p4)(t)(t)(t);\n    b1 = bz2(p1, p2, p3)(t)(t);\n    b2 = bz2(p2, p3, p4)(t)(t);\n    c1 = bz1(p1, p2)(t);\n    c2 = bz1(p2, p3)(t);\n    c3 = bz1(p3, p4)(t);\n    stars = hcat(p1, p2, p3, p4);\n    diamond1 = hcat(c1, c2);\n    diamond2 = hcat(c2, c3);\n    square = hcat(b1, b2);\n    plot(xlim = (-0.1,2.5), ylim = (-0.1,2.5), legend = false)\n    scatter!(dots[1,:], dots[2,:], markersize = 2)\n    plot!(diamond1[1,:], diamond1[2,:], markersize = 10, markershape = :diamond, color = :green)\n    plot!(diamond2[1,:], diamond2[2,:], markersize = 10, markershape = :diamond, color = :green)\n    plot!(square[1,:], square[2,:], markersize = 10, markershape = :square, color = :blue)\n    plot!(stars[1,:], stars[2,:], markersize = 10, markershape = :star, color = :purple)\n    scatter!(Tuple(a), markersize = 10, markershape = :circle, markercolor = :red)\nend\n\ngif(anim, fps = 24)\n```\n![](https://jcarroll.xyz/uploads/2022/ea5f75012f.gif)\n\nMoving the points around, I get a new version all of my own\n\n![](https://jcarroll.xyz/uploads/2022/b776bf8259.gif)\n\nI'm very happy with how these turned out, and I've learned a lot! A gist of the code to make these is hosted here: [https://gist.github.com/jonocarroll/27f9b57332424ea50ec2970e74d8e3b3](https://gist.github.com/jonocarroll/27f9b57332424ea50ec2970e74d8e3b3)\n\nIf there are better ways to do any of the steps (there surely are) please feel free to let me know!\n\nWas this fun? You Bezier ass!\n",
				"date_published": "2022-04-07T21:07:00+09:30",
				"url": "https://jcarroll.xyz/2022/04/07/interpolation-animation-in.html",
				"tags": ["Julia"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/03/25/r-challenge-contour.html",
				"title": "R challenge - contour in a matrix",
				"content_html": "<p>As part of what will hopefully become a larger post, I&rsquo;m interested in finding an R way to achieve the following: given an <code>n x n</code> matrix of zeroes with a single non-zero element of some value <code>v</code>, fill the surrounding entries such that each other element is at most one less than those surrounding it (up or down). For example, with an <code>8x8</code> matrix with a value of <code>5</code> at <code>c(5, 5)</code>, the result would be</p>\n<pre tabindex=\"0\"><code>     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n[1,]    0    0    0    0    1    0    0    0\n[2,]    0    0    0    1    2    1    0    0\n[3,]    0    0    1    2    3    2    1    0\n[4,]    0    0    2    3    4    3    2    1\n[5,]    1    2    3    4    5    4    3    2\n[6,]    0    1    2    3    4    3    2    1\n[7,]    0    0    1    2    3    2    1    0\n[8,]    0    0    0    1    2    1    0    0\n</code></pre><p>This is somewhat akin to imposing a contour density on top of a single peak, but I really can&rsquo;t find any suitable approaches. Convolutions came to mind, but I can&rsquo;t think of or find the appropriate kernel.</p>\n<p>Let me know if you have one!</p>\n<h2 id=\"update\">Update:</h2>\n<p>Thanks to <a href=\"https://twitter.com/yjunechoe/status/1507344665514848258?s=20&amp;t=27rn8zNl-36D-3ppsslAjw\">June Choe</a>, this code using <code>outer()</code> produces the desired matrix for a point at <code>c(vx, vy)</code> with value <code>vv</code> in a <code>n x n</code> matrix</p>\n<pre tabindex=\"0\"><code>vx &lt;- 4\nvy &lt;- 3\nvv &lt;- 5\nn &lt;- 8\nouter(1:n, 1:n, function(x, y) pmax(vv - abs(x - vx) - abs(y - vy), 0))\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n[1,]    0    1    2    1    0    0    0    0\n[2,]    1    2    3    2    1    0    0    0\n[3,]    2    3    4    3    2    1    0    0\n[4,]    3    4    5    4    3    2    1    0\n[5,]    2    3    4    3    2    1    0    0\n[6,]    1    2    3    2    1    0    0    0\n[7,]    0    1    2    1    0    0    0    0\n[8,]    0    0    1    0    0    0    0    0\n</code></pre>",
				"content_text": "As part of what will hopefully become a larger post, I'm interested in finding an R way to achieve the following: given an `n x n` matrix of zeroes with a single non-zero element of some value `v`, fill the surrounding entries such that each other element is at most one less than those surrounding it (up or down). For example, with an `8x8` matrix with a value of `5` at `c(5, 5)`, the result would be\n\n```\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n[1,]    0    0    0    0    1    0    0    0\n[2,]    0    0    0    1    2    1    0    0\n[3,]    0    0    1    2    3    2    1    0\n[4,]    0    0    2    3    4    3    2    1\n[5,]    1    2    3    4    5    4    3    2\n[6,]    0    1    2    3    4    3    2    1\n[7,]    0    0    1    2    3    2    1    0\n[8,]    0    0    0    1    2    1    0    0\n````\n\nThis is somewhat akin to imposing a contour density on top of a single peak, but I really can't find any suitable approaches. Convolutions came to mind, but I can't think of or find the appropriate kernel.\n\nLet me know if you have one!\n\n## Update:\n\nThanks to [June Choe](https://twitter.com/yjunechoe/status/1507344665514848258?s=20&t=27rn8zNl-36D-3ppsslAjw), this code using `outer()` produces the desired matrix for a point at `c(vx, vy)` with value `vv` in a `n x n` matrix \n```\nvx <- 4\nvy <- 3\nvv <- 5\nn <- 8\nouter(1:n, 1:n, function(x, y) pmax(vv - abs(x - vx) - abs(y - vy), 0))\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]\n[1,]    0    1    2    1    0    0    0    0\n[2,]    1    2    3    2    1    0    0    0\n[3,]    2    3    4    3    2    1    0    0\n[4,]    3    4    5    4    3    2    1    0\n[5,]    2    3    4    3    2    1    0    0\n[6,]    1    2    3    2    1    0    0    0\n[7,]    0    1    2    1    0    0    0    0\n[8,]    0    0    1    0    0    0    0    0\n```\n",
				"date_published": "2022-03-25T22:02:00+09:30",
				"url": "https://jcarroll.xyz/2022/03/25/r-challenge-contour.html",
				"tags": ["R"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/03/20/rowwise-optimizations-in.html",
				"title": "ByRow optimizations in Julia",
				"content_html": "<p>I&rsquo;m still fairly new to Julia, even though I&rsquo;ve been trying to learn it for a few years. It&rsquo;s <em>extremely</em> powerful (fast, expressive, &hellip; whatever metric you want to use) but with that comes some complexity.</p>\n<p>I saw <a href=\"https://bkamins.github.io/julialang/2022/02/25/anyall.html\">this post</a> in my feed and it seemed like a great bite-sized chunk of code to learn from. I <em>think</em> I understand everything that&rsquo;s happening, even if I certainly couldn&rsquo;t write that myself, with one exception.</p>\n<p>The connection that for <code>Bool</code> data, <code>all()</code> is equivalent to <code>minimum()</code> (it&rsquo;s false as soon as there is one 0, otherwise it&rsquo;s true) and <code>any()</code> is equivalent to <code>maximum()</code> (if there&rsquo;s a 1 it&rsquo;s true) took me a moment, but seems pretty cool. That wasn&rsquo;t the problem I had.</p>\n<p>The bit that surprised me was that for <code>ByRow</code> calculations on a <code>DataFrame</code>, <code>minimum()</code> is <strong>faster</strong> than <code>all()</code>. The reason this is so surprising for me is that I understand <code>all()</code> from an R-perspective and my understanding was that <code>all()</code> could short-circuit because as soon as it sees a <code>FALSE</code> it can ignore any other values - the result is guaranteed to be <code>FALSE</code> (yes, yes, up to missingness). Surely, a calculation of <code>minimum()</code> needs to evaluate every value at least once (?). Where this might (must?) fall apart is that I&rsquo;m thinking purely of vectors. Sure enough, checking out some timings on a vector in Julia shows <code>all()</code> is near-instantaneous (after compilation)</p>\n<pre tabindex=\"0\"><code class=\"language-{julia}\" data-lang=\"{julia}\">x = rand(Bool, 100_000_000)\n\n@time all(x)\n  0.009047 seconds (218 allocations: 9.531 KiB, 99.85% compilation time)\nfalse\n\n@time all(x)\n  0.000002 seconds\nfalse\n\n@time minimum(x)\n  0.091183 seconds (85.03 k allocations: 4.461 MiB, 41.98% compilation time)\nfalse\n\n@time minimum(x)\n  0.052287 seconds\nfalse\n</code></pre><p>I get similar results, expectedly, from R</p>\n<pre tabindex=\"0\"><code class=\"language-{r}\" data-lang=\"{r}\">x &lt;- sample(c(TRUE, FALSE), 1e8, replace = TRUE)\nmicrobenchmark::microbenchmark(\n  min = max(x),\n  any = any(x),\n  times = 10\n)\n# Unit: nanoseconds\n#  expr       min        lq        mean    median        uq       max neval\n#   min 208741173 210539351 223219500.3 212388892 222673528 285974960    10\n#   any       160       187      2403.4       295      5095      7451    10\n</code></pre><p>So, what&rsquo;s going on? I <em>think</em> the answer is that we&rsquo;re not dealing with just a vector, it&rsquo;s rows from a <code>DataFrame</code>, right? Now, from the R side, that&rsquo;s complicated enough - <code>rowwise()</code> is a <a href=\"https://speakerdeck.com/jennybc/row-oriented-workflows-in-r-with-the-tidyverse\">necessary thing</a> because R stores a <code>data.frame</code> as a list of vectors representing <em>columns</em>, so extracting a row means slicing across those.</p>\n<p>I can reproduce the speedup in Julia (and honestly, I struggle to find a clean and fast way to do it in R) but the statement &ldquo;<a href=\"https://bkamins.github.io/julialang/2022/02/25/anyall.html#:~:text=This%20time%20things%20are%20very%20fast%2C%20as%20row%2Dwise%20aggregation%20for%20maximum%20and%20minimum%20is%20optimized.\">This time things are very fast, as row-wise aggregation for maximum and minimum is optimized.</a>&rdquo; got me thinking - where should I have learned that? Google isn&rsquo;t showing me any relevant results, so is this just a known thing? I can imagine that such an optimization for doing this might exist, but can anyone provide a reference or guide?? The author of the blog post used this optimization in a <a href=\"https://stackoverflow.com/a/71209103/4168169\">StackOverflow answer</a> without challenge (no reference provided) so I feel like it&rsquo;s potentially just something I should know.</p>\n",
				"content_text": "I'm still fairly new to Julia, even though I've been trying to learn it for a few years. It's *extremely* powerful (fast, expressive, ... whatever metric you want to use) but with that comes some complexity. \n\nI saw [this post](https://bkamins.github.io/julialang/2022/02/25/anyall.html) in my feed and it seemed like a great bite-sized chunk of code to learn from. I *think* I understand everything that's happening, even if I certainly couldn't write that myself, with one exception.\n\nThe connection that for `Bool` data, `all()` is equivalent to `minimum()` (it's false as soon as there is one 0, otherwise it's true) and `any()` is equivalent to `maximum()` (if there's a 1 it's true) took me a moment, but seems pretty cool. That wasn't the problem I had.\n\nThe bit that surprised me was that for `ByRow` calculations on a `DataFrame`, `minimum()` is **faster** than `all()`. The reason this is so surprising for me is that I understand `all()` from an R-perspective and my understanding was that `all()` could short-circuit because as soon as it sees a `FALSE` it can ignore any other values - the result is guaranteed to be `FALSE` (yes, yes, up to missingness). Surely, a calculation of `minimum()` needs to evaluate every value at least once (?). Where this might (must?) fall apart is that I'm thinking purely of vectors. Sure enough, checking out some timings on a vector in Julia shows `all()` is near-instantaneous (after compilation)\n```{julia}\nx = rand(Bool, 100_000_000)\n\n@time all(x)\n  0.009047 seconds (218 allocations: 9.531 KiB, 99.85% compilation time)\nfalse\n\n@time all(x)\n  0.000002 seconds\nfalse\n\n@time minimum(x)\n  0.091183 seconds (85.03 k allocations: 4.461 MiB, 41.98% compilation time)\nfalse\n\n@time minimum(x)\n  0.052287 seconds\nfalse\n```\nI get similar results, expectedly, from R\n```{r}\nx <- sample(c(TRUE, FALSE), 1e8, replace = TRUE)\nmicrobenchmark::microbenchmark(\n  min = max(x),\n  any = any(x),\n  times = 10\n)\n# Unit: nanoseconds\n#  expr       min        lq        mean    median        uq       max neval\n#   min 208741173 210539351 223219500.3 212388892 222673528 285974960    10\n#   any       160       187      2403.4       295      5095      7451    10\n```\nSo, what's going on? I *think* the answer is that we're not dealing with just a vector, it's rows from a `DataFrame`, right? Now, from the R side, that's complicated enough - `rowwise()` is a [necessary thing](https://speakerdeck.com/jennybc/row-oriented-workflows-in-r-with-the-tidyverse) because R stores a `data.frame` as a list of vectors representing *columns*, so extracting a row means slicing across those. \n\nI can reproduce the speedup in Julia (and honestly, I struggle to find a clean and fast way to do it in R) but the statement \"[This time things are very fast, as row-wise aggregation for maximum and minimum is optimized.](https://bkamins.github.io/julialang/2022/02/25/anyall.html#:~:text=This%20time%20things%20are%20very%20fast%2C%20as%20row%2Dwise%20aggregation%20for%20maximum%20and%20minimum%20is%20optimized.)\" got me thinking - where should I have learned that? Google isn't showing me any relevant results, so is this just a known thing? I can imagine that such an optimization for doing this might exist, but can anyone provide a reference or guide?? The author of the blog post used this optimization in a [StackOverflow answer](https://stackoverflow.com/a/71209103/4168169) without challenge (no reference provided) so I feel like it's potentially just something I should know.\n",
				"date_published": "2022-03-20T13:11:00+09:30",
				"url": "https://jcarroll.xyz/2022/03/20/rowwise-optimizations-in.html",
				"tags": ["R","Julia"]
			},
			{
				"id": "http://jonocarroll.micro.blog/2022/03/20/first-post-on.html",
				"title": "First post on jcarroll.xyz",
				"content_html": "<p>I like blogging, but in the spirit of lowering the resistance to getting posts out, I&rsquo;ve started a micro blog <a href=\"https://jcarroll.xyz\">jcarroll.xyz</a> where I&rsquo;ll capture shorter, less polished pieces and random thoughts / snippets.</p>\n<p>This is my first post, testing all the functionality. DNS might still take a little while, so don&rsquo;t worry if you see my full blog when you click the link.</p>\n",
				"content_text": "I like blogging, but in the spirit of lowering the resistance to getting posts out, I've started a micro blog [jcarroll.xyz](https://jcarroll.xyz) where I'll capture shorter, less polished pieces and random thoughts / snippets.\n\nThis is my first post, testing all the functionality. DNS might still take a little while, so don't worry if you see my full blog when you click the link.\n",
				"date_published": "2022-03-20T11:28:39+09:30",
				"url": "https://jcarroll.xyz/2022/03/20/first-post-on.html"
			}
	]
}
